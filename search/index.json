[{"content":"Lua 源码阅读笔记-函数调用过程 先来看一段Lua代码和对应的字节码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 function f1(a, b , c) return c + a , b + a end function \u0026lt;test/test_call.lua:3,5\u0026gt; (6 instructions at 0x55d992393f40) 3 params, 5 slots, 0 upvalues, 3 locals, 0 constants, 0 functions 1 [4] ADD 3 2 0 2 [4] MMBIN 2 0 6 ; __add 3 [4] ADD 4 1 0 4 [4] MMBIN 1 0 6 ; __add 5 [4] RETURN 3 3 0 ; 2 out 6 [5] RETURN0 function call(a, b, c) local x, y = f1(a, b, c) return x, y end function \u0026lt;test/test_call.lua:7,10\u0026gt; (9 instructions at 0x55d9923942e0) 3 params, 7 slots, 1 upvalue, 5 locals, 1 constant, 0 functions 1 [8] GETTABUP 3 0 0 ; _ENV \u0026#34;f1\u0026#34; 将f1 函数拷贝到 3寄存器 2 [8] MOVE 4 0 // 移动A到4 寄存器 3 [8] MOVE 5 1 // 移动B到5 寄存器 4 [8] MOVE 6 2 // 移动C到6 寄存器 5 [8] CALL 3 4 3 ; 3 in 2 out /*\tA B C\tR[A], ... ,R[A+C-2] := R[A](R[A+1], ... ,R[A+B-1]) */ 6 [9] MOVE 5 3 // 将3 寄存器的东西拷贝到5 寄存器 7 [9] MOVE 6 4 // 将4 寄存器的东西拷贝到6 寄存器 8 [9] RETURN 5 3 0 ; 2 out /*\tA B C k\treturn R[A], ... ,R[A+B-2]\t(see note)\t*/ 9 [10] RETURN0 function tailCall(a, b, c) return f1(a, b, c) end function \u0026lt;test/test_call.lua:12,14\u0026gt; (7 instructions at 0x55d992394880) 3 params, 7 slots, 1 upvalue, 3 locals, 1 constant, 0 functions 1 [13] GETTABUP 3 0 0 ; _ENV \u0026#34;f1\u0026#34; 2 [13] MOVE 4 0 // 移动A到4 寄存器 3 [13] MOVE 5 1 // 移动B到5 寄存器 4 [13] MOVE 6 2 // 移动C到6 寄存器 5 [13] TAILCALL 3 4 0 ; 3 in /* A B C k return R[A](R[A+1], ... ,R[A+B-1]) */ 6 [13] RETURN 3 0 0 ; all out 7 [14] RETURN0 在Lua中，函数调用对应的字节码分为 OP_CALL 和 OP_TAIL_CALL, 接下来就分析一下这两个操作码对应的实现\nOP_CALL OP_CALL 字节码的参数有三个，调用的格式如下\n1 /*\tA B C\tR[A], ... ,R[A+C-2] := R[A](R[A+1], ... ,R[A+B-1]) */ 可以看到 OPCALL 的 操作数有三个，调用函数的时候，函数通过第一个操作数A来获取，从[A + 1, B - 1]都认为是函数的参数，如果有参数，则会将当前的栈顶修正 函数的返回个数会写入[A， A + C - 2]所在的位置。\n接下来看看源码里的具体实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 vmcase(OP_CALL) { StkId ra = RA(i); // R[A] 就是对应func，调用结束后的返回值第一个也存储在这个位置 CallInfo *newci; int b = GETARG_B(i); // 参数个数 int nresults = GETARG_C(i) - 1; // 返回值个数 if (b != 0) /* fixed number of arguments? */ L-\u0026gt;top.p = ra + b; /* top signals number of arguments */ /* else previous instruction set top */ savepc(L); /* 用于处理异常 */ if ((newci = luaD_precall(L, ra, nresults)) == NULL) updatetrap(ci); /* 用于处理 Call C 函数的行为*/ else { /* Lua call: run function in this same C frame */ // 对于LUA 函数而言，luaD_precall后就将ci换成新的ci，然后重新开始执行开始执行字节码 ci = newci; goto startfunc; } vmbreak; } 调用函数前会先通过luaD_precall 来做调用前的准备，如果是C的函数，则会在luaD_precall中直接调用；而如果是Lua函数则会创建一个新的CallInfo， 然后跳转到函数开头重新开始执行字节码，直到执行到RETURN 字节码\nluaD_precall luaD_precall 的主要目的是为了产生一个CallInfo（对于Lua函数来说），所以可以想象这边就是通过R[A]的内容来对CallInfo进行填充\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 CallInfo *luaD_precall (lua_State *L, StkId func, int nresults) { retry: switch (ttypetag(s2v(func))) { case LUA_VCCL: /* C closure */ ... case LUA_VLCF: /* light C function */ .... case LUA_VLCL: { /* Lua function */ Proto *p = clLvalue(s2v(func))-\u0026gt;p; int fsize = p-\u0026gt;maxstacksize; /* frame size */ int nfixparams = p-\u0026gt;numparams; int i; ci-\u0026gt;func.p -= delta; /* restore \u0026#39;func\u0026#39; (if vararg) */ // 这边会将函数、函数参数 都写入到正确的位置 // i = 0 的时候写入的就是函数 for (i = 0; i \u0026lt; narg1; i++) /* move down function and arguments */ setobjs2s(L, ci-\u0026gt;func.p + i, func + i); func = ci-\u0026gt;func.p; /* moved-down function */ // 如果传入的函数参数小于函数的定义，这边会补齐成nil for (; narg1 \u0026lt;= nfixparams; narg1++) setnilvalue(s2v(func + narg1)); /* complete missing arguments */ // 修正栈顶、修正字节码、调用类型等 ci-\u0026gt;top.p = func + 1 + fsize; /* top for new function */ ci-\u0026gt;u.l.savedpc = p-\u0026gt;code; /* starting point */ ci-\u0026gt;callstatus |= CIST_TAIL; L-\u0026gt;top.p = func + narg1; /* set top */ return -1; } default: { /* not a function */ func = luaD_tryfuncTM(L, func); /* try to get \u0026#39;__call\u0026#39; metamethod */ /* return luaD_precall(L, func, nresults); */ goto retry; /* try again with metamethod */ } } } 在lua函数的准备过程中，R[A]是Proto类型的数据结构。这边主要是通过Proto获取函数的字节码，函数的参数个数、返回值等行为，然后调整好CallInfo中的栈的大小、参数等信息，最后将函返回。 而对于 LUA_VCCL 和 LUA_VLCF ，他们都是C 的函数类型，都会执行 precallC ，在这个里面会完成C函数的调用。 在执行真正的f时，传入的是当前的lua_State，所以在写C扩展的时候，需要通过L的栈来获取Lua层传入的参数。执行完毕之后会调用 luaD_poscall 来清理。\nOP_RETURN 之前说了，对于Lua函数在创建完CallInfo之后，是跳转到开头重新执行当前CallInfo的字节码，所以需要执行到RETURN 之后，才会对之前的内存进行写入。OP_RETURN的操作码如下\n1 2 3 4 5 6 OP_RETURN,/*\tA B C k\treturn R[A], ... ,R[A+B-2]\t(see note)\t*/ (*) In instructions OP_RETURN/OP_TAILCALL, \u0026#39;k\u0026#39; specifies that the function builds upvalues, which may need to be closed. C \u0026gt; 0 means the function is vararg, so that its \u0026#39;func\u0026#39; must be corrected before returning; in this case, (C - 1) is its number of fixed parameters. A对应的就是之前的位置，而B在这边对应的是之前的C； 而这边的C如果大于0则代表函数需要在return前被修正，k代表有多少个upvalues需要被close.\n看看源码的具体实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 vmcase(OP_RETURN) { StkId ra = RA(i); // 获取之前的写入位置 int n = GETARG_B(i) - 1; // 获取需要返回的参数个数 int nparams1 = GETARG_C(i); if (n \u0026lt; 0) /* not fixed? */ n = cast_int(L-\u0026gt;top.p - ra); /* get what is available */ savepc(ci); // 处理 close upvalues 相关 if (TESTARG_k(i)) { /* may there be open upvalues? */ ci-\u0026gt;u2.nres = n; /* save number of returns */ if (L-\u0026gt;top.p \u0026lt; ci-\u0026gt;top.p) L-\u0026gt;top.p = ci-\u0026gt;top.p; luaF_close(L, base, CLOSEKTOP, 1); updatetrap(ci); updatestack(ci); } // 修正正确的函数位置 if (nparams1) /* vararg function? */ ci-\u0026gt;func.p -= ci-\u0026gt;u.l.nextraargs + nparams1; // 处理函数返回 L-\u0026gt;top.p = ra + n; /* set call for \u0026#39;luaD_poscall\u0026#39; */ luaD_poscall(L, ci, n); updatetrap(ci); /* \u0026#39;luaD_poscall\u0026#39; can change hooks */ goto ret; } /* ** Finishes a function call: calls hook if necessary, moves current ** number of results to proper place, and returns to previous call ** info. If function has to close variables, hook must be called after ** that. */ void luaD_poscall (lua_State *L, CallInfo *ci, int nres) { int wanted = ci-\u0026gt;nresults; // 获取函数预期的返回值 if (l_unlikely(L-\u0026gt;hookmask \u0026amp;\u0026amp; !hastocloseCfunc(wanted))) rethook(L, ci, nres); /* move results to proper place */ moveresults(L, ci-\u0026gt;func.p, nres, wanted); // 这边会将返回值移动到正确的位置 L-\u0026gt;ci = ci-\u0026gt;previous; /* back to caller (after closing variables) */ } 对于ABCk的处理，和之前说的一样，具体不在展开。具体的赋值在 moveresults 函数中。 这个函数比较长，但逻辑上来说主要是将函数的返回值移动到 ci-\u0026gt;func.p 的位置。并处理预期返回值和实际返回值不一致的情况。\nOP_TAILCALL OP_TAILCALL的字节码操作如下\n1 2 3 4 5 6 OP_TAILCALL,/* A B C k return R[A](R[A+1], ... ,R[A+B-1]) */ (*) In instructions OP_RETURN/OP_TAILCALL, \u0026#39;k\u0026#39; specifies that the function builds upvalues, which may need to be closed. C \u0026gt; 0 means the function is vararg, so that its \u0026#39;func\u0026#39; must be corrected before returning; in this case, (C - 1) is its number of fixed parameters. 可以看到这边的操作和 OP_RETURN一致，但在行为上和OP_CALL有着比较大的区别\n其中最主要的区别就是调用的时候，是不会新生成CallInfo的，而是在原来的CallInfo上进行数据的替换。\n接下来看看具体的代码是如何实现的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 vmcase(OP_TAILCALL) { StkId ra = RA(i); int b = GETARG_B(i); /* 获取对应的参数 */ int n; /* number of results when calling a C function */ int nparams1 = GETARG_C(i); /* delta is virtual \u0026#39;func\u0026#39; - real \u0026#39;func\u0026#39; (vararg functions) */ int delta = (nparams1) ? ci-\u0026gt;u.l.nextraargs + nparams1 : 0; // 确认L-\u0026gt;top的栈顶位置 if (b != 0) L-\u0026gt;top.p = ra + b; else /* previous instruction set top */ b = cast_int(L-\u0026gt;top.p - ra); savepc(ci); /* several calls here can raise errors */ if (TESTARG_k(i)) { luaF_closeupval(L, base); /* close upvalues from current call */ ...... } if ((n = luaD_pretailcall(L, ci, ra, b, delta)) \u0026lt; 0) /* Lua function? */ // lua func的调用是重新执行startfunc goto startfunc; /* execute the callee */ else { /* C function? */ // C函数调用结束的处理 ci-\u0026gt;func.p -= delta; /* restore \u0026#39;func\u0026#39; (if vararg) */ luaD_poscall(L, ci, n); /* finish caller */ updatetrap(ci); /* \u0026#39;luaD_poscall\u0026#39; can change hooks */ goto ret; /* caller returns after the tail call */ } } 和 OpCall 一样，具体CallInfo都是在luaD_pretailcall中进行处理的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 int luaD_pretailcall (lua_State *L, CallInfo *ci, StkId func, int narg1, int delta) { retry: switch (ttypetag(s2v(func))) { case LUA_VCCL: /* C closure */ return precallC(L, func, LUA_MULTRET, clCvalue(s2v(func))-\u0026gt;f); case LUA_VLCF: /* light C function */ return precallC(L, func, LUA_MULTRET, fvalue(s2v(func))); case LUA_VLCL: { /* Lua function */ // 对于Lua函数的处理 Proto *p = clLvalue(s2v(func))-\u0026gt;p; int fsize = p-\u0026gt;maxstacksize; /* frame size */ int nfixparams = p-\u0026gt;numparams; int i; checkstackGCp(L, fsize - delta, func); ci-\u0026gt;func.p -= delta; /* restore \u0026#39;func\u0026#39; (if vararg) */ // 外边的如果有C的话，那么计算出来的delta就会在这边使得函数栈底往下继续偏移 // 在当前栈上进行赋值 for (i = 0; i \u0026lt; narg1; i++) /* move down function and arguments */ setobjs2s(L, ci-\u0026gt;func.p + i, func + i); func = ci-\u0026gt;func.p; /* moved-down function */ for (; narg1 \u0026lt;= nfixparams; narg1++) setnilvalue(s2v(func + narg1)); /* complete missing arguments */ // 设置CallInfo的其他信息 ci-\u0026gt;top.p = func + 1 + fsize; /* top for new function */ ci-\u0026gt;u.l.savedpc = p-\u0026gt;code; /* starting point */ ci-\u0026gt;callstatus |= CIST_TAIL; L-\u0026gt;top.p = func + narg1; /* set top */ return -1; } default: { /* not a function */ // 如果是table设置了元表的，就会重新尝试处理 func = luaD_tryfuncTM(L, func); /* try to get \u0026#39;__call\u0026#39; metamethod */ /* return luaD_pretailcall(L, ci, func, narg1 + 1, delta); */ narg1++; goto retry; /* try again */ } } } 在luaD_pretailcall中，可以看到对于C函数的处理也是直接通过precallC进行调用了。而对于Lua函数来说，会将函数和参数重新赋值到当前栈上。这边可以注意\n1 2 for (i = 0; i \u0026lt; narg1; i++) /* move down function and arguments */ setobjs2s(L, ci-\u0026gt;func.p + i, func + i); 这一句是从0开始的，0的时候赋值的就是执行的函数，后面则是执行的参数。其他行为就是重新对当前的CallInfo进行改写。\n所以从整个流程上可以看出来，OpTailCall是字节在当前栈上进行构造的，所以无限递归不会造成栈溢出而是造成死循环。而且因为是复用调用栈的，所以在报错的时候会丢失中间部分栈的信息，对于某些时候的调试来说是比较不友好的，但效率的提升还是很大的。\n小结 这边总体过了一遍 对于LUA 来说是如何执行 OP_CALL 和 OP_TAILCALL 两种字节码的，也对比了一下在模型和代码上他们的主要区别，总要来说就是是否要生成新的CallInfo的区别。 我尝试修改LUA源码，在生成字节码的时候把生成OP_TAILCALL的地方注释掉，让其生成出来的是OP_CALL的字节码，也能正常运行，可以认为OP_TAILCALL就是在满足条件的情况下对应OP_CALL的优化。在正常情况下来说，这个优化是没问题的，不过如果无限递归了，反而不会抛出异常，这一点倒是有点小麻烦。\n","date":"2024-10-31T00:00:00Z","image":"https://frozenlychees.github.io/p/lua-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E8%BF%87%E7%A8%8B/lua_hu12632442988653076332.png","permalink":"https://frozenlychees.github.io/p/lua-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E8%BF%87%E7%A8%8B/","title":"Lua 源码阅读笔记-函数调用过程"},{"content":"todo 整理一下这个文章 需要在f_parser之前说明 top的结构 Lua 源码阅读笔记-Lua代码执行过程 因为脚本语言通常都是解释型语言，在执行脚本语言的时候，都需要先将代码翻译成对应虚拟机的字节码，然后虚拟机会调用一些加载的函数将字节码加载到虚拟机内执行，Lua也不例外。接下来就准备窥探一下Lua在从lua代码到虚拟机开始执行字节码的整个流程，并整理流程中遇到的比较重要的数据结构和函数，为之后深入研究Lua虚拟机做一个铺垫。\n这边探究的是5.4 的lua代码。\n整体数据结构 先来看一下整体的数据结构\n大概可以分为以下几个数据结构\nLuaStatus 是Lua的虚拟机，控制着当前代码的整个环境，持有对整个栈的引用 CallInfo 控制单个函数调用的环境，同时通过双向链表可以获取到整个调用栈的顺序。 Closure 函数闭包，分为CClosure和LClosure，其中Lua的LClosure 由Proto 和 upvales构成，upvalues是对于整个栈的其他位置的变量的引用. Proto 包含函数的字节码 和 局部变量、upvalues变量等DEBUG信息，可以认为这个就是函数编译后的静态的相关信息 整体流程 执行lua代码的流程大致如下\n在lua中整个流程大致可以分成两个子步骤\nlua代码的词法语法分析，这边的主要函数是在 luaY_parser 执行OpCode，这边主要函数是 luaV_execute 整个流程主要就是通过 luaY_parser 来产生Closure，并在 luaV_execute 中进行执行.\nf_parser 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 static void f_parser (lua_State *L, void *ud) { LClosure *cl; struct SParser *p = cast(struct SParser *, ud); int c = zgetc(p-\u0026gt;z); /* read first character */ if (c == LUA_SIGNATURE[0]) { // 加载二进制的处理 checkmode(L, p-\u0026gt;mode, \u0026#34;binary\u0026#34;); cl = luaU_undump(L, p-\u0026gt;z, p-\u0026gt;name); } else { // 加载文本文件的处理 checkmode(L, p-\u0026gt;mode, \u0026#34;text\u0026#34;); cl = luaY_parser(L, p-\u0026gt;z, \u0026amp;p-\u0026gt;buff, \u0026amp;p-\u0026gt;dyd, p-\u0026gt;name, c); } lua_assert(cl-\u0026gt;nupvalues == cl-\u0026gt;p-\u0026gt;sizeupvalues); luaF_initupvals(L, cl); } 这边具体不深入到 luaY_parser 的细节，这边只看 f_parser的 大致情况，可以比较明显的看出在 f_parser 中通过调用luaY_parser进行词法解析，并可以得到一个LClosure的数据结构。无论进入的是哪个分支，都可以在对应的函数中看到下面这一行调用\n1 setclLvalue2s(L, L-\u0026gt;top.p, cl); 说明cl已经被放置到 L-\u0026gt;top的位置。这个top就是当前栈的栈顶。所以在执行完整个f_parser后，栈顶就是一个Closure。这边稍微说明一下，因为这边做的是文件解析，所以到最后\nluaV_execute 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 l_sinline void ccall (lua_State *L, StkId func, int nResults, l_uint32 inc) { CallInfo *ci; L-\u0026gt;nCcalls += inc; // 增加调用次数 // 栈溢出判断 if (l_unlikely(getCcalls(L) \u0026gt;= LUAI_MAXCCALLS)) { checkstackp(L, 0, func); /* free any use of EXTRA_STACK */ luaE_checkcstack(L); } // 调用函数前的准备 if ((ci = luaD_precall(L, func, nResults)) != NULL) { /* Lua function? */ ci-\u0026gt;callstatus = CIST_FRESH; /* mark that it is a \u0026#34;fresh\u0026#34; execute */ // 执行luaV_execute，传入的是CallInfo luaV_execute(L, ci); /* call it */ } L-\u0026gt;nCcalls -= inc; } 调用luaV_execute的入口是ccall，这边的func是刚刚在栈内的Closure，nResult是对应闭包的返回值。\n在调用luaV_execute的时候传入的不是Closure，是CallInfo。而在 luaD_precall 这个准备函数里面可以看到CallInfo 和 Closure之间是如何联系上的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 CallInfo *luaD_precall (lua_State *L, StkId func, int nresults) { retry: switch (ttypetag(s2v(func))) { case LUA_VCCL: /* C closure */ ... case LUA_VLCF: /* light C function */ ... case LUA_VLCL: { /* Lua function */ CallInfo *ci; Proto *p = clLvalue(s2v(func))-\u0026gt;p; int fsize = p-\u0026gt;maxstacksize; /* frame size */ L-\u0026gt;ci = ci = prepCallInfo(L, func, nresults, 0, func + 1 + fsize); -- 建立关系 ci-\u0026gt;u.l.savedpc = p-\u0026gt;code; // 字节码指针在这里被设置到初始位置 // 修复传入的参数，如果传入的参数比预计的少，就补充 NIL int narg = cast_int(L-\u0026gt;top.p - func) - 1; /* 获取真实传入的参数 */ int nfixparams = p-\u0026gt;numparams; for (; narg \u0026lt; nfixparams; narg++) setnilvalue(s2v(L-\u0026gt;top.p++)); /* complete missing arguments */ lua_assert(ci-\u0026gt;top.p \u0026lt;= L-\u0026gt;stack_last.p); return ci; } default: ... // try to get \u0026#39;__call\u0026#39; metamethod } } } l_sinline CallInfo *prepCallInfo (lua_State *L, StkId func, int nret, int mask, StkId top) { CallInfo *ci = L-\u0026gt;ci = next_ci(L); /* new frame */ ci-\u0026gt;func.p = func; ci-\u0026gt;nresults = nret; ci-\u0026gt;callstatus = mask; ci-\u0026gt;top.p = top; return ci; } 这边只看 LUA_VLCL，这个是 lua 的函数类型，这边可以看到关系是在 prepCallInfo 中建立的，新初始的CallInfo将指针指向了Closure，并且初始化了新的调用栈的信息。\n接下来看 luaV_execute 是如何执行的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 void luaV_execute (lua_State *L, CallInfo *ci) { LClosure *cl; TValue *k; StkId base; const Instruction *pc; ...... cl = clLvalue(s2v(ci-\u0026gt;func.p)); k = cl-\u0026gt;p-\u0026gt;k; pc = ci-\u0026gt;u.l.savedpc; ...... base = ci-\u0026gt;func.p + 1; /* main loop of interpreter */ for (;;) { Instruction i; vmfetch(); // 这边的大致相当于执行 (base = ci-\u0026gt;func.p + 1); } i = *(pc++); ...... vmdispatch (GET_OPCODE(i)) { vmcase(OP_MOVE){.....} vmcase(OP_LOADI){.....} vmcase(OP_LOADF){.....} vmcase(OP_LOADK){.....} } } 在for循环里，指令的执行是根据i对应的字节码进行跳转执行的，而i在循环前都会通过 i = *(pc++) 进行获取。在 for 循环前，可以看到 pc 被赋值成 ci-\u0026gt;u.l.savedpc , 而这个位置就是 Closure中的Proto的字节码数组。\nclosure中的 upvalues 这个数组是怎么生成的 对于最外层的Closure，再编译字节码的时候，就会计算出需要的upvalues数量，在 f_parser 的最后一行代码，调用了 luaF_initupvals 初始化最外层的closure。\n1 2 3 4 5 6 7 8 9 10 11 void luaF_initupvals (lua_State *L, LClosure *cl) { int i; for (i = 0; i \u0026lt; cl-\u0026gt;nupvalues; i++) { GCObject *o = luaC_newobj(L, LUA_VUPVAL, sizeof(UpVal)); UpVal *uv = gco2upv(o); uv-\u0026gt;v.p = \u0026amp;uv-\u0026gt;u.value; /* make it closed */ setnilvalue(uv-\u0026gt;v.p); cl-\u0026gt;upvals[i] = uv; luaC_objbarrier(L, cl, uv); } } 这边会把最外层的Closure都初始化成nil，这样空间就预留出来了，后续字节码就能直接对这些空间进行初始化等一系列操作。\n而对于内层函数产生的Closure，我们可以通过对应的字节码发现端倪\n1 2 3 4 5 6 7 8 9 function f() local a = 1 function f2() a = a + 1 return a end return f2 end 通过 luac -l 获取上述lua代码的字节码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 main \u0026lt;test/test_main.lua:0,0\u0026gt; (4 instructions at 0x562d63b0ace0) 0+ params, 2 slots, 1 upvalue, 0 locals, 1 constant, 1 function 1 [1] VARARGPREP 0 2 [12] CLOSURE 0 0 ; 0x562d63b0af40 3 [4] SETTABUP 0 0 0 ; _ENV \u0026#34;f\u0026#34; 4 [12] RETURN 0 1 1 ; 0 out function \u0026lt;test/test_main.lua:4,12\u0026gt; (6 instructions at 0x562d63b0af40) 0 params, 2 slots, 1 upvalue, 1 local, 1 constant, 1 function 1 [6] LOADI 0 1 -- 这边对应 local a = 1 2 [10] CLOSURE 1 0 ; 0x562d63b0b320 -- 创建闭包 函数地址是0x562d63b0b320 3 [7] SETTABUP 0 0 1 ; _ENV \u0026#34;f2\u0026#34; -- 设置到 _ENV 中 4 [11] GETTABUP 1 0 0 ; _ENV \u0026#34;f2\u0026#34; 5 [11] RETURN 1 2 0k ; 1 out 6 [12] RETURN 1 1 0k ; 0 out function \u0026lt;test/test_main.lua:7,10\u0026gt; (7 instructions at 0x562d63b0b320) 0 params, 2 slots, 1 upvalue, 0 locals, 0 constants, 0 functions 1 [8] GETUPVAL 0 0 ; a 2 [8] ADDI 0 0 1 3 [8] MMBINI 0 1 6 0 ; __add 4 [8] SETUPVAL 0 0 ; a 5 [9] GETUPVAL 0 0 ; a 6 [9] RETURN1 0 7 [10] RETURN0 在funcction f 中，通过 CLOSURE 创建出了对应的closure，CLOSURE 对应的字节码是OP_CLOSURE.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 vmcase(OP_CLOSURE) { StkId ra = RA(i); Proto *p = cl-\u0026gt;p-\u0026gt;p[GETARG_Bx(i)]; --- 这边取出的是Proto，说明0x562d63b0b320应该对应的就是Proto halfProtect(pushclosure(L, p, cl-\u0026gt;upvals, base, ra)); --- 创建Closure，并塞到栈里 checkGC(L, ra + 1); vmbreak; } static void pushclosure (lua_State *L, Proto *p, UpVal **encup, StkId base, StkId ra) { int nup = p-\u0026gt;sizeupvalues; Upvaldesc *uv = p-\u0026gt;upvalues; int i; LClosure *ncl = luaF_newLclosure(L, nup); ncl-\u0026gt;p = p; setclLvalue2s(L, ra, ncl); /* anchor new closure in stack */ // 这边对UpValues做赋值 for (i = 0; i \u0026lt; nup; i++) { /* fill in its upvalues */ if (uv[i].instack) /* upvalue refers to local variable? */ ncl-\u0026gt;upvals[i] = luaF_findupval(L, base + uv[i].idx); // 如果在栈上，就通过idx直接获取赋值 else /* get upvalue from enclosing function */ ncl-\u0026gt;upvals[i] = encup[uv[i].idx]; // 如果不在栈上，说明需要通过对当前的Closure的upvalues进行间接获取 luaC_objbarrier(L, ncl, ncl-\u0026gt;upvals[i]); } } 可以看到在pushClosure的时候，会新初始化一个Closure，并通过 Proto 对upvals进行初始化，如果对应的upvals是在栈上的，则引用栈上对应的idx的变量。如果不在栈上的，则引用当前的Closure的upvals的对应变量。\n这边存在一个比较特殊的点，从栈上赋值的时候，通过的是 newupval\n1 2 3 4 5 6 7 8 static UpVal *newupval (lua_State *L, StkId level, UpVal **prev) { GCObject *o = luaC_newobj(L, LUA_VUPVAL, sizeof(UpVal)); UpVal *uv = gco2upv(o); UpVal *next = *prev; uv-\u0026gt;v.p = s2v(level); /* current value lives in the stack */ // 从这边赋值的话，是会新建一个upvalues的， ...... return uv; } s2v 的方式会把栈上的值通过拷贝的方式新建一个出来，所以这个时候会导致数值、字符串等都被静态拷贝一份，相当于创建闭包的时候会固定了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 a = {} function f() for i = 1, 5 do a[i] = function() return i end end end f() for k, v in pairs(a) do print(k, v()) end -- 输出 1 1 2 2 3 3 4 4 5 5 而对于非栈的赋值，是直接拷贝 encup[uv[i].idx] 的， 这个时候无论是不是数值，都是变成引用。如果存在多层的upvalus的嵌套时，最好别混用这些行为。更建议都统一认为upvalues都是对外面的引用，这样出错的概率会小一点\n使用GDB 验证 在GDB环境下执行 lua xxxx.lua 脚本，可以看到以下栈\n1 2 3 4 5 6 7 8 9 #0 luaV_execute (L=0x5555557ac268, ci=0x5555557adab0) at lvm.c:1156 #1 0x00005555555642d6 in ccall (L=0x5555557ac268, func=0x5555557ac910, nResults=-1, inc=65537) at ldo.c:637 #2 0x000055555556434b in luaD_callnoyield (L=0x5555557ac268, func=0x5555557ac910, nResults=-1) at ldo.c:655 .... #7 0x000055555555b6e7 in docall (L=0x5555557ac268, narg=0, nres=-1) at lua.c:160 #8 0x000055555555bb07 in handle_script (L=0x5555557ac268, argv=0x7fffffffddd0) at lua.c:256 #9 0x000055555555c7c8 in pmain (L=0x5555557ac268) at lua.c:645 .... #18 0x000055555555c916 in main (argc=2, argv=0x7fffffffddc8) at lua.c:673 其中，\n在 handle_script 中执行了 luaL_loadfile 将脚本加载到内存并完成词法分析，并将 Closure 设置到了栈顶 在 handle_script 中准备开始调用的时候，是通过 docall 进行的，这边n是执行lua脚本时给的参数数量，返回值个数被写死成 LUA_MULTRET 在 docall 中，执行前第一步就是将base 取出，base取出的方式是通过 1 base = lua_gettop(L) - narg 这样base就是词法分析得到的 Closure 到 ccall 后，对应的入参就是func 就是之前说的Closure，然后通过 luaD_precall 进行初始化，最后执行 luaV_execute 完成调用 小结 这边基本完成了对Lua内执行一个脚本的流程的分析，梳理了对应的数据结构和数据的流向，对未来更深入了解Lua虚拟机做了一些铺垫。 个人认为相比于Python的虚拟机来说，Lua虚拟机设计的还是比较精炼的，但精炼就会带来一些地方会比较难以理解，需要多看两遍用GDB跟着实验一下会更能理解其中的设计\n","date":"2024-09-20T00:00:00Z","image":"https://frozenlychees.github.io/p/lua-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-lua%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/lua_hu12632442988653076332.png","permalink":"https://frozenlychees.github.io/p/lua-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-lua%E4%BB%A3%E7%A0%81%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/","title":"Lua 源码阅读笔记-Lua代码执行过程"},{"content":"Skynet源码阅读笔记-Skynet进程架构总览 skynet进程在架构如上图所示，skynet的主要工作模式就是通过创建很多的服务来完成的，服务与服务之间相互隔离，通过消息队列的方式将消息投递到对应的服务上。无论这个消息是来自网络、定时器或者是其他模块之间的消息，他们都会被打包成相同的类型，通过type来区别。\nskynet的主线程的启动流程大致也如上，启动完毕后久等待信号关闭线程进行资源回收了。\n其中业务流程是在bootstrap中进行启动的，业务根据自己的需要改写lua层面的启动流程即可。\n个人理解 skynet的这种方式模式可以认为是单进程多线程的一个模型，对于内存共享行的业务来说比较合适，它的主要业务处理是通过worker线程来完成的，在一台机器上启动足够多的即可充分使用机器性能，对于跨线程的消息投递来说也可以节省序列化相关的CPU消耗。但如果使用不当，感觉也会出现比较奇怪的问题（假设发送之后立即把对象给改写了的话，感觉可能会出现问题）。\n存在的其他缺陷的话就是容易对于一些公用功能，如果存在特别大量消息要处理的话，那可能就会存在异常；又或者是类似socket线程调用了阻塞式的系统API的话，就会导致所有业务都无法正常进行了。在实际生产过程中遇到过一次使用skynet去发送http请求，但dns服务器发生了一些异常，导致socket线程被卡住的情况。\n但总归来说，skynet的提供的主要功能就是\n隔离各个业务模块 单进程多线程尽量提升单台机器性能 对于一些跨机器的业务，skynet也提供了cluster集群等对应的解决思路，但其中有一些设计个人感觉会有点奇怪，在做完整的架构设计前，最好花一些时间去了解。\n","date":"2024-09-15T00:00:00Z","image":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E5%8D%81%E5%9B%9B-skynet%E8%BF%9B%E7%A8%8B%E6%9E%B6%E6%9E%84%E6%80%BB%E8%A7%88/skynet_hu17557819904416107650.png","permalink":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E5%8D%81%E5%9B%9B-skynet%E8%BF%9B%E7%A8%8B%E6%9E%B6%E6%9E%84%E6%80%BB%E8%A7%88/","title":"Skynet源码阅读笔记(十四)-Skynet进程架构总览"},{"content":"Skynet源码阅读笔记-cluster模式分析 项目中主要用到的是cluster模式，这边就简单的分析一下具体它是如何运作的。\ncluster 模型 从途中可以看出clusterd才是cluter集群模式的主体，其中保存了两个主要的数据结构用于发送和接受消息。 从clusterSender 发起的连接会通过gateserver收到并通过clusterd创建的clusterAgent进行消息的处理。\ncluster.lua 在使用的时候，需要将cluster require进来。而 cluster 这个文件本身主要是提供对外接口，在require的时候会执行init，init中调用uniqueserver来生成一个 clusterd 的服务，这个服务才是cluster模式的主体。\nclusterd.lua cluter集群的主体，这边会对处理对其他clusterd的连接和消息处理。\nlisten 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 --- cluster.lua function cluster.open(port, maxclient) if type(port) == \u0026#34;string\u0026#34; then return skynet.call(clusterd, \u0026#34;lua\u0026#34;, \u0026#34;listen\u0026#34;, port, nil, maxclient) else return skynet.call(clusterd, \u0026#34;lua\u0026#34;, \u0026#34;listen\u0026#34;, \u0026#34;0.0.0.0\u0026#34;, port, maxclient) end end --- clusterd.lua function command.listen(source, addr, port, maxclient) local gate = skynet.newservice(\u0026#34;gate\u0026#34;) if port == nil then ... else local realaddr, realport = skynet.call(gate, \u0026#34;lua\u0026#34;, \u0026#34;open\u0026#34;, { address = addr, port = port, maxclient = maxclient }) skynet.ret(skynet.pack(realaddr, realport)) end end 当外部调用open的时候，会转发到clusterd的listen接口，该接口会创建一个gate的service，然后调用gate的open接口，成功后返回实际的地址和端口。\n发起连接 1 2 3 4 5 6 7 8 9 10 11 --- cluster.lua function cluster.reload(config) skynet.call(clusterd, \u0026#34;lua\u0026#34;, \u0026#34;reload\u0026#34;, config) end --- clusterd.lua function command.reload(source, config) loadconfig(config) skynet.ret(skynet.pack(nil)) end 当调用cluter的reload接口，并传入对应的配置后，相当于调用的是clusterd.loadconfig(config), 这个config的格式是 {name: addr},具体看看loadconfig中做了什么\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 --- clusterd.lua local node_channel = setmetatable({}, { __index = open_channel }) function loadconfig(tmp) if tmp == nil then ... --- 传入空的时候 读环境配置 end local reload = {} for name,address in pairs(tmp) do if name:sub(1,2) == \u0026#34;__\u0026#34; then --- 特殊开头的名字需要输出一下 .... else assert(address == false or type(address) == \u0026#34;string\u0026#34;) if node_address[name] ~= address then -- address changed --- 原有连接的地址变了 if node_sender[name] then -- reset connection if node_sender[name] exist node_channel[name] = nil table.insert(reload, name) end node_address[name] = address end local ct = connecting[name] if ct and ct.namequery and not config.nowaiting then --- 查询地址的处理 skynet.error(string.format(\u0026#34;Cluster node [%s] resloved : %s\u0026#34;, name, address)) skynet.wakeup(ct.namequery) end end end if config.nowaiting then --- 有设置nowaiting的特殊处理 .... end for _, name in ipairs(reload) do -- open_channel would block skynet.fork(open_channel, node_channel, name) end end node_address 维护的是名字到地址的映射，node_sender 维护的是名字到sender的映射，当访问不存在的name时，会触发open_channel。\nloadConfig中做的主要是将传入的{name:address}的配置进行处理，如果之前不在node_address 中的，则标记需要连接；如果之前在node_address中的，则说明已经连接上了，需要重新连接。最后对每一个需要连接的配置启动一个协程进行open_channel的操作。\nopen_channel open_channel 的主要目的就是连接对应的地址\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 --- 这边 t 是node_channel， key是对应name local function open_channel(t, key) local ct = connecting[key] if ct then ... --- 如果已经在连接了，则这边不会重复连接，协程会被挂起到另一个协程连接完成 end ct = {} connecting[key] = ct local address = node_address[key] if address == nil and not config.nowaiting then --- 如果连接的name没有对应的地址，则会挂起该协程，直到reload 对应配置的时候被唤醒 ... end local succ, err, c if address then local host, port = string.match(address, \u0026#34;([^:]+):(.*)$\u0026#34;) c = node_sender[key] if c == nil then --- 创建对应的sender c = skynet.newservice(\u0026#34;clustersender\u0026#34;, key, nodename, host, port) if node_sender[key] then -- double check skynet.kill(c) c = node_sender[key] else node_sender[key] = c end end --- 调用sender的changenode succ = pcall(skynet.call, c, \u0026#34;lua\u0026#34;, \u0026#34;changenode\u0026#34;, host, port) if succ then t[key] = c ct.channel = c node_sender_closed[key] = nil else err = string.format(\u0026#34;changenode [%s] (%s:%s) failed\u0026#34;, key, host, port) end elseif address == false then c = node_sender[key] if c == nil or node_sender_closed[key] then -- no sender or closed, always succ succ = true else -- trun off the sender --- 如果地址是false，则直接关闭对应的sender succ, err = pcall(skynet.call, c, \u0026#34;lua\u0026#34;, \u0026#34;changenode\u0026#34;, false) if succ then --trun off failed, wait next index todo turn off node_sender_closed[key] = true end end else err = string.format(\u0026#34;cluster node [%s] is absent.\u0026#34;, key) end --- 唤醒所有等待连接的协程 connecting[key] = nil for _, co in ipairs(ct) do skynet.wakeup(co) end --- 在检查一遍地址，如果不正确则再次连接 if node_address[key] ~= address then return open_channel(t,key) end assert(succ, err) return c end open_channel 看起来有点长，实际并不会很复杂。主要目的就是为了创建clustersender，并调用其changenode。这边可以简单认为调用成功的话，就是连接完毕了。\ngate 和 gateServer 现在目光来到gate这边，因为上面发起连接之后，对方处理listen的gate此时应该就会收到对应的信息。\ngate.lua文件里面可以看到实际上这个文件就是一个中间层，提供gateserver到外部的消息接口 以及 外部调用到gateServer的接口。\n在gate 这个文件的最后，执行了\n1 2 local handler = {} gateserver.start(handler) 这个handler是gate.lua中的一个局部变量，用来承接从gateServer中抛出的事件转发给外部用的。\n在clusterd创建geta的时候，还顺便调用了open这个接口\n1 2 3 4 function handler.open(source, conf) watchdog = conf.watchdog or source return conf.address, conf.port end open接口内就把clusterd作为watchdog给保存了下来。\ngateServer gateServer.lua中也有很多的函数，但不用害怕，绝大多是都是命令，这边初始化的时候就只执行了下面这段代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 ... skynet.register_protocol { name = \u0026#34;socket\u0026#34;, id = skynet.PTYPE_SOCKET,\t-- PTYPE_SOCKET = 6 unpack = function ( msg, sz ) return netpack.filter( queue, msg, sz) end, dispatch = function (_, _, q, type, ...) queue = q if type then MSG[type](...) end end } local function init() skynet.dispatch(\u0026#34;lua\u0026#34;, function (_, address, cmd, ...) local f = CMD[cmd] if f then skynet.ret(skynet.pack(f(address, ...))) else skynet.ret(skynet.pack(handler.command(cmd, address, ...))) end end) end if handler.embed then init() else skynet.start(init) end 这边注册了 skynet.PTYPE_SOCKET 这个类型的协议，已经lua 类型的协议的dispatch方式。lua类型的协议搜索空间是CMD，而 skynet.PTYPE_SOCKET 的搜索空间是MSG\naccept 当底层收到连接了之后，会抛出连接的信息给到gateServer\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 int skynet_socket_poll() { struct socket_server *ss = SOCKET_SERVER; assert(ss); struct socket_message result; int more = 1; int type = socket_server_poll(ss, \u0026amp;result, \u0026amp;more); switch (type) { ... case SOCKET_ACCEPT: forward_message(SKYNET_SOCKET_TYPE_ACCEPT, true, \u0026amp;result); break; } if (more) { return -1; } return 1; } forward_message 会将 SOCKET_ACCEPT 包装成 id为 skynet.PTYPE_SOCKET 的信息，其中还会把 skynet_socket_message 的type标记成 SKYNET_SOCKET_TYPE_ACCEPT。\n在gateServer中接到这个消息后，会netpack.filter将其解开，得到对应的type为open，这一步是在lua-netpack.c中处理的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 --- gateServer.lua function MSG.open(fd, msg) client_number = client_number + 1 if client_number \u0026gt;= maxclient then socketdriver.shutdown(fd) return end if nodelay then socketdriver.nodelay(fd) end connection[fd] = true handler.connect(fd, msg) end --- gate.lua function handler.connect(fd, addr) local c = { fd = fd, ip = addr, } connection[fd] = c skynet.send(watchdog, \u0026#34;lua\u0026#34;, \u0026#34;socket\u0026#34;, \u0026#34;open\u0026#34;, fd, addr) end gateServer中open最主要的事情也就是将这个事件调出去，而gate中则是将对应的连接保存后，给watchdog发送消息，因为clueted在一开始的时候就将自己设置成了watchdog，所以这边消息就又回到了clusterd上。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 --- clusterd.lua function command.socket(source, subcmd, fd, msg) if subcmd == \u0026#34;open\u0026#34; then skynet.error(string.format(\u0026#34;socket accept from %s\u0026#34;, msg)) -- new cluster agent cluster_agent[fd] = false local agent = skynet.newservice(\u0026#34;clusteragent\u0026#34;, skynet.self(), source, fd) local closed = cluster_agent[fd] cluster_agent[fd] = agent if closed then skynet.send(agent, \u0026#34;lua\u0026#34;, \u0026#34;exit\u0026#34;) cluster_agent[fd] = nil end else ... end end clusterd 上对于这个消息的处理就是将对应cluster_agent给创建出来，如果之前有对应fd的连接信息，则关闭掉之前的。\nclusteragent 来到 clueteragent的创建\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 skynet.start(function() --- 注册协议 skynet.register_protocol { name = \u0026#34;client\u0026#34;, id = skynet.PTYPE_CLIENT, unpack = cluster.unpackrequest, dispatch = dispatch_request, } -- fd can write, but don\u0026#39;t read fd, the data package will forward from gate though client protocol. --- 此时fd只能写不能读，需要通过forward协议完成后续的内容 skynet.call(gate, \u0026#34;lua\u0026#34;, \u0026#34;forward\u0026#34;, fd) --- 完成disptach的处理 skynet.dispatch(\u0026#34;lua\u0026#34;, function(_,source, cmd, ...) if cmd == \u0026#34;exit\u0026#34; then socket.close_fd(fd) skynet.exit() elseif cmd == \u0026#34;namechange\u0026#34; then register_name = new_register_name() else skynet.error(string.format(\u0026#34;Invalid command %s from %s\u0026#34;, cmd, skynet.address(source))) end end) end) clusteragent在创建的时候有一个特殊的处理是给gate发送了一个forward 的协议，发送forward之后会导致gate的连接状态更新，把连接的agent更新成clusteragent。同时也会让底层更新对应的socket状态\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 --- gate.lua function CMD.forward(source, fd, client, address) local c = assert(connection[fd]) unforward(c) c.client = client or 0 c.agent = address or source gateserver.openclient(fd) end --- gateserver.lua function gateserver.openclient(fd) if connection[fd] then socketdriver.start(fd) end end --- lua-socket.c void socket_server_start(struct socket_server *ss, uintptr_t opaque, int id) { struct request_package request; request.u.resumepause.id = id; --- 这个id 就是 lua传进来的fd request.u.resumepause.opaque = opaque; send_request(ss, \u0026amp;request, \u0026#39;R\u0026#39;, sizeof(request.u.resumepause)); --- 这边给socket_server.c发送 } --- socket_server.c static int resume_socket(struct socket_server *ss, struct request_resumepause *request, struct socket_message *result) { int id = request-\u0026gt;id; ... --- 处理一些特殊的异常情况 uint8_t type = ATOM_LOAD(\u0026amp;s-\u0026gt;type); if (type == SOCKET_TYPE_PACCEPT || type == SOCKET_TYPE_PLISTEN) { ATOM_STORE(\u0026amp;s-\u0026gt;type , (type == SOCKET_TYPE_PACCEPT) ? SOCKET_TYPE_CONNECTED : SOCKET_TYPE_LISTEN); s-\u0026gt;opaque = request-\u0026gt;opaque; result-\u0026gt;data = \u0026#34;start\u0026#34;; return SOCKET_OPEN; } ... --- 处理一些特殊的异常情况 return -1; } forward 信息最后回到底层之后，正常情况下会修改对应socket的信息，将type变成 SOCKET_TYPE_CONNECTED.\n发送消息 当我们要发送消息的时候，使用的是 cluster.call 这个接口\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 --- cluster.lua function cluster.call(node, address, ...) -- skynet.pack(...) will free by cluster.core.packrequest local s = sender[node] if not s then --- 还没有的时候会进行等待处理 end return skynet.call(s, \u0026#34;lua\u0026#34;, \u0026#34;req\u0026#34;, address, skynet.pack(...)) end --- clusterSender.lua function command.req(...) local ok, msg = pcall(send_request, ...) if ok then if type(msg) == \u0026#34;table\u0026#34; then skynet.ret(cluster.concat(msg)) else skynet.ret(msg) end else skynet.error(msg) skynet.response()(false) end end local function send_request(addr, msg, sz) -- msg is a local pointer, cluster.packrequest will free it local current_session = session local request, new_session, padding = cluster.packrequest(addr, session, msg, sz) session = new_session .... return channel:request(request, current_session, padding) end 这个接口是通过node来找到对应的sender，最终通过channel的request来发送数据，这边可以认为就是给对应的fd发送数据。\n接受消息 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 --- gateserver.lua local function dispatch_msg(fd, msg, sz) if connection[fd] then handler.message(fd, msg, sz) else skynet.error(string.format(\u0026#34;Drop message from fd (%d) : %s\u0026#34;, fd, netpack.tostring(msg,sz))) end end MSG.data = dispatch_msg --- gate.lua function handler.message(fd, msg, sz) -- recv a package, forward it local c = connection[fd] local agent = c.agent if agent then -- 这边就是clusteragent -- It\u0026#39;s safe to redirect msg directly , gateserver framework will not free msg. skynet.redirect(agent, c.client, \u0026#34;client\u0026#34;, fd, msg, sz) else skynet.send(watchdog, \u0026#34;lua\u0026#34;, \u0026#34;socket\u0026#34;, \u0026#34;data\u0026#34;, fd, skynet.tostring(msg, sz)) -- skynet.tostring will copy msg to a string, so we must free msg here. skynet.trash(msg,sz) end end 在gateserver.lua中接受消息后 调用的是MSG.data 接口，这边会调用handler的message，转发给对应的clusteragent, 这边转发的消息类型会变成client\nclusteragent 在clueteragent中，对于client的消息是通过dispatch_request进行处理\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 local function dispatch_request(_,_,addr, session, msg, sz, padding, is_push) ... local ok, response if addr == 0 then ... --- 查询名字相关 else if cluster.isname(addr) then addr = register_name[addr] end if addr then if is_push then skynet.rawsend(addr, \u0026#34;lua\u0026#34;, msg, sz) return\t-- no response else ... ok , msg, sz = pcall(skynet.rawcall, addr, \u0026#34;lua\u0026#34;, msg, sz) end else ok = false msg = \u0026#34;Invalid name\u0026#34; end end if ok then --- 打包回包数据 response = cluster.packresponse(session, true, msg, sz) if type(response) == \u0026#34;table\u0026#34; then for _, v in ipairs(response) do socket.lwrite(fd, v) end else socket.write(fd, response) end else response = cluster.packresponse(session, false, msg) socket.write(fd, response) end end 这边化简后的代码如上，总的来说就是解析对应的数据，然后发送给对应的名字的服务，这个名字需要由其他服务主动来注册。调用完毕之后就会将数据打包，然后通过对应的socket write的方式将回包数据写入fd中。\n小结 这边基本把 cluster模式中几个比较重要的事情以源码分析的方式都分析了一下，虽然篇幅较长，但我感觉只要耐心看完应该会由收获。不过我个人没有get到为什么要读写分离成sender和agent的方式，可能是为了复用先用代码是新的一些功能？如果由我来实现的话，我可能会将这两个写在同一个结构内，感觉会更加统一一点。\n","date":"2024-09-02T00:00:00Z","image":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E5%8D%81%E4%B8%89-cluster%E9%9B%86%E7%BE%A4/skynet_hu17557819904416107650.png","permalink":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E5%8D%81%E4%B8%89-cluster%E9%9B%86%E7%BE%A4/","title":"Skynet源码阅读笔记(十三)-cluster集群"},{"content":"skynet API skynet 的API在 LuaAPI 中由简单的使用方式介绍，这边针对其中的部分API做一些源码上的分析\nAPI 分类 这边将会按上面的几个大类来对 skynet 的 lua层常用API 进行源码上的分析\n源码分析 服务的启动 skynet启动函数必须使用skynet.start来传入一个函数进行启动，这边分析一下skynet.start的源码，看看具体做了什么\nskynet.start 在lua层启动一个服务的时候，是skynet.star这个API来启动的，启动时传入一个自定义的函数，在适当的时机会被调用以启动具体的服务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 function skynet.start(start_func) c.callback(skynet.dispatch_message) -- 将当前服务的回调设置成disptach_message init_thread = skynet.timeout(0, function() -- 设置一个定时器，在帧末尾执行skynet.init_service(start_func). 主要这边回调的时候执行的是dispatch skynet.init_service(start_func) init_thread = nil end) -- 同时，skynet.timeout这边会产生一个协程 end function skynet.init_service(start) local function main() skynet_require.init_all() -- 执行start前会调用init_all start() end local ok, err = xpcall(main, traceback) -- 通过xpcall的方式调用main，main中执行start函数 if not ok then skynet.error(\u0026#34;init service failed: \u0026#34; .. tostring(err)) skynet.send(\u0026#34;.launcher\u0026#34;,\u0026#34;lua\u0026#34;, \u0026#34;ERROR\u0026#34;) skynet.exit() else skynet.send(\u0026#34;.launcher\u0026#34;,\u0026#34;lua\u0026#34;, \u0026#34;LAUNCHOK\u0026#34;) end end 启动前会先调用skynet_require.init_all()， 这个函数可以让用户预先require所需要的文件。 启动的时候是将当前服务的回调函数设置城 skynet.dispatch_message, 注意这边不单单是设置定时器的回调，而是设置的服务的事件回调函数，这边的事件包括定时器、网络信息等。然后设置一个0秒后的定时器进行回调，skynet.timeout这个接口会产生一个协程用于执行回调函数。\n消息分发 这边消息指的是从skynet底层抛出的消息事件，在start的时候，将处理这个事件的函数指定成了 skynet.dispatch_message ，这边看看消息是如何在这个函数中被处理的\n数据结构 继续往下前，先看一些协程相关数据结构，避免在看源码的时候会被这些数据结构的含义给阻塞\n1 2 3 4 5 6 7 8 9 10 11 local session_id_coroutine = {} -- session 到 co 的映射 local session_coroutine_id = {} -- co 到 session 的映射 local session_coroutine_address = {} -- co 到 来源服务的映射 local session_coroutine_tracetag = {} -- co 到 traceId的映射，用来记录协程的日志行为记录 local unresponse = {} -- 使用skynet.response获得闭包且并没有使用闭包进行回包处理的协程 local wakeup_queue = {} --被唤醒的co，co之前是主动sleep的 local sleep_session = {} -- token 到 session的 映射 local fork_queue = { h = 1, t = 0 } -- 保存 主动调用skynet.fork时产生的协程 这边co指的是协程，session是由skynet产生，用来对应挂起的co；traceId是用来记录对应co的行为日志使用的。 sleep_session 中 保存token 到 主动sleep的协程对应的session 的映射 ，token是由用户置顶或者系统生成的。\nskynet.dispatch_message 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 function skynet.dispatch_message(...) local succ, err = pcall(raw_dispatch_message,...) -- raw_dispatch_message中需要根据不同的事件类型来执行对应的处理函数 while true do if fork_queue.h \u0026gt; fork_queue.t then -- 如果队列中没有需要处理的事件，则退出 -- queue is empty fork_queue.h = 1 fork_queue.t = 0 break end -- pop queue local h = fork_queue.h -- 取出队列中需要处理的协程 local co = fork_queue[h] fork_queue[h] = nil fork_queue.h = h + 1 local fork_succ, fork_err = pcall(suspend,co,coroutine_resume(co)) -- 执行协程 if not fork_succ then ... -- 这边只是对错误信息进行拼接 end end assert(succ, tostring(err)) -- 如果有报错则统一输出 end skynet.dispatch_message 的过程可以看成两个部分\n通过 raw_dispatch_message 来处理事件 执行fork_queue中的协程，这部分是用户主动调用skynet.fork产生的 raw_dispatch_message 1 2 3 4 5 6 7 8 9 10 local function raw_dispatch_message(prototype, msg, sz, session, source) -- skynet.PTYPE_RESPONSE = 1, read skynet.h if prototype == 1 then -- 处理 response ... else -- 处理其他数据 ... end end raw_dispatch_message的参数含义如下\nprototype 事件类型，具体看 skynet.h msg 消息 sz 消息长度 session 执行事件的协程标记 source 消息来源 整个 raw_dispatch_message 分成 response事件 和 其他事件 这两个部分来分析\nresponse事件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 if prototype == 1 then local co = session_id_coroutine[session] if co == \u0026#34;BREAK\u0026#34; then session_id_coroutine[session] = nil elseif co == nil then unknown_response(session, source, msg, sz) else local tag = session_coroutine_tracetag[co] if tag then c.trace(tag, \u0026#34;resume\u0026#34;) end session_id_coroutine[session] = nil suspend(co, coroutine_resume(co, true, msg, sz, session)) end else ... end response事件 通过session 来找到对应的执行协程，如果协程是不存在或者是处于\u0026quot;BREAK\u0026quot;的状态的话，则执行对应的错误处理。否则就通过 session_id_coroutine 找到对应四鹅城，将消息数据传入协程，然后让其继续执行即可。同时这边也可以推测，lua层有调用skynet的框架的API时，应该都会将自身协程挂起，等待dispatch回来后再继续处理。\n其他类型的协议处理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 else local p = proto[prototype] -- 先查以下proto中是否有对应类型的数据，如果没有的话则进行错误处理 if p == nil then ... return end local f = p.dispatch if f then -- 新建协程 local co = co_create(f) session_coroutine_id[co] = session session_coroutine_address[co] = source -- 记录来源 -- 如果开了traceflag，就会处理记录source到本服务的事件记录 local traceflag = p.trace ... suspend(co, coroutine_resume(co, session,source, p.unpack(msg,sz))) -- 执行调度 else -- 如果注册的协议没有对应的处理函数，则也执行错误处理 ... end end 其他事件处理的情况时，首先会查找一下对应协议类型是否有注册过，以及是否有对应的执行函数。调用前会判断对应的协议是否开启了记录，便于debug。最后也是创建协程来执行对应的调度函数。所以可以知道lua层在处理skynet的消息时，都是采用协程的方式进行执行的。\n注册协议类型 skynet.register_protocol 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 function skynet.register_protocol(class) local name = class.name local id = class.id assert(proto[name] == nil and proto[id] == nil) assert(type(name) == \u0026#34;string\u0026#34; and type(id) == \u0026#34;number\u0026#34; and id \u0026gt;=0 and id \u0026lt;=255) proto[name] = class proto[id] = class end do local REG = skynet.register_protocol REG { name = \u0026#34;lua\u0026#34;, id = skynet.PTYPE_LUA, pack = skynet.pack, unpack = skynet.unpack, } REG { name = \u0026#34;response\u0026#34;, id = skynet.PTYPE_RESPONSE, } REG { name = \u0026#34;error\u0026#34;, id = skynet.PTYPE_ERROR, unpack = function(...) return ... end, dispatch = _error_dispatch, } end 注册协议通过 register_protocol 来进行注册，传入的table中必须含有id 和 name，且不能和之前注册过的重复。\n由skynet自身注册协议中可以看到，对应一个类型来说，还需要处理对应类型的 序列化和反序列化函数，以及处理函数。\n消息回包 skynet.ret 和 skynet.response skynet.ret 和 skynet.response 都是对请求进行回包，但区别在于\nskynet.ret 传入msg 和 sz，直接就给来源服务回包，并且多次调用会产生异常 skynet.response 调用的时候会返回一个闭包f，之后通过这个闭包f进行回包，回包的时候传入的是需要回包的对象，f回自动进行序列化。这个函数的主要目的是为了函数处理的时候可能需要等待其他事件触发从而被挂起了，而等时机满足的时候，已经是其他coroutine了。 协程调度 skynet 协程挂起 外部协程在跑的过程中，可以使用 skynet.wait 或者 skynet.sleep 来挂起协程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 function skynet.wait(token) local session = c.genid() token = token or coroutine.running() suspend_sleep(session, token) -- 这边是挂起协程的入口 -- 到这边已经是协程恢复了，删除保存的索引 sleep_session[token] = nil session_id_coroutine[session] = nil end function skynet.sleep(ti, token) local session = c.intcommand(\u0026#34;TIMEOUT\u0026#34;,ti) assert(session) token = token or coroutine.running() local succ, ret = suspend_sleep(session, token) -- 这边是挂起协程的入口 -- 到这边已经是协程恢复了，删除保存的索引 sleep_session[token] = nil if succ then return end -- if ret == \u0026#34;BREAK\u0026#34; then return \u0026#34;BREAK\u0026#34; else error(ret) end end local function suspend_sleep(session, token) local tag = session_coroutine_tracetag[running_thread] -- 获取当前的tracetag，如果有的话，就输出当前协程的切换行为 if tag then c.trace(tag, \u0026#34;sleep\u0026#34;, 2) end session_id_coroutine[session] = running_thread -- 将session 和 协程绑定 assert(sleep_session[token] == nil, \u0026#34;token duplicative\u0026#34;) sleep_session[token] = session -- token 和session 绑定 return coroutine_yield \u0026#34;SUSPEND\u0026#34; -- 挂起协程 end skynet.sleep 和 skynet.wait 最后调用的都是 suspend_sleep 这个接口要求传入session 和 token，session 时调用接口的时候立即产生的。而token如果用户不指定的话则默认使用协程的地址作为token。 token的目的是用来索引到session的，而session用来索引到具体的协程。 suspend_sleep 最后调用 coroutine_yield 来完成协程挂起\ncoroutine_yield 直接就是lua原生的 coroutine.yield，那么挂起之后线程就会回到调用协程最开始的位置，这边探究的时候，先简单认为回到上面处理消息的位置\ncoroutine_resume 将 running_thread 设置成要运行的协程，然后调用原生的 cresume\nsuspend 协程挂起之后，下一步就变成调用 suspend 函数，相当于\n1 suspend(co, \u0026#34;SUSPEND\u0026#34;) 具体看看 suspend 处理了什么情况\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 function suspend(co, result, command) if not result then local session = session_coroutine_id[co] -- 错误处理，涉及到一些日志以及协程的关闭操作 ... error(tb) -- 引发trace end if command == \u0026#34;SUSPEND\u0026#34; then return dispatch_wakeup() elseif command == \u0026#34;QUIT\u0026#34; then coroutine.close(co) -- service exit return elseif command == \u0026#34;USER\u0026#34; then -- See skynet.coutine for detail error(\u0026#34;Call skynet.coroutine.yield out of skynet.coroutine.resume\\n\u0026#34; .. traceback(co)) elseif command == nil then -- debug trace return else error(\u0026#34;Unknown command : \u0026#34; .. command .. \u0026#34;\\n\u0026#34; .. traceback(co)) end end suspend 传入的参数分别是协程，协程是否执行成功，协程返回的内容。\n如果执行失败，则会对协程执行清理操作，输出日志等行为 如果返回的命令是 SUSPEND, 则调用 dispatch_wakeup，这个函数是用打断一些可被唤醒的协程这边会尽可能快速的唤醒 如果返回的命令是 QUIT，则执行清理操作 返回的其他任何命令也都是错误处理，不过值得注意的是 \u0026ldquo;USER\u0026rdquo; 的话，应该是在错误使用了skynet.coroutine的结果 消息推送 和 远程调用 这边主要分析 skynet.call 和 skynet.send 这两个API\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 function skynet.call(addr, typename, ...) local tag = session_coroutine_tracetag[running_thread] -- 是否开启trace监控 if tag then c.trace(tag, \u0026#34;call\u0026#34;, 2) c.send(addr, skynet.PTYPE_TRACE, 0, tag) end local p = proto[typename] local session = c.send(addr, p.id , nil , p.pack(...)) -- 用对应proto的pack对数据进行打包。然后调用c.send if session == nil then error(\u0026#34;call to invalid address \u0026#34; .. skynet.address(addr)) end return p.unpack(yield_call(addr, session)) -- 主动放弃协程控制权，等待对方回包。 end function skynet.send(addr, typename, ...) local p = proto[typename] return c.send(addr, p.id, 0 , p.pack(...)) end 可以很明显的看出，skynet.call 和 skynet.send 这两个API的区别就是在于是否会主动放弃当前协程的控制权\n小结 这边对常用API进行了一个源码层面的梳理，其实代码并不会特别复杂，只是上述代码都放在一个文件内，进行完整的梳理会比较容易绕晕。对这些代码进行梳理我认为主要还是更能明白代码是以什么方式执行的，出现BUG的时候也能更快速定位BUG以及确认BUG影响的范围。\n","date":"2024-08-16T00:00:00Z","image":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E5%8D%81%E4%BA%8C-skynetluaapi%E5%88%86%E6%9E%90/skynet_hu17557819904416107650.png","permalink":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E5%8D%81%E4%BA%8C-skynetluaapi%E5%88%86%E6%9E%90/","title":"Skynet源码阅读笔记(十二)-SkynetLuaApi分析"},{"content":"Bootstrap bootstrap是skynet默认初始化第一个执行的lua文件，上一遍在梳理snlua的过程中，知道了snlua是如何在初始化的时候执行到lua层的代码的，那接下来就看看在初始化时bootstrap具体的过程。\nbootstrap.lua 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 skynet.start(function() local launcher = assert(skynet.launch(\u0026#34;snlua\u0026#34;,\u0026#34;launcher\u0026#34;)) skynet.name(\u0026#34;.launcher\u0026#34;, launcher) local standalone = skynet.getenv \u0026#34;standalone\u0026#34; local harbor_id = tonumber(skynet.getenv \u0026#34;harbor\u0026#34; or 0) if harbor_id == 0 then -- 这边是单节点模式启动 assert(standalone == nil) standalone = true skynet.setenv(\u0026#34;standalone\u0026#34;, \u0026#34;true\u0026#34;) -- 用cdummy 来代替cslave local ok, slave = pcall(skynet.newservice, \u0026#34;cdummy\u0026#34;) if not ok then skynet.abort() end skynet.name(\u0026#34;.cslave\u0026#34;, slave) else -- 这边是多节点模式 if standalone then -- 如果standalone有配置，则需要启动cmaster if not pcall(skynet.newservice,\u0026#34;cmaster\u0026#34;) then skynet.abort() end end -- 无论什么类型，cslave一定都有 local ok, slave = pcall(skynet.newservice, \u0026#34;cslave\u0026#34;) if not ok then skynet.abort() end skynet.name(\u0026#34;.cslave\u0026#34;, slave) end -- 这边还需要给master节点启动datecenter if standalone then local datacenter = skynet.newservice \u0026#34;datacenterd\u0026#34; skynet.name(\u0026#34;DATACENTER\u0026#34;, datacenter) end skynet.newservice \u0026#34;service_mgr\u0026#34; .... -- 启动用户自定义的脚本 pcall(skynet.newservice,skynet.getenv \u0026#34;start\u0026#34; or \u0026#34;main\u0026#34;) skynet.exit() end) 先启动一个launcher的服务 bootstrap 根据配置中是否配置了 harbor 来分成两个模式 如果配置了没harbor，那么就一定是以单节点的方式启动，当前进程会额外启动一个cdummy的服务作为 cslave 如果配置了harbor，那么还需要根据配置判断standlalone来判断是否启动 cmaster 服务 和 datecenter 服务；配置了harbor的节点一定会启动 cslave 服务 无论什么模式，最后根据配置获取start 或者 main 脚本 来启动业务服务，然后本服务退出 cmaster / cslave cmaster / cslave 这边的源码就不具体分析了\ncmaster cmaster 和 cslave 在 https://github.com/cloudwu/skynet/wiki/Cluster 中也有介绍，主要是用来局域网内的多节点之间的一个使用方式\nmaster主要管理slave的节点信息，包括地址和名字等。主要的协议交互如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 --[[ master manage data : 1. all the slaves address : id -\u0026gt; ipaddr:port 2. all the global names : name -\u0026gt; address master hold connections from slaves . protocol slave-\u0026gt;master : package size 1 byte type 1 byte : \u0026#39;H\u0026#39; : HANDSHAKE, report slave id, and address. \u0026#39;R\u0026#39; : REGISTER name address \u0026#39;Q\u0026#39; : QUERY name protocol master-\u0026gt;slave: package size 1 byte type 1 byte : \u0026#39;W\u0026#39; : WAIT n \u0026#39;C\u0026#39; : CONNECT slave_id slave_address \u0026#39;N\u0026#39; : NAME globalname address \u0026#39;D\u0026#39; : DISCONNECT slave_id ]] master的启动过程如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 skynet.start(function() local master_addr = skynet.getenv \u0026#34;standalone\u0026#34; skynet.error(\u0026#34;master listen socket \u0026#34; .. tostring(master_addr)) local fd = socket.listen(master_addr) -- 监听对应端口 socket.start(fd , function(id, addr) -- 在连接进来的时候，执行这个函数 skynet.error(\u0026#34;connect from \u0026#34; .. addr .. \u0026#34; \u0026#34; .. id) socket.start(id) local ok, slave, slave_addr = pcall(handshake, id) -- 先进行handshake进行握手 if ok then skynet.fork(monitor_slave, slave, slave_addr) -- 成功了之后在创建协程 else -- 否则关闭连接 skynet.error(string.format(\u0026#34;disconnect fd = %d, error = %s\u0026#34;, id, slave)) socket.close(id) end end) end) master在启动的时候会通过监听 standalone 配置的地址来等待slave的注册信息。\nhandshake函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 local function handshake(fd) local t, slave_id, slave_addr = read_package(fd) assert(t==\u0026#39;H\u0026#39;, \u0026#34;Invalid handshake type \u0026#34; .. t) assert(slave_id ~= 0 , \u0026#34;Invalid slave id 0\u0026#34;) if slave_node[slave_id] then error(string.format(\u0026#34;Slave %d already register on %s\u0026#34;, slave_id, slave_node[slave_id].addr)) end report_slave(fd, slave_id, slave_addr) -- 这边会广播给其他slave slave_node[slave_id] = { -- 保存slave对应的数据 fd = fd, id = slave_id, addr = slave_addr, } return slave_id , slave_addr end 在slave连接上来之后，master首先会执行handshake与slave进行握手，并广播给当前的slave信息广播给其他slave节点。之后会创建一个单独的协程来执行 monitor_slave 与slave进行协议的交互。\nmonitor_slave 1 2 3 4 5 6 7 8 9 10 11 12 local function monitor_slave(slave_id, slave_address) local fd = slave_node[slave_id].fd skynet.error(string.format(\u0026#34;Harbor %d (fd=%d) report %s\u0026#34;, slave_id, fd, slave_address)) while pcall(dispatch_slave, fd) do end skynet.error(\u0026#34;slave \u0026#34; ..slave_id .. \u0026#34; is down\u0026#34;) local message = pack_package(\u0026#34;D\u0026#34;, slave_id) slave_node[slave_id].fd = 0 for k,v in pairs(slave_node) do socket.write(v.fd, message) end socket.close(fd) end monitor_slave 就是协程不停的调用dispatch_slave 来处理slave的消息，知道slave关闭为止。 而dispatch_slave中就是具体的协议处理了，这边就不继续展开了。\ncslave clave 就会稍微复杂一点了。\n在服务启动的时候，会通过配置先获取master的地址，并打开自己的端口进行的监听。 注册自身的dispatch消息处理函数，这个函数会尝试在harbor这个table中查找对应的函数并执行。同时创建一个harbor的service。 开始与master进行连接，连接上之后创建一个协程用来处理与master的数据交互 master连接之后会发送一个等待协议，让当前slave等待之前的N个slave与自己连接。当完成之后，创建slave的协程就退出。后面依赖第3步创建的协议与新的slave进行连接。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 skynet.start(function() -- 在服务启动的时候，会通过配置先获取master的地址，并打开自己的端口进行的监听。 local master_addr = skynet.getenv \u0026#34;master\u0026#34; local harbor_id = tonumber(skynet.getenv \u0026#34;harbor\u0026#34;) local slave_address = assert(skynet.getenv \u0026#34;address\u0026#34;) local slave_fd = socket.listen(slave_address) skynet.error(\u0026#34;slave connect to master \u0026#34; .. tostring(master_addr)) local master_fd = assert(socket.open(master_addr), \u0026#34;Can\u0026#39;t connect to master\u0026#34;) -- 注册自身的dispatch消息处理函数，这个函数会尝试在harbor这个table中查找对应的函数并执行。同时创建一个harbor的service。 skynet.dispatch(\u0026#34;lua\u0026#34;, function (_,_,command,...) local f = assert(harbor[command]) f(master_fd, ...) end) skynet.dispatch(\u0026#34;text\u0026#34;, monitor_harbor(master_fd)) harbor_service = assert(skynet.launch(\u0026#34;harbor\u0026#34;, harbor_id, skynet.self())) -- 开始与master进行连接，连接上之后创建一个协程用来处理与master的数据交互 local hs_message = pack_package(\u0026#34;H\u0026#34;, harbor_id, slave_address) socket.write(master_fd, hs_message) local t, n = read_package(master_fd) assert(t == \u0026#34;W\u0026#34; and type(n) == \u0026#34;number\u0026#34;, \u0026#34;slave shakehand failed\u0026#34;) skynet.error(string.format(\u0026#34;Waiting for %d harbors\u0026#34;, n)) skynet.fork(monitor_master, master_fd) -- master连接之后会发送一个等待协议，让当前slave等待之前的N个slave与自己连接。 if n \u0026gt; 0 then local co = coroutine.running() socket.start(slave_fd, function(fd, addr) skynet.error(string.format(\u0026#34;New connection (fd = %d, %s)\u0026#34;,fd, addr)) socketdriver.nodelay(fd) if pcall(accept_slave,fd) then local s = 0 for k,v in pairs(slaves) do s = s + 1 end if s \u0026gt;= n then skynet.wakeup(co) -- 全部完成了之后唤醒创建slave的协程 end end end) skynet.wait() --等待其他slave的连接 end -- 当完成之后，创建slave的协程就退出。后面依赖第3步创建的协议与新的slave进行连接。 socket.close(slave_fd) skynet.error(\u0026#34;Shakehand ready\u0026#34;) skynet.fork(ready) end) harbor服务 这个服务主要就是用来转发数据到slave中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 local skynet = require \u0026#34;skynet\u0026#34; local harbor = {} function harbor.globalname(name, handle) handle = handle or skynet.self() skynet.send(\u0026#34;.cslave\u0026#34;, \u0026#34;lua\u0026#34;, \u0026#34;REGISTER\u0026#34;, name, handle) end function harbor.queryname(name) return skynet.call(\u0026#34;.cslave\u0026#34;, \u0026#34;lua\u0026#34;, \u0026#34;QUERYNAME\u0026#34;, name) end function harbor.link(id) skynet.call(\u0026#34;.cslave\u0026#34;, \u0026#34;lua\u0026#34;, \u0026#34;LINK\u0026#34;, id) end function harbor.connect(id) skynet.call(\u0026#34;.cslave\u0026#34;, \u0026#34;lua\u0026#34;, \u0026#34;CONNECT\u0026#34;, id) end function harbor.linkmaster() skynet.call(\u0026#34;.cslave\u0026#34;, \u0026#34;lua\u0026#34;, \u0026#34;LINKMASTER\u0026#34;) end return harbor 可以看到就是包装了一层到slave的调用而已。\n小结 这边稍微探究了一下skynet bootstrap的启动过程中具体是做了什么，以及对应master/slave模式具体是干了什么事情。不过在代码里面可以看到很多skynet.xxx的调用。接下来就要具体看看skynet.lua中具体是如何处理消息的了。\n","date":"2024-08-13T00:00:00Z","image":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E5%8D%81%E4%B8%80-bootstrap-%E4%B8%8E-cmaster/cslave/skynet_hu17557819904416107650.png","permalink":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E5%8D%81%E4%B8%80-bootstrap-%E4%B8%8E-cmaster/cslave/","title":"Skynet源码阅读笔记(十一)-Bootstrap 与 cmaster/cslave"},{"content":"Skynet源码阅读笔记-Snlua服务 snlua 服务是 skynet 中重要的服务之一，其主要功能是为了创建一个执行lua代码的服务, skynet在默认情况下执行的第一个服务就是 snlua bootstrap\n先看看其主要的的数据结构\n1 2 3 4 5 6 7 8 9 struct snlua { lua_State * L; // lua 服务的主线程 struct skynet_context * ctx; // skynet服务的上下文 size_t mem; // 目前的内存使用 size_t mem_report; // 内存警报阈值 size_t mem_limit; // 内存使用上限 lua_State * activeL; // 当前的活跃的lua 线程 ATOM_INT trap; // 标记设置signal_hook }; 之前在skynet_module中曾经提到过，创建一个新的服务时，对应的服务需要实现4个函数，用于初始化和释放\n1 2 3 4 5 6 7 8 struct skynet_module { const char * name; // 名字 void * module; // module的地址 skynet_dl_create create; // 创建module实例执行的函数 skynet_dl_init init; // 初始化module执行的函数 skynet_dl_release release; // 释放module执行函数 skynet_dl_signal signal; // module信号执行函数 }; 当skynet在初始化的时候，执行的第一个snlua的服务是snlua bootstrap, 以这个为例子看看snlua中对应的函数是如何实现的。\nsnlua_create 1 2 3 4 5 6 7 8 9 10 11 struct snlua * snlua_create(void) { struct snlua * l = skynet_malloc(sizeof(*l)); memset(l,0,sizeof(*l)); l-\u0026gt;mem_report = MEMORY_WARNING_REPORT; l-\u0026gt;mem_limit = 0; l-\u0026gt;L = lua_newstate(lalloc, l); l-\u0026gt;activeL = NULL; ATOM_INIT(\u0026amp;l-\u0026gt;trap , 0); return l; } snlua的创建函数，可以只是对上述属性进行一个简单的初始化操作，可以注意到在lua_newstate的时候传入了一个lalloc, 在这边对lua内存分配做了一个自定义的行为。\nlalloc 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 static void * lalloc(void * ud, void *ptr, size_t osize, size_t nsize) { struct snlua *l = ud; size_t mem = l-\u0026gt;mem; l-\u0026gt;mem += nsize; if (ptr) l-\u0026gt;mem -= osize; if (l-\u0026gt;mem_limit != 0 \u0026amp;\u0026amp; l-\u0026gt;mem \u0026gt; l-\u0026gt;mem_limit) { if (ptr == NULL || nsize \u0026gt; osize) { l-\u0026gt;mem = mem; return NULL; } } if (l-\u0026gt;mem \u0026gt; l-\u0026gt;mem_report) { l-\u0026gt;mem_report *= 2; skynet_error(l-\u0026gt;ctx, \u0026#34;Memory warning %.2f M\u0026#34;, (float)l-\u0026gt;mem / (1024 * 1024)); } return skynet_lalloc(ptr, osize, nsize); } lalloc 中主要干了两件事情\n对内存的分配进行了监控，超过一定限制会输出日志报警 调用skynet_lalloc来实际分配内存，这边先不展开，不过skynet_lalloc中使用的是jemalloc来对内存进行分配。 snlua_init 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 int snlua_init(struct snlua *l, struct skynet_context *ctx, const char * args) { // 先把参数拷贝出来 int sz = strlen(args); char * tmp = skynet_malloc(sz); memcpy(tmp, args, sz); // args 这边是bootstrap skynet_callback(ctx, l, launch_cb); // 设置消息回调的接口和userData，这边设置进行去的ud是 l // 调用REG 来获取handle_id const char * self = skynet_command(ctx, \u0026#34;REG\u0026#34;, NULL); uint32_t handle_id = strtoul(self+1, NULL, 16); // it must be first message skynet_send(ctx, 0, handle_id, PTYPE_TAG_DONTCOPY,0, tmp, sz); // 通过给自己发送一条消息的方式来触发后续的初始化操作 return 0; } init流程看似也很简单，但实际上是为了调用skynet_send来给自己发送一条消息，用消息回调的方式来触发剩余的初始化操作。 不过为啥要用回调的方式以及为啥这个消息必须是第一条，我目前没有理解。\nlaunch_cb 消息回调的时候首先调用的是launch_cb，在init的时候已经通过skynet_callback将ud和launch_cb设置到消息回调中了\n1 2 3 4 5 6 7 8 9 10 11 12 static int launch_cb(struct skynet_context * context, void *ud, int type, int session, uint32_t source , const void * msg, size_t sz) { assert(type == 0 \u0026amp;\u0026amp; session == 0); struct snlua *l = ud; skynet_callback(context, NULL, NULL); // 这边又将回调的接口给重置了 int err = init_cb(l, context, msg, sz); // 真正的初始化位置 if (err) { skynet_command(context, \u0026#34;EXIT\u0026#34;, NULL); } return 0; } launch_cb 也只是用来包装调用init_cb，自身只是处理了如果init_cb出错了，就调用EXIT指令卸载掉当前的服务\ninit_cb init_cb 中就是初始化snlua服务的主要流程了，主要是 hook一些协程接口、处理路径相关、加载执行lua文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 static int init_cb(struct snlua *l, struct skynet_context *ctx, const char * args, size_t sz) { lua_State *L = l-\u0026gt;L; l-\u0026gt;ctx = ctx; lua_gc(L, LUA_GCSTOP, 0); // GC STOP lua_pushboolean(L, 1); /* signal for libraries to ignore env. vars. */ lua_setfield(L, LUA_REGISTRYINDEX, \u0026#34;LUA_NOENV\u0026#34;); // 跳过LUA_PATH和LUA_CPATH luaL_openlibs(L); luaL_requiref(L, \u0026#34;skynet.profile\u0026#34;, init_profile, 0); // require skynet profile // hook coroutine相关接口, 相当于下面的lua代码 // replace coroutine.resume / coroutine.wrap // coroutine[resume] = profile_lib[resume] // coroutine[wrap] = profile_lib[wrap] ... // 相当于 LUA_REGISTRYINDEX[skynet_context] = ctx lua_getglobal(L, \u0026#34;coroutine\u0026#34;); lua_getfield(L, profile_lib, \u0026#34;resume\u0026#34;); lua_setfield(L, -2, \u0026#34;resume\u0026#34;); lua_getfield(L, profile_lib, \u0026#34;wrap\u0026#34;); lua_setfield(L, -2, \u0026#34;wrap\u0026#34;); ... // 设置路径，如果配置有提供lua_path、lua_cpath、luaservice 则使用配置的， 否则使用默认的 const char *path = optstring(ctx, \u0026#34;lua_path\u0026#34;,\u0026#34;./lualib/?.lua;./lualib/?/init.lua\u0026#34;); .... // 加载lua loader， lua_pushcfunction(L, traceback); assert(lua_gettop(L) == 1); const char * loader = optstring(ctx, \u0026#34;lualoader\u0026#34;, \u0026#34;./lualib/loader.lua\u0026#34;); int r = luaL_loadfile(L,loader); if (r != LUA_OK) { skynet_error(ctx, \u0026#34;Can\u0026#39;t load %s : %s\u0026#34;, loader, lua_tostring(L, -1)); report_launcher_error(ctx); return 1; } // pcall 调用 如果报错了，则把错误信息打印出来 // 这边一开始的args应该是 bootstrap lua_pushlstring(L, args, sz); r = lua_pcall(L,1,0,1); if (r != LUA_OK) { skynet_error(ctx, \u0026#34;lua loader error : %s\u0026#34;, lua_tostring(L, -1)); report_launcher_error(ctx); return 1; } // 如果 LUA_REGISTRYINDEX[memlimit] 有被设置的话， 则更新mem_limit if (lua_getfield(L, LUA_REGISTRYINDEX, \u0026#34;memlimit\u0026#34;) == LUA_TNUMBER) { ... } lua_gc(L, LUA_GCRESTART, 0); return 0; } init_cb 里面主要是使用了很多Lua的C API来执行了一系列操作，分为一下几个步骤\n替换掉系统的coroutine相关的操作 将ctx设置到全局变量中，以便C 和 lua更好的交互 设置require的路径 加载 loader.lua 调用 loader.lua args 。这边的args 内容最开始是 bootstrap.lua 设置 memlimit 这边目前更关心 loader.lua bootstap 这个调用的过程\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 -- skynet.loader.lua -- 其他更多是在处理配置路径相关的事情 -- main = load(bootstap.lua) snlua初始化的时候执行的是这个语句 ... -- 如果定义了LUA_PRELOAD，那么就先加载对应文件 if LUA_PRELOAD then local f = assert(loadfile(LUA_PRELOAD)) f(table.unpack(args)) LUA_PRELOAD = nil end _G.require = (require \u0026#34;skynet.require\u0026#34;).require -- skynet.require 后续新开一个文档研究，这边可以认为是对于协程并行的一些处理，如果没有使用协程，那么这边就是普通的require main(select(2, table.unpack(args))) -- 这边就是执行服务的函数，main 对应的函数就是loadfile进来的 loader.lua 中大部分都是处理服务路径相关的事情，需要注意的就是如果定义了LUA_PRELOAD，那么就会提前加载对应的模块。 顺便再提一嘴，main函数是通过 loadfile(targeServiceFile) 的结果。\n这边args再初始化加载的时候应该只有{bootstap}，所以main执行的时候是没有参数的。\ninit的流程先到此为止，这边知道skynet snlua服务会在init_cb的时候通过loadfile的方式将lua服务加载进来就行了。\n之后具体的bootstrap流程还会具体在分析。这边先告一段落。\n后续看看snlua的另外几个操作\nsnlua_signal singla接口主要是为了能让其他线程给snlua服务在跑的过程发送一些信号，以达到一些自定义的需求。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 void snlua_signal(struct snlua *l, int signal) { skynet_error(l-\u0026gt;ctx, \u0026#34;recv a signal %d\u0026#34;, signal); if (signal == 0) { if (ATOM_LOAD(\u0026amp;l-\u0026gt;trap) == 0) { // only one thread can set trap ( l-\u0026gt;trap 0-\u0026gt;1 ) if (!ATOM_CAS(\u0026amp;l-\u0026gt;trap, 0, 1)) return; lua_sethook (l-\u0026gt;activeL, signal_hook, LUA_MASKCOUNT, 1); -- 相当于debug.sethook(signal_hook, \u0026#34;count\u0026#34;, 1) // finish set ( l-\u0026gt;trap 1 -\u0026gt; -1 ) ATOM_CAS(\u0026amp;l-\u0026gt;trap, 1, -1); -- 设置成功了就将trap 设置成-1 } } else if (signal == 1) { skynet_error(l-\u0026gt;ctx, \u0026#34;Current Memory %.3fK\u0026#34;, (float)l-\u0026gt;mem / 1024); } } snlua_signal目前只处理了两个信号事件\n当信号为1的时候，snlua会输出当前的内存使用 当新号为0的时候，会执行 相当于 相当于debug.sethook(signal_hook, \u0026ldquo;count\u0026rdquo;, 1)的 语句， 1 2 3 4 5 6 7 8 9 10 11 12 static void signal_hook(lua_State *L, lua_Debug *ar) { void *ud = NULL; lua_getallocf(L, \u0026amp;ud); struct snlua *l = (struct snlua *)ud; lua_sethook (L, NULL, 0, 0); if (ATOM_LOAD(\u0026amp;l-\u0026gt;trap)) { ATOM_STORE(\u0026amp;l-\u0026gt;trap , 0); -- 走到这边说明必定触发，则先将trap设置会0 luaL_error(L, \u0026#34;signal 0\u0026#34;); -- 抛出异常 } } 这个signal_hook在执行的时候就会将hook解除，并立即抛出异常。\n还记得在分析线程作用的一章里，有谈到过关于死循环检查的事情吗，当在日志中发现存在死循环后，可以通过给snlua服务发送信号0的方式来打断它的执行，从而跳出死循环。\nsnlua_release 1 2 3 4 5 void snlua_release(struct snlua *l) { lua_close(l-\u0026gt;L); skynet_free(l); } snlua_release 这边就很简单了，关闭lua的虚拟机、释放对应的内存即可\n小结 这边主要过了一下snlua服务中4个主要函数的大致实现。其中比较重要的就是初始化的过程和信号处理的过程。唯一还没理解的地方就是为啥snlua服务需要通过给自己发信息的方式来触发初始化过程。 snlua在init_cb的时候，代码就来到了lua层，后面就准备分析一些bootstrap.lua中做了什么事情。 其实snlua这边还有很大篇幅是有关协程调度的（只是hook了调度函数，用来做profile和信号打断的），在源码中定义在init_profile函数里，有机会在分析这块内容。\n","date":"2024-08-10T00:00:00Z","image":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E5%8D%81-snlua-%E6%9C%8D%E5%8A%A1/skynet_hu17557819904416107650.png","permalink":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E5%8D%81-snlua-%E6%9C%8D%E5%8A%A1/","title":"Skynet源码阅读笔记(十)- Snlua 服务"},{"content":"Skynet源码阅读笔记(八)-skynet的线程类型 skynet中的线程类型可以分为一下几种类型\n主线程 worker 线程 timer 线程 monitor 线程 socket 线程 这些线程的初始化都在start函数里，由主线程驱动\nsocket线程 从start函数中进入，可以看到初始化socket线程执行的是thread_socket函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 static void * thread_socket(void *p) { struct monitor * m = p; skynet_initthread(THREAD_SOCKET); for (;;) { int r = skynet_socket_poll(); if (r==0) break; if (r\u0026lt;0) { CHECK_ABORT continue; } wakeup(m,0); } return NULL; } int skynet_socket_poll() { struct socket_server *ss = SOCKET_SERVER; assert(ss); struct socket_message result; int more = 1; int type = socket_server_poll(ss, \u0026amp;result, \u0026amp;more); switch (type) { case SOCKET_EXIT: return 0; .......... default: skynet_error(NULL, \u0026#34;Unknown socket message type %d.\u0026#34;,type); return -1; } if (more) { return -1; } return 1; } 这边可以看出现线程一直执行的是skynet_socket_poll，而对于返回值r，正常关机执行时返回0；出现异常返回小于0；其他情况则尝试唤醒睡眠的work进程，这边唤醒睡眠线程的条件是当所有work线程都在睡眠的时候。\nskynet_socket_poll 中则是对 socket_server_poll 的包装调用，根绝socket_server_poll返回的type执行对应操作。\nsocket_server 在具体看 socket_server_poll 之前，先看看 socket_server 这个数据结构。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 struct socket_server { volatile uint64_t time; // 创建socket_server的时间 int reserve_fd;\t// 为了处理accept返回emfile错误码造成的问题 int recvctrl_fd; // 管道的读端 int sendctrl_fd; // 管道的写端 int checkctrl; // 是否需要检查管道命令 poll_fd event_fd; // epoll的fd ATOM_INT alloc_id;\t// 下一个socket的ID，多个线程都有可能同时调用，所以是一个原子类型 int event_n;\t// epoll_wait返回的事件数量 int event_index; // 当前处理的epoll事件index struct socket_object_interface soi;\t// 能够让数据自定义使用buffer的构造和释放 struct event ev[MAX_EVENT];\t// 对epoll_event 的一个封装 struct socket slot[MAX_SOCKET];\t// skynet包装的socket对象，因为是个数组，所以分配内存的时候直接分配好了 char buffer[MAX_INFO];\t// 在TCP环境下通用的临时缓冲区 uint8_t udpbuffer[MAX_UDP_PACKAGE];\t// 在UDP环境下通用的临时缓冲区 fd_set rfds;\t// 用于select，主要就是判断recvctrl_fd是否有事件 }; socket_server 结构就是整个socket 服务的核心了。 从结构上看它包装了对epoll使用和对socket的读写。接下来看看初始化它的时候做了些什么操作\nsocket_server的初始化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 void skynet_socket_init() { SOCKET_SERVER = socket_server_create(skynet_now()); } struct socket_server * socket_server_create(uint64_t time) { int i; int fd[2]; poll_fd efd = sp_create(); // 这个函数包装了对epoll_create的调用 .... // efd的异常处理 if (pipe(fd)) { ... // 失败的异常处理 } if (sp_add(efd, fd[0], NULL)) // 这边把读端放入到了epoll中, sp_add看起来只有LT模式 ... // 失败的异常处理 } struct socket_server *ss = MALLOC(sizeof(*ss)); ss-\u0026gt;time = time; // 设置了socket的启动时间 ss-\u0026gt;event_fd = efd; ss-\u0026gt;recvctrl_fd = fd[0]; ss-\u0026gt;sendctrl_fd = fd[1]; ss-\u0026gt;checkctrl = 1;\t// 主要是为了处理accpet的时候，fd不够导致无法关闭连接的情况 // https://stackoverflow.com/questions/47179793/how-to-gracefully-handle-accept-giving-emfile-and-close-the-connection ss-\u0026gt;reserve_fd = dup(1);\t// reserve an extra fd for EMFILE for (i=0;i\u0026lt;MAX_SOCKET;i++) { // 初始化socket数组内的所有socket struct socket *s = \u0026amp;ss-\u0026gt;slot[i]; ATOM_INIT(\u0026amp;s-\u0026gt;type, SOCKET_TYPE_INVALID); ... } // 初始化剩下的变量 ATOM_INIT(\u0026amp;ss-\u0026gt;alloc_id , 0); ss-\u0026gt;event_n = 0; ss-\u0026gt;event_index = 0; memset(\u0026amp;ss-\u0026gt;soi, 0, sizeof(ss-\u0026gt;soi)); FD_ZERO(\u0026amp;ss-\u0026gt;rfds); assert(ss-\u0026gt;recvctrl_fd \u0026lt; FD_SETSIZE); return ss; } skynet_socket_init 是在skynet_start中被调用的，初始化操作中并没有做什么特殊的操作，基本上可以认为是内存的申请和对数据的清空操作，只有reserve_fd是被预留处理特殊情况的时候使用。\n当在lua中调用了listen 在skynet中，提供了lua 层调用socket的方法，实现在 lua-socket.c 中，lua可以require socket后进行调用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 -- lua local socket = require \u0026#34;skynet.socket\u0026#34; local id = socket.listen(\u0026#34;0.0.0.0\u0026#34;, 8001) // c static int llisten(lua_State *L) { // 获取lua的对象，然后获取其中的数据 const char * host = luaL_checkstring(L,1); int port = luaL_checkinteger(L,2); int backlog = luaL_optinteger(L,3,BACKLOG); struct skynet_context * ctx = lua_touserdata(L, lua_upvalueindex(1)); // 调用真正的listen函数 int id = skynet_socket_listen(ctx, host,port,backlog); if (id \u0026lt; 0) { return luaL_error(L, \u0026#34;Listen error\u0026#34;); } // 把结果在还给lua lua_pushinteger(L,id); return 1; } 以 listen 为例子，当lua脚本中调用了 socket.listen，那么相当于在C中调用了 skynet_socket_listen\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 int skynet_socket_listen(struct skynet_context *ctx, const char *host, int port, int backlog) { uint32_t source = skynet_context_handle(ctx); // 获取对应context的handle return socket_server_listen(SOCKET_SERVER, source, host, port, backlog); } int socket_server_listen(struct socket_server *ss, uintptr_t opaque, const char * addr, int port, int backlog) { int fd = do_listen(addr, port, backlog); // 函数包装了完整的的从socket的创建到listen结束， socket有设置 SO_REUSEADDR if (fd \u0026lt; 0) { return -1; } struct request_package request; int id = reserve_id(ss); // 分配socket_server 的 socket对象的数组下标 if (id \u0026lt; 0) { close(fd); return id; } // 包装消息 request.u.listen.opaque = opaque; // 这个字段被赋值成了对应服务的handle request.u.listen.id = id; // 这个字段被赋值成了socket_server 的 socket对象的数组下标 request.u.listen.fd = fd;\t// 这个字段被赋值成了真正的socket fd send_request(ss, \u0026amp;request, \u0026#39;L\u0026#39;, sizeof(request.u.listen)); //发送消息给socket_server return id; } static int reserve_id(struct socket_server *ss) { int i; for (i=0;i\u0026lt;MAX_SOCKET;i++) { // 原子的加减分配id，保证落在int范围内， int id = ATOM_FINC(\u0026amp;(ss-\u0026gt;alloc_id))+1; if (id \u0026lt; 0) { id = ATOM_FAND(\u0026amp;(ss-\u0026gt;alloc_id), 0x7fffffff) \u0026amp; 0x7fffffff; } struct socket *s = \u0026amp;ss-\u0026gt;slot[HASH_ID(id)]; int type_invalid = ATOM_LOAD(\u0026amp;s-\u0026gt;type); if (type_invalid == SOCKET_TYPE_INVALID) { // 未使用的socket类型就是 SOCKET_TYPE_INVALID // 分配出去的就在这边修改成保留的类型 if (ATOM_CAS(\u0026amp;s-\u0026gt;type, type_invalid, SOCKET_TYPE_RESERVE)) { // 初始化使用的socket的数据 s-\u0026gt;id = id; s-\u0026gt;protocol = PROTOCOL_UNKNOWN; // socket_server_udp_connect may inc s-\u0026gt;udpconncting directly (from other thread, before new_fd), // so reset it to 0 here rather than in new_fd. ATOM_INIT(\u0026amp;s-\u0026gt;udpconnecting, 0); s-\u0026gt;fd = -1; return id; } else { // retry --i; } } } return -1; } 当在lua中调用了listen后，做的事实际上是调用线程自行申请fd，然后去申请 socket_server 包装的socket对象，打包好之后通过send_request发送给socket_server。 不过我有点疑惑的是，为什么在申请 socket_server 包装的socket对象的时候不用uint？这样就不用处理溢出情况了\nsend_request 先看看 request_package 是如何包装消息的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 struct request_package { uint8_t header[8];\t// 6 bytes dummy union { char buffer[256]; struct request_open open; struct request_send send; struct request_send_udp send_udp; struct request_close close; struct request_listen listen; struct request_bind bind; struct request_resumepause resumepause; struct request_setopt setopt; struct request_udp udp; struct request_setudp set_udp; } u; // 每种消息类型都是一个结构体，用union 包起来 uint8_t dummy[256]; }; struct request_listen { int id; int fd; uintptr_t opaque; char host[1]; }; request_package的union包含了所有请求类型的消息体，其中的buffer[256]表明消息类型最大是256个字节。 这边我疑惑的是request_package 中前6个字节和后256字节都标记成了dummy, 暂时不确定这些占位字节的意义，可能是用来留做扩展？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 static void send_request(struct socket_server *ss, struct request_package *request, char type, int len) { request-\u0026gt;header[6] = (uint8_t)type; request-\u0026gt;header[7] = (uint8_t)len; const char * req = (const char *)request + offsetof(struct request_package, header[6]); for (;;) { ssize_t n = write(ss-\u0026gt;sendctrl_fd, req, len+2); if (n\u0026lt;0) { if (errno != EINTR) { skynet_error(NULL, \u0026#34;socket-server : send ctrl command error %s.\u0026#34;, strerror(errno)); } continue; } assert(n == len+2); return; } } 以 request_listen 为例子，在socket_server_listen中是直接对局部变量的request中u进行赋值即可，在真正调用发送函数send_request的时候，传入的就是统一的结构体。把每个协议具体细节屏蔽了。不过在发送的时候，需要传入request具体的长度。这个就需要在每个协议发送前自己算出来了\n在这边可以看到send_request的前6个字节是直接跳过的，然后len的类型也是被强制转成uint8了，所以一个request_message的最大程度也只能是256。\n同时还需要注意到这边写入的处理实际上是必须要保证完全写入的，对于非阻塞的管道，write操作必须阻塞到所有数据都完全写入到管道中。\nIf a process attempts to read from an empty pipe, then read(2) will block until data is available. If a process attempts to write to a full pipe (see below), then write(2) blocks until sufficient data has been read from the pipe to allow the write to complete.\n在调用write的时候，如果进程收到信号的话，那么就有可能会触发EINTR 打断正在执行的系统调用。而且这边时在完全没有写入数据之前才会出现EINTR错误。\nIf a blocked call to one of the following interfaces is interrupted by a signal handler, then the call is automatically restarted after the signal handler returns if the SA_RESTART flag was used; otherwise the call fails with the error EINTR: read(2), readv(2), write(2), writev(2), and ioctl(2) calls on \u0026ldquo;slow\u0026rdquo; devices. A \u0026ldquo;slow\u0026rdquo; device is one where the I/O call may block for an indefinite time, for example, a terminal, pipe, or socket. If an I/O call on a slow device has already transferred some data by the time it is interrupted by a signal handler, then the call will return a success status(normally, the number of bytes transferred). Note that a (local) disk is not a slow device according to this definition; I/O operations on disk devices are not interrupted by signals.\nsocket 处理管道消息 worker线程把数据发送到管道以后，接下来的事情就得看socket线程的了。在最开始的时候说过 socket线程一直执行的是socket_server_poll函数，那就先看看socket_server_poll 函数大致执行的内容是怎么样的。\n1 2 3 4 5 6 7 8 9 10 11 12 int socket_server_poll(struct socket_server *ss, struct socket_message * result, int * more) { for (;;) { if (ss-\u0026gt;checkctrl) { ... // 检查是否有管道消息，并进行处理 } if (ss-\u0026gt;event_index == ss-\u0026gt;event_n) { ... // epoll 的消息处理完毕了，那就重新进入epoll_wait } ... // 处理 ss-\u0026gt;event_index++ 对应的epoll消息\t} } socket_server_poll 主要分成三个部分：\n检查是否有管道传入的消息 如果没有更多的消息需要执行，则执行epoll_wait 如果有还没有处理完毕的消息，则继续处理 在初始化的时候，管道的读端就被塞入到了epoll中。当管道可读的时候，就会通过从epoll_wait中读取出来。\n把 关于管道的部分展开\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 for (;;) { if (ss-\u0026gt;checkctrl) { // 判断是否存在检查管道标记 if (has_cmd(ss)) { //检查管道是否可读, int type = ctrl_cmd(ss, result); // 处理管道消息 if (type != -1) { clear_closed_event(ss, result, type); return type; } else continue; } else { ss-\u0026gt;checkctrl = 0; // } } if (ss-\u0026gt;event_index == ss-\u0026gt;event_n) { ss-\u0026gt;event_n = sp_wait(ss-\u0026gt;event_fd, ss-\u0026gt;ev, MAX_EVENT); // 阻塞epoll_wait等待可操作的事件 ss-\u0026gt;checkctrl = 1; //是否检查管道的标记 if (more) { *more = 0; } ss-\u0026gt;event_index = 0; //处理epoll事件的下标重置成0 if (ss-\u0026gt;event_n \u0026lt;= 0) { ... // 错误处理 continue; } } struct event *e = \u0026amp;ss-\u0026gt;ev[ss-\u0026gt;event_index++]; struct socket *s = e-\u0026gt;s; if (s == NULL) { // dispatch pipe message at beginning continue; } ... // 处理 ss-\u0026gt;event_index++ 对应的epoll消息\t} 由这部分可以知道：\n每次socket线程在从epoll_wait中返回之后，都会标记检查命令管道。 在处理返回的事件时，如果事件的socket是空的，则说明是管道的消息可读。 for循环开始的时候判断 checkctrl ，这个变量只会在 初始化和epoll返回的时候被设置, 所以一次处理事件处理的时候，会优先把这次事件的所有管道消息给处理掉 而 ctrl_cmd 才是处理命令的核心, 具体看一下代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 static int ctrl_cmd(struct socket_server *ss, struct socket_message *result) { int fd = ss-\u0026gt;recvctrl_fd; // the length of message is one byte, so 256 buffer size is enough. uint8_t buffer[256]; uint8_t header[2]; block_readpipe(fd, header, sizeof(header)); int type = header[0]; int len = header[1]; block_readpipe(fd, buffer, len); // ctrl command only exist in local fd, so don\u0026#39;t worry about endian. switch (type) { ... case \u0026#39;L\u0026#39;: return listen_socket(ss,(struct request_listen *)buffer, result); ... default: skynet_error(NULL, \u0026#34;socket-server: Unknown ctrl %c.\u0026#34;,type); return -1; }; return -1; } static int listen_socket(struct socket_server *ss, struct request_listen * request, struct socket_message *result) { int id = request-\u0026gt;id; int listen_fd = request-\u0026gt;fd; struct socket *s = new_fd(ss, id, listen_fd, PROTOCOL_TCP, request-\u0026gt;opaque, false); if (s == NULL) { goto _failed; } ATOM_STORE(\u0026amp;s-\u0026gt;type , SOCKET_TYPE_PLISTEN); result-\u0026gt;opaque = request-\u0026gt;opaque; result-\u0026gt;id = id; result-\u0026gt;ud = 0; result-\u0026gt;data = \u0026#34;listen\u0026#34;; .... return SOCKET_OPEN; _failed: ... // 错误处理 return SOCKET_ERR; } ctrl_cmd 中会从管道中读取出对应的header 和 body。之前分析过，管道的写入一定是完整的数据，不会存在一半的数据，所以管道读端也可以不用处理一半的包的情况。 这边先读取固定2字节的header，也就是type 和 len， 再根据len 去读取具体的数据到buffer中。\n数据包重装完毕之后，会根据类型转成把buffer强转成对应类型的数据丢入到具体的处理函数当中。\n还是以listen 为例子，这边收到的类型是 \u0026lsquo;L\u0026rsquo;, 具体的处理函数是listen_socket。listen_socket中主要就是把request中的fd 和 socket_server 中的一个fd关联起来。这边可以注意到一个事情，关联完毕之后，还对result进行了一些操作。\n顺着这result去看，我们可以找到在传入 socket_server_poll 的时候，reuslt就是一个指针。所以result会被还给带调用 socket_server_poll 的位置， 也就是 skynet_socket_poll。\n所以这边可以理解成socket处理完对应消息后，会对管道消息进行回包。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 int skynet_socket_poll() { struct socket_server *ss = SOCKET_SERVER; assert(ss); struct socket_message result; int more = 1; int type = socket_server_poll(ss, \u0026amp;result, \u0026amp;more); switch (type) { ...... case SOCKET_OPEN: forward_message(SKYNET_SOCKET_TYPE_CONNECT, true, \u0026amp;result); break; ...... default: skynet_error(NULL, \u0026#34;Unknown socket message type %d.\u0026#34;,type); return -1; } if (more) { return -1; } return 1; } 回到 skynet_socket_poll ，我们可以看到这边处理了 listen_socket 返回的 SOCKET_OPEN，然后把处理过的result传入到 forward_message\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // mainloop thread static void forward_message(int type, bool padding, struct socket_message * result) { struct skynet_socket_message *sm; size_t sz = sizeof(*sm); if (padding) { .... //填充字节 } sm = (struct skynet_socket_message *)skynet_malloc(sz); sm-\u0026gt;type = type; sm-\u0026gt;id = result-\u0026gt;id; sm-\u0026gt;ud = result-\u0026gt;ud; ...... struct skynet_message message; message.source = 0; message.session = 0; message.data = sm; message.sz = sz | ((size_t)PTYPE_SOCKET \u0026lt;\u0026lt; MESSAGE_TYPE_SHIFT); if (skynet_context_push((uint32_t)result-\u0026gt;opaque, \u0026amp;message)) { // 处理失败错误 } } forward_message 内容不多，就是把reuslt的结果包装成 skynet_message，然后通过skynet_context_push传入到对应的skynet_context进行处理，还记得一开始opaque吗？它在最开始调用 socket_server_listen 的时候，就被赋值成了调用函数的服务的handle了。 同时在new_fd的时候，这个opaque也会被写入到包装的socket中，后面有socket 收到的消息时，就可以找到对应handle进行分发了。\n总结 skynet_socket_poll是由socket线程不断调用处理的，skynet_socket_poll 上由是通过socket_server_poll处理网络数据的，处理完毕之后通过对应的type 和 result 来将结果进行分发到对应skynet_context来进行处理。\n这边只简单以 listen 行为把skynet底层的网络模型进行了分析，实际上收发包的内容也是相当重要的，后面有空可以了可以再写一篇详细分析一下其中的内容\n","date":"2024-04-16T00:00:00Z","image":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E5%85%AB-skynet%E7%9A%84%E7%BA%BF%E7%A8%8B%E7%B1%BB%E5%9E%8B%E4%B8%89/skynet_hu17557819904416107650.png","permalink":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E5%85%AB-skynet%E7%9A%84%E7%BA%BF%E7%A8%8B%E7%B1%BB%E5%9E%8B%E4%B8%89/","title":"Skynet源码阅读笔记(八)-skynet的线程类型（三）"},{"content":"Skynet源码阅读笔记(七)-skynet的线程类型 skynet中的线程类型可以分为一下几种类型\n主线程 worker 线程 timer 线程 monitor 线程 socket 线程 这些线程的初始化都在start函数里，由主线程驱动\ntiemr线程 从start函数中进入，可以看到初始化timer线程的时候的使用了thread_timer。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #define CHECK_ABORT if (skynet_context_total()==0) break; static void * thread_timer(void *p) { struct monitor * m = p; skynet_initthread(THREAD_TIMER); for (;;) { skynet_updatetime(); // 更新定时器相关 skynet_socket_updatetime(); // 更新Socket 的时间， CHECK_ABORT wakeup(m,m-\u0026gt;count-1); // 唤醒睡眠线程 usleep(2500); if (SIG) { signal_hup(); // 如果接收到 SIGHUP 新号，则输出日志 SIG = 0; } } // wakeup socket thread skynet_socket_exit(); // 唤醒socket 线程 // wakeup all worker thread //唤醒所有worker线程 pthread_mutex_lock(\u0026amp;m-\u0026gt;mutex); m-\u0026gt;quit = 1; //work循环条件就是!quit pthread_cond_broadcast(\u0026amp;m-\u0026gt;cond); pthread_mutex_unlock(\u0026amp;m-\u0026gt;mutex); return NULL; } socket部分先跳过，主要是因为还没探索过，不确定里面再做啥。\n从thread_timer 中可以看出，timer线程主要工作就是每2500微秒（2.5ms）定时调用 skynet_updatetime。当CHECK_ABORT检测执行到服务都退出了以后，timer才会跳出循环。 跳出循环后，还会唤醒socker和worker线程，让他们也执行退出流程。\ntimer 相关数据结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #define TIME_NEAR_SHIFT 8 #define TIME_NEAR (1 \u0026lt;\u0026lt; TIME_NEAR_SHIFT) #define TIME_LEVEL_SHIFT 6 #define TIME_LEVEL (1 \u0026lt;\u0026lt; TIME_LEVEL_SHIFT) #define TIME_NEAR_MASK (TIME_NEAR-1) #define TIME_LEVEL_MASK (TIME_LEVEL-1) struct timer_event { uint32_t handle; int session; }; struct timer_node { struct timer_node *next; uint32_t expire; }; struct link_list { struct timer_node head; struct timer_node *tail; }; struct timer { struct link_list near[TIME_NEAR]; // 这边是 2 ^ 8 个，是最小的时间轮 struct link_list t[4][TIME_LEVEL]; // 0 位置的每个都是 2^8的轮， 数组1上每个都是2^16, 依次类推 struct spinlock lock; uint32_t time; uint32_t starttime; //开服时间 uint64_t current; //当前时间 uint64_t current_point; }; static struct timer * TI = NULL; static inline struct timer_node * link_clear(struct link_list *list) { struct timer_node * ret = list-\u0026gt;head.next; list-\u0026gt;head.next = 0; list-\u0026gt;tail = \u0026amp;(list-\u0026gt;head); return ret; } skynet的定时器算法是时间轮，near是最近256个时间轮单位，每跑完256个单位才会更新一次时间轮。而t 可以认为是粒度更大的时间轮。 t0 上的每个元素的粒度都是2 ^ 8，一共TIME_LEVEL(2 ^ 6)个元素。 t1 上的每个元素的粒度都是2 ^ 14, 一共TIME_LEVEL(2 ^ 6)个元素。 t2 上的每个元素的粒度都是2 ^ 20, 一共TIME_LEVEL(2 ^ 6)个元素。 t3 上的每个元素的粒度都是2 ^ 26, 一共TIME_LEVEL(2 ^ 6)个元素。 所以t上刚好可表示2^32个元素。\n初始化阶段 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 void skynet_timer_init(void) { TI = timer_create_timer(); uint32_t current = 0; systime(\u0026amp;TI-\u0026gt;starttime, \u0026amp;current); TI-\u0026gt;current = current; TI-\u0026gt;current_point = gettime(); } // centisecond: 1/100 second static void systime(uint32_t *sec, uint32_t *cs) { struct timespec ti; clock_gettime(CLOCK_REALTIME, \u0026amp;ti); *sec = (uint32_t)ti.tv_sec; *cs = (uint32_t)(ti.tv_nsec / 10000000); } static uint64_t gettime() { uint64_t t; struct timespec ti; clock_gettime(CLOCK_MONOTONIC, \u0026amp;ti); t = (uint64_t)ti.tv_sec * 100; t += ti.tv_nsec / 10000000; return t; } 在初始化阶段，会将全局的TI需要的空间申请好，并将 current 和 current_point 设置好，这边需要注意的是，systime 和 gettime 的单位都是 1/100 秒，即10ms。\n添加定时器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 int skynet_timeout(uint32_t handle, int time, int session) { if (time \u0026lt;= 0) { // 直接触发 struct skynet_message message; message.source = 0; message.session = session; message.data = NULL; message.sz = (size_t)PTYPE_RESPONSE \u0026lt;\u0026lt; MESSAGE_TYPE_SHIFT; if (skynet_context_push(handle, \u0026amp;message)) { return -1; } } else { // 定时触发 struct timer_event event; event.handle = handle; event.session = session; timer_add(TI, \u0026amp;event, sizeof(event), time); } return session; } static void timer_add(struct timer *T,void *arg,size_t sz,int time) { struct timer_node *node = (struct timer_node *)skynet_malloc(sizeof(*node)+sz); // 多申请了sz的内存 memcpy(node+1,arg,sz);//拷贝事件数据 SPIN_LOCK(T); node-\u0026gt;expire=time+T-\u0026gt;time; // 设置过期事件 add_node(T,node); // 放到对应位置上 SPIN_UNLOCK(T); } static void add_node(struct timer *T,struct timer_node *node) { uint32_t time=node-\u0026gt;expire; uint32_t current_time=T-\u0026gt;time; if ((time|TIME_NEAR_MASK)==(current_time|TIME_NEAR_MASK)) { // 如果是near粒度下 link(\u0026amp;T-\u0026gt;near[time\u0026amp;TIME_NEAR_MASK],node); } else { int i; uint32_t mask=TIME_NEAR \u0026lt;\u0026lt; TIME_LEVEL_SHIFT; for (i=0;i\u0026lt;3;i++) { if ((time|(mask-1))==(current_time|(mask-1))) { // 找到与timer相对应的粒度 break; } mask \u0026lt;\u0026lt;= TIME_LEVEL_SHIFT; } link(\u0026amp;T-\u0026gt;t[i][((time\u0026gt;\u0026gt;(TIME_NEAR_SHIFT + i*TIME_LEVEL_SHIFT)) \u0026amp; TIME_LEVEL_MASK)],node);\t} } 对外的主要接口是skynet_timeout，如果传入的时间小于0的话，则直接触发，产生对应的message丢入消息队列中。 而添加定时器通过timer_add来完成，这边在申请的内存的时候可以看到，定时器和对应事件的内存是一起申请的，node + 1 开始的内存存放的都是事件相关的数据。 add_node 则会根据过期事件来选择放到对应粒度的位置上\n更新阶段 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 void skynet_updatetime(void) { uint64_t cp = gettime(); if(cp \u0026lt; TI-\u0026gt;current_point) { skynet_error(NULL, \u0026#34;time diff error: change from %lld to %lld\u0026#34;, cp, TI-\u0026gt;current_point); TI-\u0026gt;current_point = cp; } else if (cp != TI-\u0026gt;current_point) { uint32_t diff = (uint32_t)(cp - TI-\u0026gt;current_point); TI-\u0026gt;current_point = cp; TI-\u0026gt;current += diff; int i; for (i=0;i\u0026lt;diff;i++) { timer_update(TI); } } } static void timer_update(struct timer *T) { SPIN_LOCK(T); // try to dispatch timeout 0 (rare condition) timer_execute(T); // 先再执行一遍当前时间的timer_execute，让那些执行timeout(0)的也能理解触发 // shift time first, and then dispatch timer message timer_shift(T); //偏移时间 timer_execute(T); // 继续执行正常的timer_execute SPIN_UNLOCK(T); } 在time线程中，每次睡眠后执行的update就是 skynet_updatetime， cp是当前的时间戳，不过单位是10ms。 如果cp出现小于之前记录的current_point，则是出现了系统时间偏移了，这边打个日志记录一下。 正常情况下，update 会计算跟上一次差了多少单位，然后每个单位都执行一下timer_update, timer_update 执行的主要函数就是下面的两个子函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 static inline void timer_execute(struct timer *T) { int idx = T-\u0026gt;time \u0026amp; TIME_NEAR_MASK; while (T-\u0026gt;near[idx].head.next) { struct timer_node *current = link_clear(\u0026amp;T-\u0026gt;near[idx]); SPIN_UNLOCK(T); // dispatch_list don\u0026#39;t need lock T dispatch_list(current); // 这个函数中会包装message，然后放到 消息队列中 SPIN_LOCK(T); } } static void timer_shift(struct timer *T) { int mask = TIME_NEAR; uint32_t ct = ++T-\u0026gt;time; if (ct == 0) { move_list(T, 3, 0); // 最大的一轮跑完了，那就从最大粒度的0号元素重新开始 } else { uint32_t time = ct \u0026gt;\u0026gt; TIME_NEAR_SHIFT; int i=0; // 找到下一个轮，如果为0则说明跑完当前的轮了，该去下一个更大的粒度的轮 while ((ct \u0026amp; (mask-1))==0) { int idx=time \u0026amp; TIME_LEVEL_MASK; if (idx!=0) { move_list(T, i, idx); break;\t} mask \u0026lt;\u0026lt;= TIME_LEVEL_SHIFT; time \u0026gt;\u0026gt;= TIME_LEVEL_SHIFT; ++i; } } } static void move_list(struct timer *T, int level, int idx) { struct timer_node *current = link_clear(\u0026amp;T-\u0026gt;t[level][idx]); //把对应粒度上面的事件分发到小粒度的轮上面 while (current) { struct timer_node *temp=current-\u0026gt;next; add_node(T,current); current=temp; } } timer_execute 的作用就是将near中对应的链表取出，然后将对应的事件抛到消息队列中去。 timer_shift 的作用就是更新当前的时间轮，如果当前粒度的时间轮跑完了，则会到更大到粒度的时间轮中把对应的事件更新到小粒度的轮上\n小结 skynet的时间轮 就是将时间拆分成粒度的数组，加元素的时候，就直接到对应的粒度的位置上添加事件；更新的时候则把大粒度的事件轮拆分到小粒度上面等待执行。\n不过这边我没看到取消定时器的函数，不知道是不是看漏了 还是说 实现上是再在触发后由业务判断是不是要回调。\n后续在研究一下。\nsocket线程相关的有点复杂，后续新开一篇总结吧。\n","date":"2024-04-15T00:00:00Z","image":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%83-skynet%E7%9A%84%E7%BA%BF%E7%A8%8B%E7%B1%BB%E5%9E%8B%E4%BA%8C/skynet_hu17557819904416107650.png","permalink":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%83-skynet%E7%9A%84%E7%BA%BF%E7%A8%8B%E7%B1%BB%E5%9E%8B%E4%BA%8C/","title":"Skynet源码阅读笔记(七)-skynet的线程类型（二）"},{"content":"Skynet源码阅读笔记(六)-skynet的线程类型 skynet中的线程类型可以分为一下几种类型\n主线程 worker 线程 timer 线程 monitor 线程 socket 线程 这些线程的初始化都在start函数里，由主线程驱动\n主线程 主线程只负责初始化工作，它主要是在start中创建了一些基础服务、创建出其他线程。执行完初始化后，主线程就会阻塞在最后等待其他结束。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 static void start(int thread) { pthread_t pid[thread+3]; // thread 是work 线程的数目，3是其他3个类型的线程 struct monitor *m = skynet_malloc(sizeof(*m)); memset(m, 0, sizeof(*m)); m-\u0026gt;count = thread; m-\u0026gt;sleep = 0; m-\u0026gt;m = skynet_malloc(thread * sizeof(struct skynet_monitor *)); int i; for (i=0;i\u0026lt;thread;i++) { m-\u0026gt;m[i] = skynet_monitor_new(); } if (pthread_mutex_init(\u0026amp;m-\u0026gt;mutex, NULL)) { fprintf(stderr, \u0026#34;Init mutex error\u0026#34;); exit(1); } if (pthread_cond_init(\u0026amp;m-\u0026gt;cond, NULL)) { fprintf(stderr, \u0026#34;Init cond error\u0026#34;); exit(1); } create_thread(\u0026amp;pid[0], thread_monitor, m); // 第一个线程用于 thread_monitor create_thread(\u0026amp;pid[1], thread_timer, m); // 第二个线程用于 thread_timer create_thread(\u0026amp;pid[2], thread_socket, m); // 第三个线程用于 thread_socket static int weight[] = { -1, -1, -1, -1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, }; struct worker_parm wp[thread]; for (i=0;i\u0026lt;thread;i++) { wp[i].m = m; wp[i].id = i; if (i \u0026lt; sizeof(weight)/sizeof(weight[0])) { wp[i].weight= weight[i]; } else { wp[i].weight = 0; } create_thread(\u0026amp;pid[i+3], thread_worker, \u0026amp;wp[i]); // 主线程创建其他work线程 } for (i=0;i\u0026lt;thread+3;i++) { pthread_join(pid[i], NULL); // 然后阻塞在这里等待其他线程结束 } free_monitor(m); } monitor 线程 monitor线程执行的函数是thread_monitor\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 static void * thread_monitor(void *p) { struct monitor * m = p; int i; int n = m-\u0026gt;count; skynet_initthread(THREAD_MONITOR); for (;;) { CHECK_ABORT for (i=0;i\u0026lt;n;i++) { // 检测对应线程的monitor 状态 skynet_monitor_check(m-\u0026gt;m[i]); } for (i=0;i\u0026lt;5;i++) { CHECK_ABORT sleep(1); } } return NULL; } void skynet_monitor_check(struct skynet_monitor *sm) { if (sm-\u0026gt;version == sm-\u0026gt;check_version) { if (sm-\u0026gt;destination) { skynet_context_endless(sm-\u0026gt;destination); skynet_error(NULL, \u0026#34;A message from [ :%08x ] to [ :%08x ] maybe in an endless loop (version = %d)\u0026#34;, sm-\u0026gt;source , sm-\u0026gt;destination, sm-\u0026gt;version); } } else { sm-\u0026gt;check_version = sm-\u0026gt;version; } } 该函数每5秒跑一下检测，判断对应线程的check_version 是否和其version相等，如果相等就说明可能存在死循环，调用 skynet_context_endless 来对ctx的 endless进行赋值。\nmonitor 这个结构如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 struct monitor { int count; struct skynet_monitor ** m; // skynet_monitor数组，每个work线程一个 pthread_cond_t cond; // 用于唤醒睡眠的worker线程 pthread_mutex_t mutex; int sleep; // 睡眠的work线程数量 int quit; }; struct skynet_monitor { ATOM_INT version; // 执行message的版本 int check_version; // 上一次检测时 执行message的版本 uint32_t source; // message 的source uint32_t destination; //message 的destination }; 本质上monitor是维护了一个条件变量 + skynet_monitor数组，每个work线程都拥有一个自己的skynet_monitor。因为worker线程和monitor线程在使用skynet_monitor时，写的是skynet_monitor的不同字段，而读操作即使出现异步问题也不要紧，所以这边可以不需要加锁。\nmonitor中的sleep 表示由多少个work线程在睡眠，睡眠的worker线程会阻塞在对应条件变量上等待被唤醒。\nworker线程 worker 线程执行的是thread_worker 函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 struct worker_parm { struct monitor *m; // monitor的引用 int id; // 线程ID int weight; //权重 }; // work线程的执行的实际函数如下 static void * thread_worker(void *p) { struct worker_parm *wp = p; int id = wp-\u0026gt;id; int weight = wp-\u0026gt;weight; struct monitor *m = wp-\u0026gt;m; struct skynet_monitor *sm = m-\u0026gt;m[id]; skynet_initthread(THREAD_WORKER); struct message_queue * q = NULL; while (!m-\u0026gt;quit) { q = skynet_context_message_dispatch(sm, q, weight); // 主要执行这个函数 if (q == NULL) { if (pthread_mutex_lock(\u0026amp;m-\u0026gt;mutex) == 0) { // 如果返回的q为空，则获取锁后标记自己为sleep ++ m-\u0026gt;sleep; // \u0026#34;spurious wakeup\u0026#34; is harmless, // because skynet_context_message_dispatch() can be call at any time. if (!m-\u0026gt;quit) pthread_cond_wait(\u0026amp;m-\u0026gt;cond, \u0026amp;m-\u0026gt;mutex); // 等待被唤醒，pthread_cond_wait 可能存在虚假唤醒，但并不要紧 -- m-\u0026gt;sleep; if (pthread_mutex_unlock(\u0026amp;m-\u0026gt;mutex)) { // 释放掉对应的锁 fprintf(stderr, \u0026#34;unlock mutex error\u0026#34;); exit(1); } } } } return NULL; } thread_worker这边主要就是执行 skynet_context_message_dispatch 函数，如果这个函数的返回值是空，则等待下一次的执行\n具体看一下 skynet_context_message_dispatch 的内容\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 struct message_queue * skynet_context_message_dispatch(struct skynet_monitor *sm, struct message_queue *q, int weight) { if (q == NULL) { q = skynet_globalmq_pop(); // 从全局的消息队列中获取一个消息队列 if (q==NULL) return NULL; // 没有则返回 } uint32_t handle = skynet_mq_handle(q); //获取这个消息队列对应的服务实例 struct skynet_context * ctx = skynet_handle_grab(handle); if (ctx == NULL) { struct drop_t d = { handle }; skynet_mq_release(q, drop_message, \u0026amp;d); return skynet_globalmq_pop(); } int i,n=1; struct skynet_message msg; for (i=0;i\u0026lt;n;i++) { if (skynet_mq_pop(q,\u0026amp;msg)) { // 开始获取消息队列中的消息， skynet_context_release(ctx); return skynet_globalmq_pop(); } else if (i==0 \u0026amp;\u0026amp; weight \u0026gt;= 0) { // 这边可以看出，每次执行消息是队列的 1/(2^weight) n = skynet_mq_length(q); n \u0026gt;\u0026gt;= weight; } int overload = skynet_mq_overload(q); // 当消息超载了之后，打个日志报警一下 if (overload) { skynet_error(ctx, \u0026#34;May overload, message queue length = %d\u0026#34;, overload); } skynet_monitor_trigger(sm, msg.source , handle); // 告诉monitor当前执行的服务是哪个服务 if (ctx-\u0026gt;cb == NULL) { skynet_free(msg.data); } else { dispatch_message(ctx, \u0026amp;msg); // 执行真正的信息处理 } skynet_monitor_trigger(sm, 0,0); } assert(q == ctx-\u0026gt;queue); struct message_queue *nq = skynet_globalmq_pop(); if (nq) { // If global mq is not empty , push q back, and return next queue (nq) // Else global mq is empty or block, don\u0026#39;t push q back, and return q again (for next dispatch) skynet_globalmq_push(q); q = nq; } skynet_context_release(ctx); return q; } skynet_context_message_dispatch 就是从队列中消费消息，weight在这起到的作用就是每次执行队列总长度的1/(2^weight)\n所以前8条线程应该都是执行完所有消息，8-16条每次执行1/2的消息长度的数据，一次类推。\n还有一个值得注意的，skynet_monitor_trigger就是会在这往skynet_monitor写入当前的服务ID，以便monitor线程进行监控\n执行消息的函数是dispatch_message，dispatch_message的内容也不长，完整的看一下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 static void dispatch_message(struct skynet_context *ctx, struct skynet_message *msg) { assert(ctx-\u0026gt;init); CHECKCALLING_BEGIN(ctx) pthread_setspecific(G_NODE.handle_key, (void *)(uintptr_t)(ctx-\u0026gt;handle)); // 取出消息对应的类型和长度，然后打个日志 int type = msg-\u0026gt;sz \u0026gt;\u0026gt; MESSAGE_TYPE_SHIFT; size_t sz = msg-\u0026gt;sz \u0026amp; MESSAGE_TYPE_MASK; FILE *f = (FILE *)ATOM_LOAD(\u0026amp;ctx-\u0026gt;logfile); if (f) { skynet_log_output(f, msg-\u0026gt;source, type, msg-\u0026gt;session, msg-\u0026gt;data, sz); } ++ctx-\u0026gt;message_count; int reserve_msg; // 如果开启了profile，则会在这边统计对应的服务执行的时间 if (ctx-\u0026gt;profile) { ctx-\u0026gt;cpu_start = skynet_thread_time(); reserve_msg = ctx-\u0026gt;cb(ctx, ctx-\u0026gt;cb_ud, type, msg-\u0026gt;session, msg-\u0026gt;source, msg-\u0026gt;data, sz); uint64_t cost_time = skynet_thread_time() - ctx-\u0026gt;cpu_start; ctx-\u0026gt;cpu_cost += cost_time; } else { // 不然就直接调用 reserve_msg = ctx-\u0026gt;cb(ctx, ctx-\u0026gt;cb_ud, type, msg-\u0026gt;session, msg-\u0026gt;source, msg-\u0026gt;data, sz); } if (!reserve_msg) { skynet_free(msg-\u0026gt;data); } CHECKCALLING_END(ctx) } dispatch_message 准确来说目的就是执行ctx-\u0026gt;cb，但外部根据执行环境决定是否写入日志和统计函数执行时间。\n小结 这边先看了一下主线程、monitor线程和worker线程是如何工作的，另外两个线程下一次再分析。\n主线程主要是初始化环境以及各个其他线程，然后join等待其他线程结束 monitor线程可以认为就是每5秒判断一次是否当前执行的某个worker线程进入了死循环。 worker线程就是将消息队列中的消息取出，并调用对应服务的cb函数。\n","date":"2024-02-10T00:00:00Z","image":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E5%85%AD-skynet%E7%9A%84%E7%BA%BF%E7%A8%8B%E7%B1%BB%E5%9E%8B%E4%B8%80/skynet_hu17557819904416107650.png","permalink":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E5%85%AD-skynet%E7%9A%84%E7%BA%BF%E7%A8%8B%E7%B1%BB%E5%9E%8B%E4%B8%80/","title":"Skynet源码阅读笔记(六)-skynet的线程类型（一）"},{"content":"Skynet源码阅读笔记-skynet_context skynet_context 在Skynet中，服务是由skynetContext来定义的，服务拥有自己的module，自己的messageQueue以及自己的其他数据结构。\nmodule、messageQueue、handle的概念在之前的文章中已经分析过了，现在就可以开始分析skynet_context了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 struct skynet_context { void * instance; // mod 实例 struct skynet_module * mod; // module void * cb_ud; // 回调函数的data skynet_cb cb; // 回调函数 struct message_queue *queue; // 消息队列 ATOM_POINTER logfile; // 日志文件的指针（原子指针） uint64_t cpu_cost;\t// in microsec CPU运行时间 uint64_t cpu_start;\t// in microsec char result[32]; // 用来保存执行CMD命令的结果 uint32_t handle; // skynet_context 在全局映射的handle int session_id; // ATOM_INT ref; // 引用计数 int message_count; // 受到过的消息总数 bool init; // 是否初始化 bool endless; // 是否死循环 bool profile; // 是否开启了profile CHECKCALLING_DECL }; 在分析消息队列的时候，有说到全局的消息队列会不断dispatch消息到 skynet_context 的私有消息队列里。而work线程会从 skynet_context 的私有队列里不断消费数据。这边可以更详细的分析一下。\n初始化skynetContext 初始化 skynet_context_new 是通过 skynet_context_new 来进行的，这个函数在分析module、message_queue的时候已经有分析过了，这边完整的看一下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 struct skynet_context * skynet_context_new(const char * name, const char *param) { // 加载module struct skynet_module * mod = skynet_module_query(name); if (mod == NULL) return NULL; // 创建module实例 void *inst = skynet_module_instance_create(mod); if (inst == NULL) return NULL; struct skynet_context * ctx = skynet_malloc(sizeof(*ctx)); CHECKCALLING_INIT(ctx) // 给 skynet_context 的所有变量赋初始值 ctx-\u0026gt;mod = mod; ctx-\u0026gt;instance = inst; // 将 skynet_context 的引用计数设置为2 ATOM_INIT(\u0026amp;ctx-\u0026gt;ref , 2); ctx-\u0026gt;cb = NULL; ctx-\u0026gt;cb_ud = NULL; ctx-\u0026gt;session_id = 0; // 初始化logfile 原子指针 ATOM_INIT(\u0026amp;ctx-\u0026gt;logfile, (uintptr_t)NULL); ctx-\u0026gt;init = false; ctx-\u0026gt;endless = false; ctx-\u0026gt;cpu_cost = 0; ctx-\u0026gt;cpu_start = 0; ctx-\u0026gt;message_count = 0; ctx-\u0026gt;profile = G_NODE.profile; // 初始化handle 和 message ctx-\u0026gt;handle = 0;\tctx-\u0026gt;handle = skynet_handle_register(ctx); struct message_queue * queue = ctx-\u0026gt;queue = skynet_mq_create(ctx-\u0026gt;handle); context_inc(); // 执行module的初始化 CHECKCALLING_BEGIN(ctx) int r = skynet_module_instance_init(mod, inst, ctx, param); CHECKCALLING_END(ctx) if (r == 0) { // 初始化成功的处理 // 这边会减少初始化的引用计数 struct skynet_context * ret = skynet_context_release(ctx); if (ret) { ctx-\u0026gt;init = true; } // 将当前queue 塞入到global mq中，等待work线程处理 skynet_globalmq_push(queue); if (ret) { skynet_error(ret, \u0026#34;LAUNCH %s %s\u0026#34;, name, param ? param : \u0026#34;\u0026#34;); } return ret; } else { // 初始化失败就释放 skynet_error(ctx, \u0026#34;FAILED launch %s\u0026#34;, name); uint32_t handle = ctx-\u0026gt;handle; skynet_context_release(ctx); skynet_handle_retire(handle); struct drop_t d = { handle }; skynet_mq_release(queue, drop_message, \u0026amp;d); return NULL; } } 初始化流程中主要就是加载并实例化module，并创建message_queue提供给work进行处理。\n在初始化的时候，可以看到引用计数被设置成2，这边初始化为2的原因我猜测是因为\n初始化流程算引用一次，所以初始化结束会减少一次 可以看到调用了skynet_context_release； 另一次是因为注册到handle中， 可以看到skynet_handle_register并不会增加引用结束，但在执行 handle_exit的时候，会调用到 skynet_handle_retire，这里面会对ctx的引用技术减少一。 减少引用计数的调用如下\n1 2 3 4 5 6 7 8 struct skynet_context * skynet_context_release(struct skynet_context *ctx) { if (ATOM_FDEC(\u0026amp;ctx-\u0026gt;ref) == 1) { delete_context(ctx); return NULL; } return ctx; } ATOM_FDEC 会将ref减少1， 并返回调用前的值。所以当引用计数为1进来的时候，就会删掉对应的 skynet_context\n回调函数的注册与回调时机 每个服务都会有自己的回调函数，这个回调函数的作用就是在收到message的时候，调用回来函数来进行处理。\n注册时机 1 2 3 4 5 void skynet_callback(struct skynet_context * context, void *ud, skynet_cb cb) { context-\u0026gt;cb = cb; context-\u0026gt;cb_ud = ud; } 每个服务通过 skynet_callback 来注册自己的回调，调用这个的时机都是在每个服务内部自己决定。 在skynet中的自带的几个服务，都是在init的时候调用 skynet_callback 来注册回调\n回调时机 1 2 3 4 5 6 7 8 9 10 11 12 struct message_queue * skynet_context_message_dispatch(struct skynet_monitor *sm, struct message_queue *q, int weight) { ... for (i=0;i\u0026lt;n;i++) { // 如果没有回调函数，则直接释放消息 if (ctx-\u0026gt;cb == NULL) { skynet_free(msg.data); } else { dispatch_message(ctx, \u0026amp;msg); } } } skynet_context_message_dispatch 这个函数是在work线程执行中回调用的函数，该函数会在ctx存在要处理的消息时调用\ndispatch_message 具体函数如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 static void dispatch_message(struct skynet_context *ctx, struct skynet_message *msg) { assert(ctx-\u0026gt;init); CHECKCALLING_BEGIN(ctx) // 设置当前线程正在跑的handle pthread_setspecific(G_NODE.handle_key, (void *)(uintptr_t)(ctx-\u0026gt;handle)); int type = msg-\u0026gt;sz \u0026gt;\u0026gt; MESSAGE_TYPE_SHIFT; size_t sz = msg-\u0026gt;sz \u0026amp; MESSAGE_TYPE_MASK; // 打个收到消息的日志 FILE *f = (FILE *)ATOM_LOAD(\u0026amp;ctx-\u0026gt;logfile); if (f) { skynet_log_output(f, msg-\u0026gt;source, type, msg-\u0026gt;session, msg-\u0026gt;data, sz); } ++ctx-\u0026gt;message_count; int reserve_msg; if (ctx-\u0026gt;profile) { // 如果开启了profile，则会记录调用前后的CPU时间差 ctx-\u0026gt;cpu_start = skynet_thread_time(); reserve_msg = ctx-\u0026gt;cb(ctx, ctx-\u0026gt;cb_ud, type, msg-\u0026gt;session, msg-\u0026gt;source, msg-\u0026gt;data, sz); uint64_t cost_time = skynet_thread_time() - ctx-\u0026gt;cpu_start; ctx-\u0026gt;cpu_cost += cost_time; } else { reserve_msg = ctx-\u0026gt;cb(ctx, ctx-\u0026gt;cb_ud, type, msg-\u0026gt;session, msg-\u0026gt;source, msg-\u0026gt;data, sz); } if (!reserve_msg) { skynet_free(msg-\u0026gt;data); } CHECKCALLING_END(ctx) } dispatch_message 函数实际上就是调用了ctx函数的回调函数，只是在调用前后额外设置了环境相关的变量。\n小结 skynet_context 的重要结构到这边就分析完了，skynet_context的作用主要就是给modules提供一个运行环境，拥有自己独立的数据结构，并提供接口给module让其能够用handle或者名字的形式给其他skynet_context 发送消息。\n","date":"2024-01-31T00:00:00Z","image":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%BA%94-skynet_context/skynet_hu17557819904416107650.png","permalink":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%BA%94-skynet_context/","title":"Skynet源码阅读笔记(五)-skynet_context"},{"content":"Skynet源码阅读笔记-message skynet_message 在skynet中，两个服务之间是通过message传递消息来触发事件的\nskynet_message 结构如下\n1 2 3 4 5 6 7 8 9 10 struct skynet_message { uint32_t source; // 消息源的handle int session; // 消息的session Id void * data; // 消息的内容 size_t sz; // 消息的长度 和 类型， }; // type is encoding in skynet_message.sz high 8bit #define MESSAGE_TYPE_MASK (SIZE_MAX \u0026gt;\u0026gt; 8) #define MESSAGE_TYPE_SHIFT ((sizeof(size_t)-1) * 8) message_queue 而保存 skynet_message 的结构则是 message_queue\n1 2 3 4 5 6 7 8 9 10 11 12 13 struct message_queue { struct spinlock lock; // 自旋锁 uint32_t handle; // 对应的handle int cap; // 当前消息队列容量 int head; // 消息队列头 int tail; // 消息队列尾 int release; //是否被释放 int in_global; // 标记是否在全局队列中 int overload; // 是否超载 int overload_threshold; //超载阈值 struct skynet_message *queue; // 实际的消息对了 struct message_queue *next; // 下一个消息队列 } message_queue 是一个简单的结构并不复杂的消息队列，本质上就是 由一个 循环数组 + 自旋锁构成。\n操作 message_queue 的代码都在 skyenet_mq.c 中。本质上和操作普通队列没什么特别大区别，只是每次操作前都通过自旋锁来锁住操作。当消息通过 skynet_mq_push 塞进队列的时候，如果队列满了的话就会变成原来的2倍。\nmessage_queue 中的handle 说明了这个 message_queue 绑定上的对应的 skynet_context。在skynet_context_new中可以看到对应的代码\n1 2 3 4 5 6 7 8 9 struct skynet_context * skynet_context_new(const char * name, const char *param) { ... ctx-\u0026gt;handle = 0;\tctx-\u0026gt;handle = skynet_handle_register(ctx); // 这一步就是笔记三中的部分 struct message_queue * queue = ctx-\u0026gt;queue = skynet_mq_create(ctx-\u0026gt;handle); // 获取handle后，就创建 message_queue， 并绑定上对应的handle ... } global_queue mesaage_queue 在接收到消息后, 会将自己放入到global_queue 这个结构中\n1 2 3 4 5 6 7 struct global_queue { struct message_queue *head; // mesaage_queue 的链表头 struct message_queue *tail; // mesaage_queue 的链表尾 struct spinlock lock; // 自旋锁 }; static struct global_queue *Q = NULL; 数据的消费以及产生 这个结构是一个全局变量，它管理着目前有消息的消息队列。在 skynet_context_message_dispatch 函数中，message_queue的message 会被消费\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 struct message_queue * skynet_context_message_dispatch(struct skynet_monitor *sm, struct message_queue *q, int weight) { if (q == NULL) { q = skynet_globalmq_pop(); // 获取全局消息队列的头部 if (q==NULL) return NULL; } uint32_t handle = skynet_mq_handle(q); struct skynet_context * ctx = skynet_handle_grab(handle); // 找到对应的 skynet_context ..... int i,n=1; struct skynet_message msg; for (i=0;i\u0026lt;n;i++) { //从队列头部获取消息 if (skynet_mq_pop(q,\u0026amp;msg)) { ... } ..... if (ctx-\u0026gt;cb == NULL) { skynet_free(msg.data); } else { // 触发消息事件 dispatch_message(ctx, \u0026amp;msg); } ... } } 可以看到skynet_context_message_dispatch 函数就是从全局队列拿到队列的消息列表后，在从消息列表中获取到对应消息来消费。\n这个函数skynet_context_message_dispatch 实际上是被包装在thread_worker，在初始化的时候由多个线程一起调用，所以需要加锁。\n1 2 3 4 5 6 7 8 9 static void * thread_worker(void *p) { .... while (!m-\u0026gt;quit) { q = skynet_context_message_dispatch(sm, q, weight); --- 所有线程一起执行skynet_context_message_dispatch .... } } 所以，所有工作线程到最后只是执行对应的服务的事件队列而已。\n而对于一个消息，它会通过下面两个接口塞入到消息队列中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 int skynet_context_push(uint32_t handle, struct skynet_message *message) { struct skynet_context * ctx = skynet_handle_grab(handle); if (ctx == NULL) { return -1; } skynet_mq_push(ctx-\u0026gt;queue, message); skynet_context_release(ctx); return 0; } void skynet_context_send(struct skynet_context * ctx, void * msg, size_t sz, uint32_t source, int type, int session) { struct skynet_message smsg; smsg.source = source; smsg.session = session; smsg.data = msg; smsg.sz = sz | (size_t)type \u0026lt;\u0026lt; MESSAGE_TYPE_SHIFT; skynet_mq_push(ctx-\u0026gt;queue, \u0026amp;smsg); } skynet.send 最后也是调用的 skynet_context_push， messsage会在外面包装好，然后直接丢到对应的 skynet_context 的 message_queue中。\nskynet_harbor_send 则是调用的 skynet_context_send 来把消息塞入到对应的message中。\n","date":"2024-01-24T00:00:00Z","image":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E5%9B%9B-message_queue/skynet_hu17557819904416107650.png","permalink":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E5%9B%9B-message_queue/","title":"Skynet源码阅读笔记(四)-message_queue"},{"content":"Git 原理 文章就基于git官方文档的学习笔记，并记录一下在看文档的时候的实验过程，git实验的版本是 git version 2.42.0.windows.1；\n如果内容有问题或者不正确的地方，欢迎留言讨论。\ngit初始目录 在执行完git init后，.git目录中包含以下文件\nhooks 用于存放钩子脚本的目录 description 用于GitWeb程序使用，文档上说这边不需要关系，那就先跳过 config 项目特有的配置信息 info 这个目录包含所有不希望记录在.gitignore又需要被忽略的文件 下面四个是比较重要的文件\nHEAD 该文件指向目前所在的分支 index 文件保存暂存区的信息，这个文件在init之初是未被创建的 objects 存储所有的数据信息 refs 存储指向数据的指针 数据对象 git的核心部分可以认为是一个key-vlaue的数据库，在git init初始化的时候，git在objects中创建了两个空的目录，分别是info 和 pack；\n跟这文档，执行下述命令后，返回一个长度40的校验和\n1 2 echo \u0026#34;test first\u0026#34; | git hash-object -w --stdin d50b0140c9fbe1aa26e7e28abf6f3c4ea9cde9ea 这个检验和是SHA-1哈希值，通过要存储的信息和一个header信息做SHA-1校验得到的运算结果。\n命令执行完毕之后，可以看到objects中多了对应的d5文件夹和0b0140c9fbe1aa26e7e28abf6f3c4ea9cde9ea的文件；可以分析出是用校验和的前两个字符作用目录名，后面38个在字符作为文件名。\n通过下述命令可以从“git数据库”中得到返回对应的内容\n1 2 $ git cat-file -p d50b0140c9fbe1aa26e7e28abf6f3c4ea9cde9ea test first 跟着官网的文档，继续使用git hash-object -w往git数据库插入一些数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 $ echo \u0026#34;version 1\u0026#34; \u0026gt; test.txt $ git hash-object -w test.txt 83baae61804e65cc73a7201a7252750c76066a30 $ find .git/objects/ -type f .git/objects/83/baae61804e65cc73a7201a7252750c76066a30 .git/objects/d5/0b0140c9fbe1aa26e7e28abf6f3c4ea9cde9ea echo \u0026#34;version 2\u0026#34; \u0026gt; test.txt $ git hash-object -w test.txt 1f7a7a472abf3dd9643fd615f6da379c4acb3e3a $ find .git/objects -type f .git/objects/1f/7a7a472abf3dd9643fd615f6da379c4acb3e3a .git/objects/83/baae61804e65cc73a7201a7252750c76066a30 .git/objects/d5/0b0140c9fbe1aa26e7e28abf6f3c4ea9cde9ea 使用这个方式插入数据的时候，可以看到git status等正常方式是不会有改变的\n1 2 3 4 5 6 7 8 $ git status On branch master No commits yet Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) test.txt 这种方式直接通过git hash-object -w插入的数被称为 数据对象（blob objects），它没有存储对应的文件名字等信息\n通过git cat-file -t 命令可以看到git存储的内部对象类型\n1 2 $ git cat-file -t 1f7a7a472abf3dd9643fd615f6da379c4acb3e3a blob 树对象 树对象的存在是为了解决数据对象中没有名字的问题；\n使用下面的一系列命令创建出一个树对象\n首先是提交文件到暂存区\n1 $ git update-index --add --cacheinfo 100644 83baae61804e65cc73a7201a7252750c76066a30 test.txt 其中\n\u0026ndash;add是因为这个文件需要首次加入到暂存区； \u0026ndash;cacheinfo 是因为对应的对象是在之前加入到git 数据库中的，而不是目录下的文件； 100644 表明加入的是一个普通文件，其他还有选项如10755之类的，具体看官网 test.txt是文件名； 提交完毕后通过git write-tree 来创建出对应的树对象\n1 2 3 4 5 6 7 8 $ git write-tree 83baae61804e65cc73a7201a7252750c76066a30 d8329fc1cc938780ffdd9f94e0d364e0ea74f579 $ git cat-file -p d8329fc1cc938780ffdd9f94e0d364e0ea74f579 100644 blob 83baae61804e65cc73a7201a7252750c76066a30 test.txt $ git cat-file -t d8329fc1cc938780ffdd9f94e0d364e0ea74f579 tree 可以看到这个树对象的内容就是之前输入到暂存区的参数；\n接下来跟着官网实例为test.txt创建新的版本，和新的文件\n1 2 3 4 5 6 7 8 9 10 $ git update-index --add --cacheinfo 100644 1f7a7a472abf3dd9643fd615f6da379c4acb3e3a test.txt $ echo \u0026#34;new file\u0026#34; \u0026gt; new.txt $ git update-index --add new.txt $ git write-tree 0155eb4229851634a0f03eb265b69f5a2d56f341 $ git cat-file -p 0155eb4229851634a0f03eb265b69f5a2d56f341 100644 blob fa49b077972391ad58037050f2a75f74e3671e92 new.txt 100644 blob 1f7a7a472abf3dd9643fd615f6da379c4acb3e3a test.txt 在这次的提交中，可以看到生成的树对象内容包含了这次的修改的数据对象指针以及文件内容\n将之前的树节点读取出来然后提交\n1 2 3 4 5 6 7 $ git read-tree --prefix=bak d8329fc1cc938780ffdd9f94e0d364e0ea74f579 $ git write-tree 3c4e9cd789d88d8d89c1073707c3585e41b0e614 $ git cat-file -p 3c4e9cd789d88d8d89c1073707c3585e41b0e614 040000 tree d8329fc1cc938780ffdd9f94e0d364e0ea74f579 bak 100644 blob fa49b077972391ad58037050f2a75f74e3671e92 new.txt 100644 blob 1f7a7a472abf3dd9643fd615f6da379c4acb3e3a test.txt 到这边我才发现，我的SHA-1内容和官方示例是一样的，不过也确实，因为校验和是根据内容生成的，内容一致，所以结果也一样。\n做到这边我的疑惑是为什么第三步读入树对象了之后，在git write-tree之后会有new.txt和test.txt；我这边以为git write-tree是对应git commit， 会将暂存区清空的；但后面发现官网文档上有说明git write-tree 只是将当前暂存区对象打包成一个树对象，不会改成暂存区；\n提交对象 提交对象的目的是为了保存什么时候、为什么提交快照信息；\n1 2 $ echo \u0026#34;first commit\u0026#34; | git commit-tree d8329fc1cc938780ffdd9f94e0d364e0ea74f579 3d892437b4885956efeece70e6264534b1aa1785 文档还很贴切的在这提示了说因为时间不同，得到的会是不同的SHA-1值\n1 2 3 4 5 6 $ git cat-file -p fdf4fc3 tree d8329fc1cc938780ffdd9f94e0d364e0ea74f579 author Scott Chacon \u0026lt;schacon@gmail.com\u0026gt; 1243040974 -0700 committer Scott Chacon \u0026lt;schacon@gmail.com\u0026gt; 1243040974 -0700 first commit 这边按文档的例子来解释，提交对象的头部是一个树对象的SHA, 然后是作者信息，最后是提交注释\n通过git log \u0026ndash;stat 就可以看到一个完整的提交记录\n如果继续把上述的树对象都提交了，后续的提交需要指定前一个提交作为父对象\n1 2 3 4 5 $ echo \u0026#39;second commit\u0026#39; | git commit-tree 0155eb -p 3d892437 80869a3e49b9078e1152d6ab8cf14b332e0cac69 $ echo \u0026#39;third commit\u0026#39; | git commit-tree 3c4e9c -p 80869a3e 55ab56f172e9224cc3ed302ff7f74da514d27e11 最后的结果应该是和文档的图是一致的 对象存储 git对象的SHA-1 是通过一个header + content组成的；\ncontent就是文档内容，而header是通过content的类型和长度生成的，最后将header + content拼接在一起后进行SHA-1得到最后的校验合。 而content在存储之前会经过zlib压缩。\n最后存储到文件的时候就是SHA-1作为文件名，zlib压缩的content作为文件内容\n引用 https://git-scm.com/book/zh/v2/Git-%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86-%E5%BA%95%E5%B1%82%E5%91%BD%E4%BB%A4%E4%B8%8E%E4%B8%8A%E5%B1%82%E5%91%BD%E4%BB%A4 https://git-scm.com/book/zh/v2/Git-%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86-Git-%E5%AF%B9%E8%B1%A1 ","date":"2023-12-01T00:00:00Z","image":"https://frozenlychees.github.io/p/git-%E5%8E%9F%E7%90%86/commit_hu17749147639934025439.png","permalink":"https://frozenlychees.github.io/p/git-%E5%8E%9F%E7%90%86/","title":"Git 原理"},{"content":"Lua 源码阅读笔记-加载chunk lua版本基于5.4.6， 文章更多是记录自己在阅读的是思绪，而非科普。 如果内容有问题或者不正确的地方，欢迎留言讨论。\n大致流程 在Python中，当python虚拟机执行py脚本的时候，会先将py脚本编译成pyc（实际上就是字节码的集合），然后虚拟机加载对应的字节码开始工作。这个流程在lua中也是一样的，lua解释器会将lua源码编译成所谓的chunk，然后加载这个chunk进行解释工作，只是一般情况下，chunk文件没有保存在本地。lua提供luac的方式手动将源码编译成二进制的chunk文件并保存。\nChunk Chunk貌似就是类似pyc一样的文件，包含了运行的字节码、版本信息等\nload chunk 从加载chunk开始 稍微往下跟一下，加载chunk的函数是lua_load\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 LUA_API int lua_load (lua_State *L, lua_Reader reader, void *data, const char *chunkname, const char *mode) { ... if (!chunkname) chunkname = \u0026#34;?\u0026#34;; luaZ_init(L, \u0026amp;z, reader, data); status = luaD_protectedparser(L, \u0026amp;z, chunkname, mode); if (status == LUA_OK) { /* no errors? */ ... } lua_unlock(L); return status; } int luaD_protectedparser (lua_State *L, ZIO *z, const char *name, const char *mode) { struct SParser p; int status; ... luaZ_initbuffer(L, \u0026amp;p.buff); status = luaD_pcall(L, f_parser, \u0026amp;p, savestack(L, L-\u0026gt;top.p), L-\u0026gt;errfunc); ... return status; } 可以看到缩减之后，函数本质是调用了luaD_protectedparser这个函数，而luaD_protectedparser中通过luaD_pcall进行了一系列的操作。\nluaD_pcall这个函数在源码中的定义如下\n1 2 3 4 5 ** Call the C function \u0026#39;func\u0026#39; in protected mode, restoring basic ** thread information (\u0026#39;allowhook\u0026#39;, etc.) and in particular ** its stack level in case of errors. int luaD_pcall (lua_State *L, Pfunc func, void *u, ptrdiff_t old_top, ptrdiff_t ef) 看起来就是通过 lua 虚拟机的操作来 “安全的” 调用 一个Pfunc，保证出现异常的时候不会直接挂掉. 这边先不深入这个函数，后面应该还会遇到它很多次\n回到luaD_protectedparser，可以看到调用的函数是f_parser。\nf_parser 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 static void f_parser (lua_State *L, void *ud) { LClosure *cl; struct SParser *p = cast(struct SParser *, ud); int c = zgetc(p-\u0026gt;z); /* read first character */ if (c == LUA_SIGNATURE[0]) { checkmode(L, p-\u0026gt;mode, \u0026#34;binary\u0026#34;); cl = luaU_undump(L, p-\u0026gt;z, p-\u0026gt;name); } else { checkmode(L, p-\u0026gt;mode, \u0026#34;text\u0026#34;); cl = luaY_parser(L, p-\u0026gt;z, \u0026amp;p-\u0026gt;buff, \u0026amp;p-\u0026gt;dyd, p-\u0026gt;name, c); } lua_assert(cl-\u0026gt;nupvalues == cl-\u0026gt;p-\u0026gt;sizeupvalues); luaF_initupvals(L, cl); } 这个函数很短，这个cast宏可以看作是一个构造函数，构造出Sparse这个对象，实际上这边传入的是luaD_protectedparser 函数的那个栈变量p；\n通过这个p的checkmode函数来检查加载的文件和加载的方式是否匹配，并调用不同的函数构造出LClosure，设置到对应的虚拟机中，这边构造出的LClosure应该是一个最外层的Lua闭包。\n具体的parse部分目前先不深究了，对于语法、词法分析相关的基础知识还差太多了，等以后有空再补。\n闭包这个概念在Lua中应该是需要花一整个篇幅来阅读的，这边写不展开看了。\n小结 从load chunk开始一层层往下，基本上可以确定Lua从给定的名字和打开方式中解析出一个闭包，然后设置到对应的虚拟机对象中，这样后面Lua虚拟机就可以根据这闭包执行对应的字节码了。\n引用 https://yuerer.com/Lua5.3-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0(%E4%B8%80)-Lua%E6%98%AF%E6%80%8E%E4%B9%88%E8%B7%91%E8%B5%B7%E6%9D%A5%E7%9A%84/ https://yuerer.com/Lua5.3-%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0(%E5%9B%9B)-Closure%E4%B8%8EUpvalues/ https://zhuanlan.zhihu.com/p/358423900\n《Lua设计与实现》 https://blog.codingnow.com/2011/03/lua_gc_1.html 《云风-Lua GC 的源码剖析》 ","date":"2023-11-21T00:00:00Z","image":"https://frozenlychees.github.io/p/lua-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-chunk-%E5%8A%A0%E8%BD%BD%E7%9B%B8%E5%85%B3/lua_hu12632442988653076332.png","permalink":"https://frozenlychees.github.io/p/lua-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-chunk-%E5%8A%A0%E8%BD%BD%E7%9B%B8%E5%85%B3/","title":"Lua 源码阅读笔记-chunk 加载相关"},{"content":"Skynet源码阅读笔记-SkynetetHandle 在一个skyent进程中，handle的作用是用来通过它查找对应注册的ctx。\ne而在 skynet_context_new 创建一个新的ctx的时候， 会通过 skynet_handle_register 来获取 ctx 对应的 handle。下面看看具体是怎么玩的。\n1 2 3 4 5 6 7 struct skynet_context * skynet_context_new(const char * name, const char *param) { ... ctx-\u0026gt;handle = 0;\tctx-\u0026gt;handle = skynet_handle_register(ctx); ... } handle_storage 先看一下 handle_storage 这个结构\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 struct handle_name { char * name; uint32_t handle; }; struct handle_storage { struct rwlock lock; // 读写锁 uint32_t harbor; // 本skynet节点的harbor uint32_t handle_index; // 下一个handle 插入时查找的位置 int slot_size; // slot 的长度 struct skynet_context ** slot; // skynet_context 数组 int name_cap; // 当前数组的长度 int name_count; // 当前使用个数 struct handle_name *name; // 名字映射handle的数组 }; static struct handle_storage *H = NULL; handle_storage结构很简单，就是一个 skynet_context 的数组，只是因为它是一个全局的对象，所以需要一个读写锁来控制访问。\nskynet_handle_register 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 uint32_t skynet_handle_register(struct skynet_context *ctx) { struct handle_storage *s = H; rwlock_wlock(\u0026amp;s-\u0026gt;lock); for (;;) { int i; uint32_t handle = s-\u0026gt;handle_index; // 从handle_index 位置开始找一个可以插入的位置 for (i=0;i\u0026lt;s-\u0026gt;slot_size;i++,handle++) { if (handle \u0026gt; HANDLE_MASK) { // 0 is reserved handle = 1; } int hash = handle \u0026amp; (s-\u0026gt;slot_size-1); if (s-\u0026gt;slot[hash] == NULL) { // 找到空位就插入返回 s-\u0026gt;slot[hash] = ctx; s-\u0026gt;handle_index = handle + 1; rwlock_wunlock(\u0026amp;s-\u0026gt;lock); handle |= s-\u0026gt;harbor; return handle; } } assert((s-\u0026gt;slot_size*2 - 1) \u0026lt;= HANDLE_MASK); // 需要扩容了 struct skynet_context ** new_slot = skynet_malloc(s-\u0026gt;slot_size * 2 * sizeof(struct skynet_context *)); memset(new_slot, 0, s-\u0026gt;slot_size * 2 * sizeof(struct skynet_context *)); for (i=0;i\u0026lt;s-\u0026gt;slot_size;i++) { if (s-\u0026gt;slot[i]) { int hash = skynet_context_handle(s-\u0026gt;slot[i]) \u0026amp; (s-\u0026gt;slot_size * 2 - 1); assert(new_slot[hash] == NULL); new_slot[hash] = s-\u0026gt;slot[i]; } } skynet_free(s-\u0026gt;slot); s-\u0026gt;slot = new_slot; s-\u0026gt;slot_size *= 2; // 扩容完成后再插入一遍 } } skynet_handle_register 需要做的事情就是将 ctx 插入到一个当前空着的 slot 中。\n因为是修改数组，所以进入函数的时候就获取写锁，这边从 handle_index 开始遍历数组，转一圈如果没找到空位就将数组扩充成原来的2倍，然后再执行一个插入。找到空位后将数组下标返回，这个数组下标就是 skynet_context 的handle。\n稍微值得注意的是，因为返回的是下标，所以扩容的时候原来位置对应的元素还是应该一样的。\nskynet_handle_namehandle 这个接口是用名字和handle进行把绑定\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 static const char * _insert_name(struct handle_storage *s, const char * name, uint32_t handle) { int begin = 0; int end = s-\u0026gt;name_count - 1; // 二分查找对应插入点 while (begin\u0026lt;=end) { int mid = (begin+end)/2; struct handle_name *n = \u0026amp;s-\u0026gt;name[mid]; int c = strcmp(n-\u0026gt;name, name); if (c==0) { return NULL; } if (c\u0026lt;0) { begin = mid + 1; } else { end = mid - 1; } } char * result = skynet_strdup(name); _insert_name_before(s, result, handle, begin); // 真正插入的行为执行点 return result; } const char * skynet_handle_namehandle(uint32_t handle, const char *name) { rwlock_wlock(\u0026amp;H-\u0026gt;lock); const char * ret = _insert_name(H, name, handle); rwlock_wunlock(\u0026amp;H-\u0026gt;lock); return ret; } 在 _insert_name 中可以很明显的看出来， handle_storage 的 name 数组是一个有序的数组，插入的时候通过二分来找到插入的位置，然后调用 _insert_name_before 完成插入， _insert_name_before 中包含了对该数组的扩容以及元素移动等行为。\nskynet_handle_retire 看一下删除操作\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 int skynet_handle_retire(uint32_t handle) { int ret = 0; struct handle_storage *s = H; rwlock_wlock(\u0026amp;s-\u0026gt;lock); uint32_t hash = handle \u0026amp; (s-\u0026gt;slot_size-1); struct skynet_context * ctx = s-\u0026gt;slot[hash]; if (ctx != NULL \u0026amp;\u0026amp; skynet_context_handle(ctx) == handle) { s-\u0026gt;slot[hash] = NULL; ret = 1; int i; int j=0, n=s-\u0026gt;name_count; // 开始删除name中的对应关系 for (i=0; i\u0026lt;n; ++i) { if (s-\u0026gt;name[i].handle == handle) { skynet_free(s-\u0026gt;name[i].name); continue; } else if (i!=j) { s-\u0026gt;name[j] = s-\u0026gt;name[i]; } ++j; } s-\u0026gt;name_count = j; } else { ctx = NULL; } rwlock_wunlock(\u0026amp;s-\u0026gt;lock); if (ctx) { // release ctx may call skynet_handle_* , so wunlock first. skynet_context_release(ctx); } return ret; } 因为handle 本身就是数组下标，所以对于删除 slot 来说很简单，相对麻烦的事情是删name里面的对应，需要遍历和移动整个数组。\nskynet_handle_init 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 void skynet_handle_init(int harbor) { assert(H==NULL); struct handle_storage * s = skynet_malloc(sizeof(*H)); s-\u0026gt;slot_size = DEFAULT_SLOT_SIZE; s-\u0026gt;slot = skynet_malloc(s-\u0026gt;slot_size * sizeof(struct skynet_context *)); memset(s-\u0026gt;slot, 0, s-\u0026gt;slot_size * sizeof(struct skynet_context *)); rwlock_init(\u0026amp;s-\u0026gt;lock); // reserve 0 for system s-\u0026gt;harbor = (uint32_t) (harbor \u0026amp; 0xff) \u0026lt;\u0026lt; HANDLE_REMOTE_SHIFT; s-\u0026gt;handle_index = 1; s-\u0026gt;name_cap = 2; s-\u0026gt;name_count = 0; s-\u0026gt;name = skynet_malloc(s-\u0026gt;name_cap * sizeof(struct handle_name)); H = s; // Don\u0026#39;t need to free H } 整个结构初始化的行为 在 skynet_start 的时候调用 skynet_handle_init，这边简单的为几个数组长度进行了初始化。稍微有点点疑惑的是 特别注释了一个 不用free H。 那H的内存什么时候释放呢？\n","date":"2023-11-21T00:00:00Z","image":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%89-skynetethandle/skynet_hu17557819904416107650.png","permalink":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B8%89-skynetethandle/","title":"Skynet源码阅读笔记(三)-SkynetetHandle"},{"content":"Skynet源码阅读笔记-SkynetModule skynet的服务可以认为是 SkynetModule 的实例，skynet本身自带了4个类型的服务，gate、logger、snlua、 harbor。 自带的这几个服务位于 service-src下。\n承接上文，logger 通过 skynet_context_new 进行创建，在 skynet_context_new 中可以看到对 skynet-module 的引用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 struct skynet_context * skynet_context_new(const char * name, const char *param) { // 根据名字来获取一个module struct skynet_module * mod = skynet_module_query(name); printf(\u0026#34;in skynet_context_new %s %s\\n\u0026#34;, name, param); if (mod == NULL) return NULL; // 创建出module的实例 void *inst = skynet_module_instance_create(mod); if (inst == NULL) return NULL; // 创建Ctx struct skynet_context * ctx = skynet_malloc(sizeof(*ctx)); CHECKCALLING_INIT(ctx) ctx-\u0026gt;mod = mod; ctx-\u0026gt;instance = inst; // 设置其他cxt的变量初始值 ....... CHECKCALLING_BEGIN(ctx) // mod 初始化 int r = skynet_module_instance_init(mod, inst, ctx, param); CHECKCALLING_END(ctx) ... } skynet_context_new 本身是为了创建 skynet_context， 但可以看到 skynet_context 中加载对应 skynet_module , 并创建了对应的实例， 下面就具体看看怎么实现的。\nskynet_module 基本机构 先看看skynet_module的结构\n1 2 3 4 5 6 7 8 9 10 11 12 13 typedef void * (*skynet_dl_create)(void); typedef int (*skynet_dl_init)(void * inst, struct skynet_context *, const char * parm); typedef void (*skynet_dl_release)(void * inst); typedef void (*skynet_dl_signal)(void * inst, int signal); struct skynet_module { const char * name; // 名字 void * module; // module的地址 skynet_dl_create create; // 创建module实例执行的函数 skynet_dl_init init; // 初始化module执行的函数 skynet_dl_release release; // 释放module执行函数 skynet_dl_signal signal; // module信号执行函数 }; 对于skynet来说，一个module相当于有一个名字以及对应的4个需要执行的函数\n在skynet_context_new中有一个skynet_module_query，这个函数会将module导入进来\n1 2 3 4 5 6 struct modules { int count; struct spinlock lock; const char * path; struct skynet_module m[MAX_MODULE_TYPE]; }; 导入进来的 skynet_module 会被保存在 modules 的数组中，MAX_MODULE_TYPE 默认是32.\nskynet_module_query 导入过程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 // 查找一下当前的M中释放已经存在了对应的module static struct skynet_module * _query(const char * name) { int i; for (i=0;i\u0026lt;M-\u0026gt;count;i++) { if (strcmp(M-\u0026gt;m[i].name,name)==0) { return \u0026amp;M-\u0026gt;m[i]; } } return NULL; } struct skynet_module * skynet_module_query(const char * name) { //查找一下当前的M中释放已经存在了对应的module struct skynet_module * result = _query(name); if (result) return result; //没有的话就需要加锁导入 SPIN_LOCK(M) result = _query(name); // double check if (result == NULL \u0026amp;\u0026amp; M-\u0026gt;count \u0026lt; MAX_MODULE_TYPE) { int index = M-\u0026gt;count; void * dl = _try_open(M,name); // 尝试导入对应名字的so if (dl) { M-\u0026gt;m[index].name = name; M-\u0026gt;m[index].module = dl; if (open_sym(\u0026amp;M-\u0026gt;m[index]) == 0) { // 将对应的4个函数进行赋值 M-\u0026gt;m[index].name = skynet_strdup(name); M-\u0026gt;count ++; result = \u0026amp;M-\u0026gt;m[index]; //完成后返回导入的module } } } SPIN_UNLOCK(M) return result; } skynet_module_query 执行的行为很简单, 如果当前缓存内不存在，就加锁导入进行导入，导入时通过_try_open进行的，导入完成后需要对skynet_module内的所有变量进行赋值\nopen_sym 是对传入的skynet_module的4个函数进行赋值，里面是使用字符串拼接的方式将module名字和函数名字拼在一起后通过dlsym的方式找到对应的函数\n_try_open 实际上是dlopen的包装，在给定的搜索路径内搜索对应的so文件，然后尝试用dlopen打开。\nskynet_module.c 内的其他接口就是对结构体内的保存的4个函数地址的封装\n小结 skynet_module 这个结构本身就是对so的一个包装，如果一个so需要通过这种方式加载到skynet内当作服务的话，则需要实现对应的4个方法。\n","date":"2023-11-21T00:00:00Z","image":"https://frozenlychees.github.io/skynet.jpg","permalink":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%BA%8C-skynetmodule/","title":"Skynet源码阅读笔记(二)-SkynetModule"},{"content":"Skynet源码阅读笔记-SkynetModule skynet的服务可以认为是 SkynetModule 的实例，skynet本身自带了4个类型的服务，gate、logger、snlua、 harbor。 自带的这几个服务位于 service-src下。\n承接上文，logger 通过 skynet_context_new 进行创建，在 skynet_context_new 中可以看到对 skynet-module 的引用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 struct skynet_context * skynet_context_new(const char * name, const char *param) { // 根据名字来获取一个module struct skynet_module * mod = skynet_module_query(name); printf(\u0026#34;in skynet_context_new %s %s\\n\u0026#34;, name, param); if (mod == NULL) return NULL; // 创建出module的实例 void *inst = skynet_module_instance_create(mod); if (inst == NULL) return NULL; // 创建Ctx struct skynet_context * ctx = skynet_malloc(sizeof(*ctx)); CHECKCALLING_INIT(ctx) ctx-\u0026gt;mod = mod; ctx-\u0026gt;instance = inst; // 设置其他cxt的变量初始值 ....... CHECKCALLING_BEGIN(ctx) // mod 初始化 int r = skynet_module_instance_init(mod, inst, ctx, param); CHECKCALLING_END(ctx) ... } skynet_context_new 本身是为了创建 skynet_context， 但可以看到 skynet_context 中加载对应 skynet_module , 并创建了对应的实例， 下面就具体看看怎么实现的。\nskynet_module 基本机构 先看看skynet_module的结构\n1 2 3 4 5 6 7 8 9 10 11 12 13 typedef void * (*skynet_dl_create)(void); typedef int (*skynet_dl_init)(void * inst, struct skynet_context *, const char * parm); typedef void (*skynet_dl_release)(void * inst); typedef void (*skynet_dl_signal)(void * inst, int signal); struct skynet_module { const char * name; // 名字 void * module; // module的地址 skynet_dl_create create; // 创建module实例执行的函数 skynet_dl_init init; // 初始化module执行的函数 skynet_dl_release release; // 释放module执行函数 skynet_dl_signal signal; // module信号执行函数 }; 对于skynet来说，一个module相当于有一个名字以及对应的4个需要执行的函数\n在skynet_context_new中有一个skynet_module_query，这个函数会将module导入进来\n1 2 3 4 5 6 struct modules { int count; struct spinlock lock; const char * path; struct skynet_module m[MAX_MODULE_TYPE]; }; 导入进来的 skynet_module 会被保存在 modules 的数组中，MAX_MODULE_TYPE 默认是32.\nskynet_module_query 导入过程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 // 查找一下当前的M中释放已经存在了对应的module static struct skynet_module * _query(const char * name) { int i; for (i=0;i\u0026lt;M-\u0026gt;count;i++) { if (strcmp(M-\u0026gt;m[i].name,name)==0) { return \u0026amp;M-\u0026gt;m[i]; } } return NULL; } struct skynet_module * skynet_module_query(const char * name) { //查找一下当前的M中释放已经存在了对应的module struct skynet_module * result = _query(name); if (result) return result; //没有的话就需要加锁导入 SPIN_LOCK(M) result = _query(name); // double check if (result == NULL \u0026amp;\u0026amp; M-\u0026gt;count \u0026lt; MAX_MODULE_TYPE) { int index = M-\u0026gt;count; void * dl = _try_open(M,name); // 尝试导入对应名字的so if (dl) { M-\u0026gt;m[index].name = name; M-\u0026gt;m[index].module = dl; if (open_sym(\u0026amp;M-\u0026gt;m[index]) == 0) { // 将对应的4个函数进行赋值 M-\u0026gt;m[index].name = skynet_strdup(name); M-\u0026gt;count ++; result = \u0026amp;M-\u0026gt;m[index]; //完成后返回导入的module } } } SPIN_UNLOCK(M) return result; } skynet_module_query 执行的行为很简单, 如果当前缓存内不存在，就加锁导入进行导入，导入时通过_try_open进行的，导入完成后需要对skynet_module内的所有变量进行赋值\nopen_sym 是对传入的skynet_module的4个函数进行赋值，里面是使用字符串拼接的方式将module名字和函数名字拼在一起后通过dlsym的方式找到对应的函数\n_try_open 实际上是dlopen的包装，在给定的搜索路径内搜索对应的so文件，然后尝试用dlopen打开。\nskynet_module.c 内的其他接口就是对结构体内的保存的4个函数地址的封装\n小结 skynet_module 这个结构本身就是对so的一个包装，如果一个so需要通过这种方式加载到skynet内当作服务的话，则需要实现对应的4个方法。\n","date":"2023-11-18T00:00:00Z","image":"https://frozenlychees.github.io/skynet.jpg","permalink":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%BA%8C-skynetmodule/","title":"Skynet源码阅读笔记(二)-SkynetModule"},{"content":"Skynet源码阅读笔记-启动流程 主流程 main函数在skynet_main.c中, 主函数里的流程看起来不算很长，这边全贴出来，然后分块分析\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 int main(int argc, char *argv[]) { // 1. 判断是否传入了配置，没有的话就退出了 const char * config_file = NULL ; if (argc \u0026gt; 1) { config_file = argv[1]; } else { fprintf(stderr, \u0026#34;Need a config file. Please read skynet wiki : https://github.com/cloudwu/skynet/wiki/Config\\n\u0026#34; \u0026#34;usage: skynet configfilename\\n\u0026#34;); return 1; } // 2. 初始化skynet的主线程相关的变量 skynet_globalinit(); // 3. 初始化skynet的环境，其中包括一个lua环境和一个自旋锁 skynet_env_init(); // 4. 信号处理相关 sigign(); struct skynet_config config; #ifdef LUA_CACHELIB // init the lock of code cache luaL_initcodecache(); #endif // 初始化一个lua虚拟机，用来读取配置 struct lua_State *L = luaL_newstate(); luaL_openlibs(L);\t// link lua lib // 执行一段硬编码的lua代码，这个代码写在skynet_main.c文件里，就是load_config变量所对应的内容 // load_config就是包装load进行的加载配置函数 // 这边是把load_config变成lua函数然后执行加载 int err = luaL_loadbufferx(L, load_config, strlen(load_config), \u0026#34;=[skynet config]\u0026#34;, \u0026#34;t\u0026#34;); assert(err == LUA_OK); lua_pushstring(L, config_file); err = lua_pcall(L, 1, 1, 0); if (err) { fprintf(stderr,\u0026#34;%s\\n\u0026#34;,lua_tostring(L,-1)); lua_close(L); return 1; } // 这个函数看起来是把刚刚读取的配置设置到lua env全局变量中 _init_env(L); // 初始化skynet的基础配置 config.thread = optint(\u0026#34;thread\u0026#34;,8); config.module_path = optstring(\u0026#34;cpath\u0026#34;,\u0026#34;./cservice/?.so\u0026#34;); config.harbor = optint(\u0026#34;harbor\u0026#34;, 1); config.bootstrap = optstring(\u0026#34;bootstrap\u0026#34;,\u0026#34;snlua bootstrap\u0026#34;); config.daemon = optstring(\u0026#34;daemon\u0026#34;, NULL); config.logger = optstring(\u0026#34;logger\u0026#34;, NULL); config.logservice = optstring(\u0026#34;logservice\u0026#34;, \u0026#34;logger\u0026#34;); config.profile = optboolean(\u0026#34;profile\u0026#34;, 1); lua_close(L); //skynet 框架启动 skynet_start(\u0026amp;config); skynet_globalexit(); return 0; } ##skynet_start 从上面的代码解析，可以清楚的知道，skynet启动的主要函数就是skynet_start，看看它做了什么\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 void skynet_start(struct skynet_config * config) { // register SIGHUP for log file reopen // 首先是注册了一个SIGHUP的信号执行函数 struct sigaction sa; sa.sa_handler = \u0026amp;handle_hup; sa.sa_flags = SA_RESTART; sigfillset(\u0026amp;sa.sa_mask); sigaction(SIGHUP, \u0026amp;sa, NULL); // 看配置是否创建守护进程 if (config-\u0026gt;daemon) { if (daemon_init(config-\u0026gt;daemon)) { exit(1); } } // 初始化 Harbor节点的数量 skynet_harbor_init(config-\u0026gt;harbor); // 初始化handle的存储 skynet_handle_init(config-\u0026gt;harbor); // 初始化全局消息队列 skynet_mq_init(); // 初始化模块的查找路径 skynet_module_init(config-\u0026gt;module_path); // 初始化定时器相关 skynet_timer_init(); // 初始化socket相关 skynet_socket_init(); // profile是否打开 skynet_profile_enable(config-\u0026gt;profile); // 初始化logger相关服务 struct skynet_context *ctx = skynet_context_new(config-\u0026gt;logservice, config-\u0026gt;logger); if (ctx == NULL) { fprintf(stderr, \u0026#34;Can\u0026#39;t launch %s service\\n\u0026#34;, config-\u0026gt;logservice); exit(1); } skynet_handle_namehandle(skynet_context_handle(ctx), \u0026#34;logger\u0026#34;); // 启动config-\u0026gt;bootstrap 所配置的服务 bootstrap(ctx, config-\u0026gt;bootstrap); // 启动线程 start(config-\u0026gt;thread); // harbor_exit may call socket send, so it should exit before socket_free skynet_harbor_exit(); skynet_socket_free(); if (config-\u0026gt;daemon) { daemon_exit(config-\u0026gt;daemon); } } 这段代码主要就是初始化skynet的组件，然后启动logger、定时器等相关服务，然后调用bootstrap 和 start\nbootstrap 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 static void bootstrap(struct skynet_context * logger, const char * cmdline) { int sz = strlen(cmdline); char name[sz+1]; char args[sz+1]; int arg_pos; sscanf(cmdline, \u0026#34;%s\u0026#34;, name); arg_pos = strlen(name); if (arg_pos \u0026lt; sz) { while(cmdline[arg_pos] == \u0026#39; \u0026#39;) { arg_pos++; } strncpy(args, cmdline + arg_pos, sz); } else { args[0] = \u0026#39;\\0\u0026#39;; } struct skynet_context *ctx = skynet_context_new(name, args); if (ctx == NULL) { skynet_error(NULL, \u0026#34;Bootstrap error : %s\\n\u0026#34;, cmdline); skynet_context_dispatchall(logger); exit(1); } } bootstrap 主要就是根据config-\u0026gt;bootstrap配置来启动一个新的服务，在默认配置下一般都是snlua bootstrap\nstart start函数主要是启动所有对应个数的线程，具体代码如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 static void start(int thread) { pthread_t pid[thread+3]; //额外多3个线程 struct monitor *m = skynet_malloc(sizeof(*m)); memset(m, 0, sizeof(*m)); m-\u0026gt;count = thread; m-\u0026gt;sleep = 0; //给每个线程都分配一个skynet_monitor m-\u0026gt;m = skynet_malloc(thread * sizeof(struct skynet_monitor *)); int i; for (i=0;i\u0026lt;thread;i++) { // 这个循环稍微有一点疑问，要么应该是i\u0026lt;thread+3 要么应该i从3开始，或者是我没理解正确理解 m-\u0026gt;m[i] = skynet_monitor_new(); } // 初始化monitor的锁和条件变量 if (pthread_mutex_init(\u0026amp;m-\u0026gt;mutex, NULL)) { fprintf(stderr, \u0026#34;Init mutex error\u0026#34;); exit(1); } if (pthread_cond_init(\u0026amp;m-\u0026gt;cond, NULL)) { fprintf(stderr, \u0026#34;Init cond error\u0026#34;); exit(1); } // 额外的三个线程用于定时器、监控、socket create_thread(\u0026amp;pid[0], thread_monitor, m); create_thread(\u0026amp;pid[1], thread_timer, m); create_thread(\u0026amp;pid[2], thread_socket, m); static int weight[] = { -1, -1, -1, -1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, }; struct worker_parm wp[thread]; // 给线程分配权重，并执行thread_worker for (i=0;i\u0026lt;thread;i++) { wp[i].m = m; wp[i].id = i; if (i \u0026lt; sizeof(weight)/sizeof(weight[0])) { wp[i].weight= weight[i]; } else { wp[i].weight = 0; } create_thread(\u0026amp;pid[i+3], thread_worker, \u0026amp;wp[i]); } //主线程等待其他线程结束 for (i=0;i\u0026lt;thread+3;i++) { pthread_join(pid[i], NULL); } free_monitor(m); } 主线程会额外启动三个线程，分别用于定时器、监控、socket， 在启动完毕所有线程之后，会阻塞等待所有线程的退出。对于每一个线程来说，还会再weight中有对应的权重，权重的作用先不探究。\n","date":"2023-11-15T00:00:00Z","image":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/skynet_hu17557819904416107650.png","permalink":"https://frozenlychees.github.io/p/skynet%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/","title":"Skynet源码阅读笔记-启动流程"},{"content":"处理出现的CLOSE_WAIT状态 问题 先说一下问题的基本情况。在内网压测过程中发现压测机器人无法登录，但在外网跑了一天稳定性也没出现问题。\n感觉很奇怪，终于有一天，内容日志中发现了下面一段\n1 accept error: Too Many open files 看起来是文件描述符打开过多，一开始以为压测的人数太多了，超过了描述符数量，就调整人数以及通过ulimit 方式增加进程的文件描述符数量。结果治标不治本，在执行过多次机器人后，发现问题还是存在\n随机通过下面一些命令查看打开的描述符\nlsof -p \u0026lt;进程号\u0026gt; 查看对应进程的文件描述符 ss -tnae 查看socket的状态 发现有一堆socket处于CLOSE_WAIT状态.\n随即找到TCP的状态机看看为啥出现这样的情况\n根据上面的图可以知道，进入CLOSE_WAIT状态了之后，是需要进程主动调用close来关闭fd才能改变状态机的状态的。\n翻阅代码，果然发现同事在处理连接断开的时候存在问题，没调用对应的close来关闭fd。\n测试一下发现，只要是个链接，fd就会卡在CLOSE_WAIT状态，直到超过进程fd上限。调用close之后确实问题解决了。\n外网为啥没问题？ 在解决之后，突然想到为啥外网没事呢？ 理论上是一套代码，应该一定会卡在CLOSE_WAIT状态才对.\n测试了一下，发现外网也存在这个情况，但CLOSE_WAIT状态的链接大概3分钟后就被清理掉了。 而且外网的进程可持有FD数量也比较大，所以才没出现无法登录的情况。\n看来CLOSE_WAIT应该是有系统级别的清理方法作为最后的保障。\n但查了一圈好像没人说过这个情况，看到一个稍微靠谱一点的说法是 TCP的 keep_alive机制\nTCP keep_alive 是内核层面上的TCP保活机制，它会隔一段时间就侦测一下TCP链接是否还有效。通过一下命令可以看到对应的参数\n1 2 3 $ cat /proc/sys/net/ipv4/tcp_keepalive_time 7200 $ cat /proc/sys/net/ipv4/tcp_keepalive_intvl 75 $ cat /proc/sys/net/ipv4/tcp_keepalive_probes 9 默认配置如上\ntcp_keepalive_time 7200 秒后发送一次侦测包 tcp_keepalive_intvl 如果没回应则 75 秒后再发一次 tcp_keepalive_probes 尝试9次没回应就断开连接 通过 ss -tnae 也能看到对应的连接上有一个timer ，表明下一次侦探包的时间\n但稍微奇怪的是，我发现虽然外网的tcp_keepalive_time不是7200，但也是高达1200 .而CLOSE_WAIT状态大概200秒左右就被清理掉了，所以不能完全确定是TCP KEEP_ALIVE所造成的。\n2023 - 09 - 26 更新 后续又调查了一下，虽然还是不能找到准确原因，但发现CLOSE_WAIT状态的清理可能和RST包有关，在客户端断开连接120秒后，因为服务器一直没下发FIN包，客户端发起RST强制中断了连接。\n这个RST在服务器引擎中不知道怎么触发了Broken pipe操作，导致连接被清理掉了。\n而内网开发的时候，因为服务器是搭建在windows10 的WSL2的虚拟机中，可能环境和真实的debian有出入，导致内网没触发 Broken pipe 所以没清理掉。\n又尝试了一下 tcp_keepalive的行为，在debian上确实需要20分钟后才被清理。\n引用 https://www.jianshu.com/p/94dff0f29218 https://www.jianshu.com/p/3c7a0771b67e https://www.xiaolincoding.com/network/3_tcp/tcp_interview.html#%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%87%BA%E7%8E%B0%E5%A4%A7%E9%87%8F-close-wait-%E7%8A%B6%E6%80%81%E7%9A%84%E5%8E%9F%E5%9B%A0%E6%9C%89%E5%93%AA%E4%BA%9B https://zhuanlan.zhihu.com/p/578699402 ","date":"2023-09-25T00:00:00Z","image":"https://frozenlychees.github.io/p/%E5%A4%84%E7%90%86%E5%87%BA%E7%8E%B0%E7%9A%84close_wait%E7%8A%B6%E6%80%81/tcp_hu9771292596611190377.png","permalink":"https://frozenlychees.github.io/p/%E5%A4%84%E7%90%86%E5%87%BA%E7%8E%B0%E7%9A%84close_wait%E7%8A%B6%E6%80%81/","title":"处理出现的CLOSE_WAIT状态"},{"content":"Lua 源码阅读笔记-Table lua版本基于5.4.6， 文章更多是记录自己在阅读的是思绪，而非科普。\n很多源码比较长，直接贴不太好，建议阅读时配合着源码一起。\n如果内容有问题或者不正确的地方，欢迎留言讨论。\nLua的Table Lua的table 比较灵活，可以同时作为数组和字典，在内部实现上实际是有区分这两个类型的。\n首先看一下Table的基本结构\n1 2 3 4 5 6 7 8 9 10 11 typedef struct Table { CommonHeader; lu_byte flags; /* 1\u0026lt;\u0026lt;p means tagmethod(p) is not present */ lu_byte lsizenode; /* log2 of size of \u0026#39;node\u0026#39; array */ unsigned int alimit; /* \u0026#34;limit\u0026#34; of \u0026#39;array\u0026#39; array */ TValue *array; /* array part */ Node *node; Node *lastfree; /* any free position is before this position */ struct Table *metatable; GCObject *gclist; } Table; flags lsizenode: log2(字典大小) 的结果， 这边也还说明作为字典的时候，大小一定是2的倍数 alimit: 看起来是数组的大小，但不一定时准确的数组大小 array： 当table是数组时，指向使用的内存位置 node: 当table是字典时，指向使用的内存位置 lastfree: 当table刚申请的时候，指向table的末尾，冲突时会向前移动这个指针，找到一个空闲的位置\nmetatable: 指向这个表的原表 gclist: gc相关链表\n1 2 3 4 5 6 7 8 9 10 11 12 13 typedef struct TValue { TValuefields; } TValue; typedef union Node { struct NodeKey { TValuefields; /* fields for value */ lu_byte key_tt; /* key type */ int next; /* for chaining */ Value key_val; /* key value */ } u; TValue i_val; /* direct access to node\u0026#39;s value as a proper \u0026#39;TValue\u0026#39; */ } Node; node 对象的组成实际上就是NodeKey， 虽然整个Node是union标识的，但实际上NodeKey这个结构体的第一个字段和TValue 是一样的，所以i_val只是一个快速访问node中value的字段的方式。\n回到NodeKey上面，NodeKey由以下字段组成\nTValuefields 存储value的类型和值(或者指针) key_tt key的类型 key_val key 的值 next hash冲突时使用链表来解决。 这边附上《lua设计与实现》 一书中的对于表结构的图，注意书中是LUA5.1的结构，我阅读的时LUA5.4稍微有点区别，但基本类似, 图方便没有自己画图。\ntable 的搜索 先看以下对于一个table，lua是怎么尝试找到对应的值的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /* ** main search function */ const TValue *luaH_get (Table *t, const TValue *key) { switch (ttypetag(key)) { case LUA_VSHRSTR: return luaH_getshortstr(t, tsvalue(key)); case LUA_VNUMINT: return luaH_getint(t, ivalue(key)); case LUA_VNIL: return \u0026amp;absentkey; case LUA_VNUMFLT: { lua_Integer k; if (luaV_flttointeger(fltvalue(key), \u0026amp;k, F2Ieq)) /* integral index? */ return luaH_getint(t, k); /* use specialized version */ /* else... */ } /* FALLTHROUGH */ default: return getgeneric(t, key, 0); } } 对于一个table和一个指定的key，会根据key的类型来决定调用什么方式搜索；\n当key 是short str的时候，会调用luaH_getshortstr 当key 是int 或者是 等于整数的float的时候，会调用luaH_getint 当key 是nil的时候，直接返回absentkey（不存在的key 其他情况调用getgeneric luaH_getshortstr 1 2 3 4 5 6 7 8 9 10 11 12 13 14 const TValue *luaH_getshortstr (Table *t, TString *key) { Node *n = hashstr(t, key); lua_assert(key-\u0026gt;tt == LUA_VSHRSTR); for (;;) { /* check whether \u0026#39;key\u0026#39; is somewhere in the chain */ if (keyisshrstr(n) \u0026amp;\u0026amp; eqshrstr(keystrval(n), key)) return gval(n); /* that\u0026#39;s it */ else { int nx = gnext(n); if (nx == 0) return \u0026amp;absentkey; /* not found */ n += nx; } } } 获取字符串的hash值，然后判断对应的node是不是short str类型 且是否和key相等，相等则返回对应的value；不是的话则通过next字段找到下一个node。这边看方式next存的不是下一个node的指针，而是偏移。\nluaH_getint 这个函数的步骤大概如下：\n确认key的范围是不是在数组大小内，即 0\u0026lt; key \u0026lt; alimit, 如果是则直接返回array[key - 1] 如果alimit不是真实的数组长度，且key是在真实范围内的话，则也直接返回arraykey - 1 尝试用字典的方式在搜索一波key。 都失败了则返回absentkey。 getgeneric 1 2 3 4 5 6 7 8 9 10 11 12 13 static const TValue *getgeneric (Table *t, const TValue *key, int deadok) { Node *n = mainpositionTV(t, key); for (;;) { /* check whether \u0026#39;key\u0026#39; is somewhere in the chain */ if (equalkey(key, n, deadok)) return gval(n); /* that\u0026#39;s it */ else { int nx = gnext(n); if (nx == 0) return \u0026amp;absentkey; /* not found */ n += nx; } } } getgeneric 函数就是完全将table当作hash表来进行搜索了。搜索代码上和short hash 基本一样的，先通过mainpositionTV获取key的第一个位置，然后通过这个位置不断的在table中寻找匹配的key。\nmainpositionTV 中会通过key的类型来获取对应的hash值。\ntable的插入 table 插入的入口看起来是luaH_set\n1 2 3 4 void luaH_set (lua_State *L, Table *t, const TValue *key, TValue *value) { const TValue *slot = luaH_get(t, key); luaH_finishset(L, t, key, slot, value); } 整个函数就2行，找到一个key，然后设置成对应的value\nluaH_finishset 1 2 3 4 5 6 7 void luaH_finishset (lua_State *L, Table *t, const TValue *key, const TValue *slot, TValue *value) { if (isabstkey(slot)) luaH_newkey(L, t, key, value); else setobj2t(L, cast(TValue *, slot), value); } 在luaH_finishset中，如果slot查找出来是absentkey，则会调用luaH_newkey创建新的key，不然就直接设置value即可。\nluaH_newkey 函数比较长，建议对照源码来看.\n首先先要确认key和value 的类型，当key或者value为nil的时候，是不允许插入的。如果key是float且能转成int 的话，则key会被当做int进行插入。 通过mainpositionTV来找到对应的node 如果发现需要扩容，则执行rehash，然后递归重新执行luaH_set。 如果找到的node已经有数据的话，则通过这步找到一个新的位置； 将找到的node的key和value都设置好。 这边的第3、4步代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 mp = mainpositionTV(t, key); // 判断是否冲突或者hash表的lastfree为空 if (!isempty(gval(mp)) || isdummy(t)) { /* main position is taken? */ // 先找一个空位来放这个元素 // getfreepos 默认都是从内存块的最后往前找一个没元素的位置 Node *othern; Node *f = getfreepos(t); /* get a free place */ if (f == NULL) { /* cannot find a free place? */ // 没位置了就rehash rehash(L, t, key); /* grow table */ /* whatever called \u0026#39;newkey\u0026#39; takes care of TM cache */ luaH_set(L, t, key, value); /* insert key into grown table */ return; } lua_assert(!isdummy(t)); // 将碰撞位置的元素进行一次hash来判断这个元素是否应该在这里 othern = mainpositionfromnode(t, mp); if (othern != mp) { /* is colliding node out of its main position? */ /* yes; move colliding node into free position */ // 将碰撞的元素找到一个新的位置插入 while (othern + gnext(othern) != mp) /* find previous */ othern += gnext(othern); gnext(othern) = cast_int(f - othern); /* rechain to point to \u0026#39;f\u0026#39; */ *f = *mp; /* copy colliding node into free pos. (mp-\u0026gt;next also goes) */ // 将新元素插入到原来碰撞元素的位置 if (gnext(mp) != 0) { gnext(f) += cast_int(mp - f); /* correct \u0026#39;next\u0026#39; */ gnext(mp) = 0; /* now \u0026#39;mp\u0026#39; is free */ } setempty(gval(mp)); } else { // 碰撞的位置是对应位置上的元素，则将新位置链接到这个元素后面 /* colliding node is in its own main position */ /* new node will go into free position */ if (gnext(mp) != 0) gnext(f) = cast_int((mp + gnext(mp)) - f); /* chain new position */ else lua_assert(gnext(f) == 0); gnext(mp) = cast_int(f - mp); mp = f; } } lua的table和其他dict实现的有点不太一样，以Python为例子，Python的hash表实现是hash表和元素节点的内存是分开的，hash表中存的是元素的链表。但Lua中hash表和元素是共用内存的，即hash表存的就是元素。\n而且冲突的时候的处理也挺不一致的。python因为元素内存是额外申请的，所以找到位置后直接修改链表即可。而Lua在冲突的时候，是通过lastfree指针在hash表从后往前找一个空闲的元素位置，然后根据冲突节点来判断这个空闲的位置到底是给新节点还是冲突节点。\n感觉这种实现的话，应该是为内存效率做考虑，但代价就是冲突处理的效率肯定是低于其他实现的，同时table删除元素是将对应的value修改成nil来实现的，所以lastfree指针只会不断向前，对于会频繁增删的hash表来说，应该是会造成rehash的次数上涨的。\nrehash lua table的rehash因为同时包含数组和hash表的，所以在rehash的时候，会同时改变这两个部分的内容。luaH_resize才是真正重新分配内存的地方，而之前的部分都是为了计算出一个新的数组大小和hash表大小。 主要涉及到一下几个变量：\ntotaluse 表示所有key的总和 na表示数字部分的key的总和 nums 一个统计数组，nums[i] 表示 在 （2^(i - 1)， 2^i] 之间的数字key的个数 这几个变量会在computesizes 中计算出一个合适的新的数组部分大小asize，用来存储数字部分的key。computesizes函数的主要思路应该是算出一个最小的2的N次幂，使得其中数字key在[1, 2^N]的分布能够小于50%。 而剩余的key就会认为应该是在hash表的部分，所以totaluse - asize 就是新的hash表大小。\nluaH_resize 就会对这两个新的大小进行内存的重新分配和元素迁移。数组分部申请新的内存，然后直接内存拷贝相同大小部分的数据。hash表部分遍历全表，找到非nil元素进行搬迁，重新调用luaH_set对新table进行插入，这样需要搬迁到数组部分的元素也就会迁移过去了。\n取长度操作 通过#操作来对table获取长度的操作实际上不是常规意义上的取长度. \u0026lsquo;#\u0026lsquo;操作符通过 luaH_getn 来完成，luaH_getn实际上是返回n，满足a[1]~a[n]所有元素不为空 以下面的代码为例子：\n1 2 3 4 5 6 a = {4, 5, nil, nil，6} print(#a) \u0026gt;\u0026gt; 5 -- 刚创建，所以初始化了数组长度，返回的还是5 a[6] = 1 print(#a) \u0026gt;\u0026gt; 2 --多塞入一个，造成了rehash，数组长度需要通过luaH_getn来获得 这边就可以看出，只要通过luaH_getn来获取长度，如果数组包含nil，那么获取的结果就不一定是完整的数组的长度。\nluaH_getn 实现实际上是通过二分的方式来找满足 a[n - 1] ~= nil and a[n] == nil\n这边就不分析具体代码了。\n总结 通过阅读table的增删查改，感觉到LUA对于table的实现上更注重内存的使用，所带来的代价就是rehash 和冲突解决的消耗变高了。\n貌似table默认也不支持取正确的长度，可能在需要table长度的时候需要注意自己维护一下，避免每次都遍历table来获取长度\n引用 1.《lua设计与实现》\n","date":"2023-09-23T00:00:00Z","image":"https://frozenlychees.github.io/p/lua-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-table/lua_hu12632442988653076332.png","permalink":"https://frozenlychees.github.io/p/lua-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-table/","title":"Lua 源码阅读笔记-Table"},{"content":"Lua 源码阅读笔记-String lua版本基于5.4.6， 文章更多是记录自己在阅读的是思绪，而非科普。\n很多源码比较长，直接贴不太好，建议阅读时配合着源码一起。\n如果内容有问题或者不正确的地方，欢迎留言讨论。\nLua的String lua String 的代码很少， 相关的代码加起来也才几百行吧。\n首先是字符串类型的定义\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 /* ** Header for a string value. */ typedef struct TString { CommonHeader; lu_byte extra; /* reserved words for short strings; \u0026#34;has hash\u0026#34; for longs */ lu_byte shrlen; /* length for short strings */ unsigned int hash; union { size_t lnglen; /* length for long strings */ struct TString *hnext; /* linked list for hash table */ } u; char contents[1]; } TString; extra 在短字符串中目前是用来判断是否是关键字，在长字符串中作为是否有hash值的标记 shrlen 短字符串的长度 hash hash值 u 长字符串是用做长度，短字符串是用作哈希表的链接 contents 存字符串的地方，用了个柔性数组，在申请的内存时候，字符串对应的位置可以一并申请并放在末尾。 extra 在短字符串中标记的位置是在luaX_init函数(llex.c)中\nluaS_new 这个函数在看起来是字符串创建的入口， 代码不长\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 TString *luaS_new (lua_State *L, const char *str) { unsigned int i = point2uint(str) % STRCACHE_N; /* hash */ int j; TString **p = G(L)-\u0026gt;strcache[i]; for (j = 0; j \u0026lt; STRCACHE_M; j++) { if (strcmp(str, getstr(p[j])) == 0) /* hit? */ return p[j]; /* that is it */ } /* normal route */ for (j = STRCACHE_M - 1; j \u0026gt; 0; j--) p[j] = p[j - 1]; /* move out last element */ /* new element is first in the list */ p[0] = luaS_newlstr(L, str, strlen(str)); return p[0]; } 可以看到在用这个接口生成字符串的时候，会先判断字符串地址是否在cache中，如果在的话，直接返回cache的对象，否则在缓存头部插入这个对象；STRCACHE_M是hash桶的大小，如果超过大小则会踢掉最后一个元素。\nluaS_newlstr 创建字符串的函数 1 2 3 4 5 6 7 8 9 10 11 12 TString *luaS_newlstr (lua_State *L, const char *str, size_t l) { if (l \u0026lt;= LUAI_MAXSHORTLEN) /* short string? */ return internshrstr(L, str, l); else { TString *ts; if (l_unlikely(l \u0026gt;= (MAX_SIZE - sizeof(TString))/sizeof(char))) luaM_toobig(L); ts = luaS_createlngstrobj(L, l); memcpy(getstr(ts), str, l * sizeof(char)); return ts; } } 这边看LUA 默认的短字符串长度为40（宏为 LUAI_MAXSHORTLEN），短字符串会通过internshrstr来创建字符串对象；而超过短长度限制的会通过luaS_createlngstrobj来创建对应的字符串对象，并赋值到content中。\ninternshrstr internshrstr 函数可以分成3个部分\n首先是根据全局共享的global_State获取到对应的stringtable，这个stringtable相当于字符串的哈希表。然后算出对应字符串的hash值。 在stringtable中查找是否有对应的字符串，有的话直接服用；这边又一个特殊一点的，就是如果找到的字符串已经没人被其他地方引用，但还没被GC回收的话，那么也会直接让对象复活。 到这边就确定是必须创建的字符串对象，那么就申请空间，赋值content，然后判断对应的stringtable是不是要扩容了，最后插入到stringtable中，并返回。 luaS_createlngstrobj 超长的对象不会进入stringtable，直接申请空间赋值就结束了。他们申请空间走的都是createstrobj这个接口，但有几个不同的点\n短字符串的tag是LUA_VSHRSTR， 而长字符串的tag是LUA_VLNGSTR。 短字符串是用shrlen表示长度，而长字符串是用lnglen来表示长度 长字符串在申请的时候确实没填充hash、shrlen、extra， 这边感觉到LUA对短字符串的内存使用有使用一些优化的手段；而对于不太常用的长字符串的话，貌似会浪费一些字段，但也不是特别要紧。\ngrowstrtab \u0026amp; luaS_resize growstrtab 和 luaS_resize 实际上都是为了调用tablerehash的。\ngrowstrtab函数在internshrstr中会用到，主要是在第三步扩容的位置使用。\nluaS_resize的代码主要分为两种情况\n当是缩容的情况，luaS_resize先执行一遍tablerehash，然后在申请新内存（看完后面的tablerehash，感觉缩容不应该会改变内存），如果申请失败则恢复。 当是扩容的情况，只有申请成功了之后才会操作。 tablerehash tablerehash的代码感觉有点意思的，是在本地上进行的rehash。有点不同于python、stl之类的方式，它们的方式是先申请一个表，然后for循环当前的hash表，将元素在新表上找到位置后一个个搬迁过去。而lua的实现如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 static void tablerehash (TString **vect, int osize, int nsize) { int i; for (i = osize; i \u0026lt; nsize; i++) /* clear new elements */ vect[i] = NULL; for (i = 0; i \u0026lt; osize; i++) { /* rehash old part of the array */ TString *p = vect[i]; vect[i] = NULL; while (p) { /* for each string in the list */ TString *hnext = p-\u0026gt;u.hnext; /* save next */ unsigned int h = lmod(p-\u0026gt;hash, nsize); /* new position */ p-\u0026gt;u.hnext = vect[h]; /* chain it into array */ vect[h] = p; p = hnext; } } } lua的这个tablerehash 主要执行的步骤如下：\n如果是扩容，则将新生长的部分清空。 遍历原来的长度的数据，将原来长度中的元素按新大小进行hash找到位置放到链表头部。 乍一看这个代码会想到两个问题\n元素被重新映射到当前位置，构成死循环？ 是否会出现重新映射后的元素后面再次遍历到？即新的元素位置还是小于osize？ 但实际上上面的问题都不会存在。先来解释第一个情况，因为在遍历到vect[i]的时候，把vect[i]的元素设置成NULL了，相当于先把链表和hash表分离了。所以即使在同一个位置，也不会构成死循环。\n第二个问题，则需要考虑到LUA的这个表的扩容和缩容一定是以2的倍数进行的。也就是扩大一定是扩大2倍，缩小也一定缩小到原来的1/2，这边在源码中可以搜索到调用luaS_resize的位置只有2处。\n假设原来的大小是4，扩容后的大小是8。原来映射到0号位置的元素，被rehash后，出现的位置一定是0和4，同理原来1号位置的元素会被映射到1和5。而rehash的范围是0~3,所以不可能出现rehash后元素的位置会小于osize且不为i的。\n这个实现方式的好处感觉在于就是可以不必频繁的变动内存位置，减少申请内存的次数。扩缩容的时候可以预留一部分内存，等真正不够用的时候在去申请更大的内存块。\n总结 字符串对象的实现确实都差不多，相比于Python 来说确实会更加轻量化一点。同时也看得出来LUA的字符串是不考虑编码格式的问题。tablerehash的方式和Redis的字典扩容的方式应该可以算是一致的。\n同样的，图例的GCObject应该修改成CommonHeader。\n引用 《Lua设计与实现》 ","date":"2023-09-01T00:00:00Z","image":"https://frozenlychees.github.io/p/lua-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-string/lua_hu12632442988653076332.png","permalink":"https://frozenlychees.github.io/p/lua-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-string/","title":"Lua 源码阅读笔记-String"},{"content":"Lua 源码阅读笔记-基本类型 lua版本基于5.4.6， 文章更多是记录自己在阅读的是思绪，而非科普。 如果内容有问题或者不正确的地方，欢迎留言讨论。\nLua的基本类型 在Lua中，所有的类型都是通过Value + type的方式进行管理\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // lobject.h typedef union Value { struct GCObject *gc; /* collectable objects */ void *p; /* light userdata */ lua_CFunction f; /* light C functions */ lua_Integer i; /* integer numbers */ lua_Number n; /* float numbers */ /* not used, but may avoid warnings for uninitialized value */ lu_byte ub; } Value; #define TValuefields\tValue value_; lu_byte tt_ typedef struct TValue { TValuefields; } TValue; Tvalue中value_管理对应的值或者指针，而 tt_管理对应的类型, lu_byte实际上是unsigned char。\n这边的类型不是用enum之类的来实现的，而是用一系列的宏来标识对应的类型。\n1 2 3 4 5 6 7 8 9 10 // lobject.h /* ** tags for Tagged Values have the following use of bits: ** bits 0-3: actual tag (a LUA_T* constant) ** bits 4-5: variant bits ** bit 6: whether value is collectable */ /* add variant bits to a type */ #define makevariant(t,v)\t((t) | ((v) \u0026lt;\u0026lt; 4)) 从注释上来看， bits的0-3位是真正用来做tag的位， 这边的tag基本类型定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 //lua.h #define LUA_TNIL\t0 #define LUA_TBOOLEAN\t1 #define LUA_TLIGHTUSERDATA\t2 #define LUA_TNUMBER\t3 #define LUA_TSTRING\t4 #define LUA_TTABLE\t5 #define LUA_TFUNCTION\t6 #define LUA_TUSERDATA\t7 #define LUA_TTHREAD\t8 #define LUA_NUMTYPES\t9 后面的扩展位就是用来在同一种类型下区分子类型的，例如\n1 2 3 4 5 6 7 8 /* Standard nil */ #define LUA_VNIL\tmakevariant(LUA_TNIL, 0) /* Empty slot (which might be different from a slot containing nil) */ #define LUA_VEMPTY\tmakevariant(LUA_TNIL, 1) #define LUA_VFALSE\tmakevariant(LUA_TBOOLEAN, 0) #define LUA_VTRUE\tmakevariant(LUA_TBOOLEAN, 1) 被GC管理的对象 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ** Common Header for all collectable objects (in macro form, to be ** included in other objects) */ #define CommonHeader\tstruct GCObject *next; lu_byte tt; lu_byte marked /* Common type for all collectable objects */ typedef struct GCObject { CommonHeader; } GCObject; // 宏展开后的结果如下 /* typedef struct GCObject { struct GCObject *next; lu_byte tt; lu_byte marked; } GCObject; */ GCoBjcet的实现里面就只有一个CommonHeader，所有需要被GC管理的对象都会带上这个Header。相当于就是继承到了GcObject。 这个GcObject的实现实际上就是个单链表. 同时这边又补充了几个宏，用于gc对象的操作。\n其中marked 被用来在GC回收过程中的标记作用。\n这边再回看一开始的Union Value, GCObject 也被囊括再其中，借用《Lua设计与实现》一书中的图，可以比较清晰的。\n这边有一个需要修正的，图中的GCHeader在Lua5.4.6中已经不存在了，即GCObject中，第一个字段直接就是CommonHeader.\n引用 《Lua设计与实现》 https://blog.codingnow.com/2011/03/lua_gc_1.html 《云风-Lua GC 的源码剖析》 ","date":"2023-09-01T00:00:00Z","image":"https://frozenlychees.github.io/p/lua-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B/lua_hu12632442988653076332.png","permalink":"https://frozenlychees.github.io/p/lua-%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0-%E5%9F%BA%E6%9C%AC%E7%B1%BB%E5%9E%8B/","title":"Lua 源码阅读笔记-基本类型"},{"content":"Welcome to Hugo theme Stack. This is your first post. Edit or delete it, then start writing!\nFor more information about this theme, check the documentation: https://docs.stack.jimmycai.com/\n","date":"2023-08-16T00:00:00Z","image":"https://frozenlychees.github.io/p/testslug/cover_hu6307248181568134095.jpg","permalink":"https://frozenlychees.github.io/p/testslug/","title":"testTitle"},{"content":"Welcome to Hugo theme Stack. This is your first post. Edit or delete it, then start writing!\nFor more information about this theme, check the documentation: https://docs.stack.jimmycai.com/\nWant a site like this? Check out hugo-theme-stack-stater\nPhoto by Pawel Czerwinski on Unsplash\n","date":"2022-03-06T00:00:00Z","image":"https://frozenlychees.github.io/p/hello-world/cover_hu6307248181568134095.jpg","permalink":"https://frozenlychees.github.io/p/hello-world/","title":"Hello World"}]